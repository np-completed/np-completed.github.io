{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"../README.md","title":"Home"},{"location":"gh-actions/build-push-image/","text":"Github Actions Build and Push Image to Repository Package Manager No PAT required. This github action uses the GITHUB_TOKEN , available to each repository. # Checkout the files from the Git repository. # Login to the ghcr.io container registry. # Setup Docker # Get metadata for use later in Docker. This avoids having to do manual work to set up the tags and labels for the Docker images. # Finally, build the image and push it. The build and push has two steps name: Docker Build & Publish to GitHub Container Registry on: push: branches: - 'main' # anything under a build/ folder will be used as testing the build processes. # - 'build/*' tags: - 'v*' workflow_dispatch: inputs: git-ref: description: Git Ref (Optional) required: false env: REGISTRY: ghcr.io IMAGE_NAME: ${{ github.repository }} jobs: build-and-push-docker-image: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Log into registry ${{ env.REGISTRY }} uses: docker/login-action@v1 with: registry: ${{ env.REGISTRY }} username: ${{ github.actor }} password: ${{ secrets.GITHUB_TOKEN }} - name: Setup Docker buildx uses: docker/setup-buildx-action@v1 - name: Extract Docker metadata id: meta uses: docker/metadata-action@v2 with: images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} # - name: Build and Push Versioned Docker Image # id: build-and-push # uses: docker/build-push-action@v2 # if: ${{ github.ref != 'refs/heads/main' }} # with: # context: ./build-push-image # push: true # tags: ${{ steps.meta.outputs.tags }} # labels: ${{ steps.meta.outputs.labels }} - name: Build and Push Latest Docker Image id: build-and-push-latest uses: docker/build-push-action@v2 if: ${{ github.ref == 'refs/heads/main' }} with: context: ./build-push-image push: true tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest labels: ${{ steps.meta.outputs.labels }}","title":"Build and Push Image to ghcr"},{"location":"gh-actions/build-push-image/#github-actions-build-and-push-image-to-repository-package-manager","text":"No PAT required. This github action uses the GITHUB_TOKEN , available to each repository. # Checkout the files from the Git repository. # Login to the ghcr.io container registry. # Setup Docker # Get metadata for use later in Docker. This avoids having to do manual work to set up the tags and labels for the Docker images. # Finally, build the image and push it. The build and push has two steps name: Docker Build & Publish to GitHub Container Registry on: push: branches: - 'main' # anything under a build/ folder will be used as testing the build processes. # - 'build/*' tags: - 'v*' workflow_dispatch: inputs: git-ref: description: Git Ref (Optional) required: false env: REGISTRY: ghcr.io IMAGE_NAME: ${{ github.repository }} jobs: build-and-push-docker-image: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Log into registry ${{ env.REGISTRY }} uses: docker/login-action@v1 with: registry: ${{ env.REGISTRY }} username: ${{ github.actor }} password: ${{ secrets.GITHUB_TOKEN }} - name: Setup Docker buildx uses: docker/setup-buildx-action@v1 - name: Extract Docker metadata id: meta uses: docker/metadata-action@v2 with: images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} # - name: Build and Push Versioned Docker Image # id: build-and-push # uses: docker/build-push-action@v2 # if: ${{ github.ref != 'refs/heads/main' }} # with: # context: ./build-push-image # push: true # tags: ${{ steps.meta.outputs.tags }} # labels: ${{ steps.meta.outputs.labels }} - name: Build and Push Latest Docker Image id: build-and-push-latest uses: docker/build-push-action@v2 if: ${{ github.ref == 'refs/heads/main' }} with: context: ./build-push-image push: true tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest labels: ${{ steps.meta.outputs.labels }}","title":"Github Actions Build and Push Image to Repository Package Manager"},{"location":"gh-actions/cachetest/","text":"Caching Docker builds in github actions: Which approach is fastest? https://dev.to/dtinth/caching-docker-builds-in-github-actions-which-approach-is-the-fastest-a-research-18ei Abstract: In this post, I experimented with 6 different approaches for caching Docker builds in GitHub Actions to speed up the build process and compared the results. After trying out every approach, 10 times each, the results show that using GitHub Packages\u2019 Docker registry as a build cache, as opposed to GitHub Actions\u2019 built-in cache, yields the highest performance gain. Unlike self-hosted runners like Jenkins, most cloud-hosted build runners are stateless, providing us with a pristine environment each run. We cannot keep files from the previous runs around; anything that needs to be persisted must be externalized. GitHub Actions has a built-in cache to help do this. But there are many ways of creating that cache ( docker save and docker load first comes to mind). Will the performance gains outweight the overhead caused by saving and loading caches? Are there more approaches other than using GitHub Action\u2019s built-in cache? That\u2019s what this research is about. Dockerfile FROM node:14.21.2 RUN yarn create react-app my-react-app RUN cd my-react-app && yarn build RUN npm install -g @vue/cli && (yes | vue create my-vue-app --default) RUN cd my-vue-app && yarn build RUN mkdir -p my-tests && cd my-tests && yarn add playwright # test # test # test # test # test # test # test # test # test # test","title":"Cache Testing"},{"location":"gh-actions/cachetest/#caching-docker-builds-in-github-actions-which-approach-is-fastest","text":"https://dev.to/dtinth/caching-docker-builds-in-github-actions-which-approach-is-the-fastest-a-research-18ei","title":"Caching Docker builds in github actions: Which approach is fastest?"},{"location":"gh-actions/cachetest/#abstract","text":"In this post, I experimented with 6 different approaches for caching Docker builds in GitHub Actions to speed up the build process and compared the results. After trying out every approach, 10 times each, the results show that using GitHub Packages\u2019 Docker registry as a build cache, as opposed to GitHub Actions\u2019 built-in cache, yields the highest performance gain. Unlike self-hosted runners like Jenkins, most cloud-hosted build runners are stateless, providing us with a pristine environment each run. We cannot keep files from the previous runs around; anything that needs to be persisted must be externalized. GitHub Actions has a built-in cache to help do this. But there are many ways of creating that cache ( docker save and docker load first comes to mind). Will the performance gains outweight the overhead caused by saving and loading caches? Are there more approaches other than using GitHub Action\u2019s built-in cache? That\u2019s what this research is about.","title":"Abstract:"},{"location":"gh-actions/cachetest/#dockerfile","text":"FROM node:14.21.2 RUN yarn create react-app my-react-app RUN cd my-react-app && yarn build RUN npm install -g @vue/cli && (yes | vue create my-vue-app --default) RUN cd my-vue-app && yarn build RUN mkdir -p my-tests && cd my-tests && yarn add playwright # test # test # test # test # test # test # test # test # test # test","title":"Dockerfile"},{"location":"gh-actions/sbom/","text":"SBOM Software Bill of Material with Docker Container and Github Actions Generate an SBOM from within a GitHub Actions workflow. In this way, the SBOM is shipped with the container image and is made available without having to scan the image each time. What is SBOM? From Wikipedia: A software bill of materials (SBOM) is a list of components in a piece of software. Software vendors often create products by assembling open source and commercial software components. The SBOM describes the components in a product. It is analogous to a list of ingredients on food packaging: where you might consult a label to avoid foods that may cause an allergies, SBOMs can help companies avoid consumption of software that could harm their organization. The concept of a BOM is well-established in traditional manufacturing as part of supply chain management. A manufacturer uses a BOM to track the parts it uses to create a product. If defects are later found in a specific part, the BOM makes it easy to locate affected products. Crane crane is a tool for interacting with remote images and registries. Install crane sudo snap install go --classic ## Install go go install github.com/google/go-containerregistry/cmd/crane@latest curl -sL \"https://github.com/google/go-containerregistry/releases/latest/download/go-containerregistry_Linux_x86_64.tar.gz\" > go-containerregistry.tar.gz curl -sL https://api.github.com/repos/konveyor/crane/releases/latest | jq -r \".assets[] | select(.name | contains(\\\"amd64-linux\\\")) | .browser_download_url\" | wget -i- Imagine you have the following Dockerfile: FROM alpine:3.17.0 RUN apk add --no-cache curl ca-certificates CMD [\"curl\", \"https://www.google.com\"] I know that there's a vulnerability in alpine 3.17.0 in the OpenSSL library. How do I know that? I recently updated every OpenFaaS Pro component to use 3.17.1 to fix a specific vulnerability. Now a typical workflow for this Dockerfile would look like the below: name: build on: push: branches: [ master, main ] pull_request: branches: [ master, main ] permissions: actions: read checks: write contents: read packages: write jobs: publish: runs-on: ubuntu-latest steps: - uses: actions/checkout@master with: fetch-depth: 1 - name: Build Docker image run: docker build . --file Dockerfile.sbom --tag my-image-name:$(date +%s) # - name: Set up Docker Buildx # uses: docker/setup-buildx-action@v2 # - name: Login to Docker Registry # uses: docker/login-action@v2 # with: # username: ${{ github.repository_owner }} # password: ${{ secrets.GITHUB_TOKEN }} # registry: ghcr.io - name: Publish image uses: docker/build-push-action@v3 with: build-args: | GitCommit=${{ github.sha }} outputs: \"type=registry,push=true\" tags: | ghcr.io/alexellis/gha-sbom:${{ github.sha }} Upon each commit, an image is published to GitHub's Container Registry with the image name of: ghcr.io/np-completed/gha-sbom:SHA . To generate an SBOM, we just need to update the docker/build-push-action to use the sbom flag: - name: Local build id: local_build uses: docker/build-push-action@v3 with: sbom: true provenance: false View the SBOM: syft ghcr.io/np-completed/gha-sbom:840fc5b2f3c94099e5dc74434a6bbcc156407a6f \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] NAME VERSION TYPE alpine-baselayout 3.4.0-r0 apk alpine-baselayout-data 3.4.0-r0 apk alpine-keys 2.4-r1 apk apk-tools 2.12.10-r1 apk brotli-libs 1.0.9-r9 apk busybox 1.35.0 binary busybox 1.35.0-r29 apk busybox-binsh 1.35.0-r29 apk ca-certificates 20220614-r4 apk ca-certificates-bundle 20220614-r2 apk curl 7.87.0-r1 apk libc-utils 0.7.2-r3 apk libcrypto3 3.0.7-r0 apk libcurl 7.87.0-r1 apk libssl3 3.0.7-r0 apk musl 1.2.3-r4 apk musl-utils 1.2.3-r4 apk nghttp2-libs 1.51.0-r0 apk scanelf 1.3.5-r1 apk ssl_client 1.35.0-r29 apk zlib 1.2.13-r0 apk grype ghcr.io/np-completed/gha-sbom:840fc5b2f3c94099e5dc74434a6bbcc156407a6f \u2714 Vulnerability DB [no update available] \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] \u2714 Scanned image [2 vulnerabilities] NAME INSTALLED FIXED-IN TYPE VULNERABILITY SEVERITY libcrypto3 3.0.7-r0 3.0.7-r2 apk CVE-2022-3996 High libssl3 3.0.7-r0 3.0.7-r2 apk CVE-2022-3996 High The image: alpine:3.17.0 contains two High vulnerabilities, and from reading the notes, we can see that both have been fixed. We can resolve the issue by changing the Dockerfile to use alpine:latest instead, and re-running the build. syft ghcr.io/np-completed/gha-sbom:1a7f4c36bad2a506d7403fe4dd904a356bd8bbfa \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] NAME VERSION TYPE alpine-baselayout 3.4.0-r0 apk alpine-baselayout-data 3.4.0-r0 apk alpine-keys 2.4-r1 apk apk-tools 2.12.10-r1 apk brotli-libs 1.0.9-r9 apk busybox 1.35.0 binary busybox 1.35.0-r29 apk busybox-binsh 1.35.0-r29 apk ca-certificates 20220614-r4 apk ca-certificates-bundle 20220614-r4 apk curl 7.87.0-r1 apk libc-utils 0.7.2-r3 apk libcrypto3 3.0.7-r2 apk libcurl 7.87.0-r1 apk libssl3 3.0.7-r2 apk musl 1.2.3-r4 apk musl-utils 1.2.3-r4 apk nghttp2-libs 1.51.0-r0 apk scanelf 1.3.5-r1 apk ssl_client 1.35.0-r29 apk zlib 1.2.13-r0 apk grype ghcr.io/np-completed/gha-sbom:1a7f4c36bad2a506d7403fe4dd904a356bd8bbfa \u2714 Vulnerability DB [no update available] \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] \u2714 Scanned image [0 vulnerabilities] Install Grype and Syft Anchore provides commercial solutions for creating, managing and inspecting SBOMs, however they also have two very useful open source tools that we can try out for free. syft - a command line tool that can be used to generate an SBOM for a container image. grype - a command line tool that can be used to scan an SBOM for vulnerabilities. Grype Run the following command to install the latest version of Grype to the /usr/local/bin directory: wget -qO - https://raw.githubusercontent.com/anchore/grype/main/install.sh | sudo bash -s -- -b /usr/local/bin ## Verify install worked grype version Run the grype command and specify the container image as argument: $ grype ubuntu:latest \u2714 Vulnerability DB [updated] \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [101 packages] \u2714 Scanned image [18 vulnerabilities] NAME INSTALLED FIXED-IN TYPE VULNERABILITY SEVERITY bash 5.1-6ubuntu1 deb CVE-2022-3715 Low coreutils 8.32-4.1ubuntu1 deb CVE-2016-2781 Low gpgv 2.2.27-3ubuntu2.1 deb CVE-2022-3219 Low libc-bin 2.35-0ubuntu3.1 deb CVE-2016-20013 Negligible libc6 2.35-0ubuntu3.1 deb CVE-2016-20013 Negligible libgssapi-krb5-2 1.19.2-2 deb CVE-2022-42898 Medium libk5crypto3 1.19.2-2 deb CVE-2022-42898 Medium Uninstall grype sudo rm -rf /usr/local/bin/grype and remove vulnerabilities database rm -rf ~/.cache/grype Install Syft Run the following command to install the latest version of Syft to the /usr/local/bin directory: wget -qO - https://raw.githubusercontent.com/anchore/syft/main/install.sh | sudo bash -s -- -b /usr/local/bin ## Verify install worked syft version Application: syft Version: 0.68.1 JsonSchemaVersion: 6.2.0 BuildDate: 2023-01-25T17:46:33Z GitCommit: 4c0aef09b8d7fb78200b04416f474b90b79370de GitDescription: v0.68.1 Platform: linux/amd64 GoVersion: go1.18.10 Compiler: gc Test Syft Generate an SBOM for a container image: syft <image> The above output includes only software that is visible in the container (i.e., the squashed representation of the image). To include software from all image layers in the SBOM, regardless of its presence in the final image, provide --scope all-layers : syft <image> --scope all-layers","title":"Software Bill of Materials"},{"location":"gh-actions/sbom/#sbom-software-bill-of-material-with-docker-container-and-github-actions","text":"Generate an SBOM from within a GitHub Actions workflow. In this way, the SBOM is shipped with the container image and is made available without having to scan the image each time.","title":"SBOM Software Bill of Material with Docker Container and Github Actions"},{"location":"gh-actions/sbom/#what-is-sbom","text":"From Wikipedia: A software bill of materials (SBOM) is a list of components in a piece of software. Software vendors often create products by assembling open source and commercial software components. The SBOM describes the components in a product. It is analogous to a list of ingredients on food packaging: where you might consult a label to avoid foods that may cause an allergies, SBOMs can help companies avoid consumption of software that could harm their organization. The concept of a BOM is well-established in traditional manufacturing as part of supply chain management. A manufacturer uses a BOM to track the parts it uses to create a product. If defects are later found in a specific part, the BOM makes it easy to locate affected products.","title":"What is SBOM?"},{"location":"gh-actions/sbom/#crane","text":"crane is a tool for interacting with remote images and registries. Install crane sudo snap install go --classic ## Install go go install github.com/google/go-containerregistry/cmd/crane@latest curl -sL \"https://github.com/google/go-containerregistry/releases/latest/download/go-containerregistry_Linux_x86_64.tar.gz\" > go-containerregistry.tar.gz curl -sL https://api.github.com/repos/konveyor/crane/releases/latest | jq -r \".assets[] | select(.name | contains(\\\"amd64-linux\\\")) | .browser_download_url\" | wget -i-","title":"Crane"},{"location":"gh-actions/sbom/#imagine-you-have-the-following-dockerfile","text":"FROM alpine:3.17.0 RUN apk add --no-cache curl ca-certificates CMD [\"curl\", \"https://www.google.com\"] I know that there's a vulnerability in alpine 3.17.0 in the OpenSSL library. How do I know that? I recently updated every OpenFaaS Pro component to use 3.17.1 to fix a specific vulnerability. Now a typical workflow for this Dockerfile would look like the below: name: build on: push: branches: [ master, main ] pull_request: branches: [ master, main ] permissions: actions: read checks: write contents: read packages: write jobs: publish: runs-on: ubuntu-latest steps: - uses: actions/checkout@master with: fetch-depth: 1 - name: Build Docker image run: docker build . --file Dockerfile.sbom --tag my-image-name:$(date +%s) # - name: Set up Docker Buildx # uses: docker/setup-buildx-action@v2 # - name: Login to Docker Registry # uses: docker/login-action@v2 # with: # username: ${{ github.repository_owner }} # password: ${{ secrets.GITHUB_TOKEN }} # registry: ghcr.io - name: Publish image uses: docker/build-push-action@v3 with: build-args: | GitCommit=${{ github.sha }} outputs: \"type=registry,push=true\" tags: | ghcr.io/alexellis/gha-sbom:${{ github.sha }} Upon each commit, an image is published to GitHub's Container Registry with the image name of: ghcr.io/np-completed/gha-sbom:SHA . To generate an SBOM, we just need to update the docker/build-push-action to use the sbom flag: - name: Local build id: local_build uses: docker/build-push-action@v3 with: sbom: true provenance: false View the SBOM: syft ghcr.io/np-completed/gha-sbom:840fc5b2f3c94099e5dc74434a6bbcc156407a6f \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] NAME VERSION TYPE alpine-baselayout 3.4.0-r0 apk alpine-baselayout-data 3.4.0-r0 apk alpine-keys 2.4-r1 apk apk-tools 2.12.10-r1 apk brotli-libs 1.0.9-r9 apk busybox 1.35.0 binary busybox 1.35.0-r29 apk busybox-binsh 1.35.0-r29 apk ca-certificates 20220614-r4 apk ca-certificates-bundle 20220614-r2 apk curl 7.87.0-r1 apk libc-utils 0.7.2-r3 apk libcrypto3 3.0.7-r0 apk libcurl 7.87.0-r1 apk libssl3 3.0.7-r0 apk musl 1.2.3-r4 apk musl-utils 1.2.3-r4 apk nghttp2-libs 1.51.0-r0 apk scanelf 1.3.5-r1 apk ssl_client 1.35.0-r29 apk zlib 1.2.13-r0 apk grype ghcr.io/np-completed/gha-sbom:840fc5b2f3c94099e5dc74434a6bbcc156407a6f \u2714 Vulnerability DB [no update available] \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] \u2714 Scanned image [2 vulnerabilities] NAME INSTALLED FIXED-IN TYPE VULNERABILITY SEVERITY libcrypto3 3.0.7-r0 3.0.7-r2 apk CVE-2022-3996 High libssl3 3.0.7-r0 3.0.7-r2 apk CVE-2022-3996 High The image: alpine:3.17.0 contains two High vulnerabilities, and from reading the notes, we can see that both have been fixed. We can resolve the issue by changing the Dockerfile to use alpine:latest instead, and re-running the build. syft ghcr.io/np-completed/gha-sbom:1a7f4c36bad2a506d7403fe4dd904a356bd8bbfa \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] NAME VERSION TYPE alpine-baselayout 3.4.0-r0 apk alpine-baselayout-data 3.4.0-r0 apk alpine-keys 2.4-r1 apk apk-tools 2.12.10-r1 apk brotli-libs 1.0.9-r9 apk busybox 1.35.0 binary busybox 1.35.0-r29 apk busybox-binsh 1.35.0-r29 apk ca-certificates 20220614-r4 apk ca-certificates-bundle 20220614-r4 apk curl 7.87.0-r1 apk libc-utils 0.7.2-r3 apk libcrypto3 3.0.7-r2 apk libcurl 7.87.0-r1 apk libssl3 3.0.7-r2 apk musl 1.2.3-r4 apk musl-utils 1.2.3-r4 apk nghttp2-libs 1.51.0-r0 apk scanelf 1.3.5-r1 apk ssl_client 1.35.0-r29 apk zlib 1.2.13-r0 apk grype ghcr.io/np-completed/gha-sbom:1a7f4c36bad2a506d7403fe4dd904a356bd8bbfa \u2714 Vulnerability DB [no update available] \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] \u2714 Scanned image [0 vulnerabilities]","title":"Imagine you have the following Dockerfile:"},{"location":"gh-actions/sbom/#install-grype-and-syft","text":"Anchore provides commercial solutions for creating, managing and inspecting SBOMs, however they also have two very useful open source tools that we can try out for free. syft - a command line tool that can be used to generate an SBOM for a container image. grype - a command line tool that can be used to scan an SBOM for vulnerabilities.","title":"Install Grype and Syft"},{"location":"gh-actions/sbom/#grype","text":"Run the following command to install the latest version of Grype to the /usr/local/bin directory: wget -qO - https://raw.githubusercontent.com/anchore/grype/main/install.sh | sudo bash -s -- -b /usr/local/bin ## Verify install worked grype version Run the grype command and specify the container image as argument: $ grype ubuntu:latest \u2714 Vulnerability DB [updated] \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [101 packages] \u2714 Scanned image [18 vulnerabilities] NAME INSTALLED FIXED-IN TYPE VULNERABILITY SEVERITY bash 5.1-6ubuntu1 deb CVE-2022-3715 Low coreutils 8.32-4.1ubuntu1 deb CVE-2016-2781 Low gpgv 2.2.27-3ubuntu2.1 deb CVE-2022-3219 Low libc-bin 2.35-0ubuntu3.1 deb CVE-2016-20013 Negligible libc6 2.35-0ubuntu3.1 deb CVE-2016-20013 Negligible libgssapi-krb5-2 1.19.2-2 deb CVE-2022-42898 Medium libk5crypto3 1.19.2-2 deb CVE-2022-42898 Medium","title":"Grype"},{"location":"gh-actions/sbom/#uninstall-grype","text":"sudo rm -rf /usr/local/bin/grype and remove vulnerabilities database rm -rf ~/.cache/grype","title":"Uninstall grype"},{"location":"gh-actions/sbom/#install-syft","text":"Run the following command to install the latest version of Syft to the /usr/local/bin directory: wget -qO - https://raw.githubusercontent.com/anchore/syft/main/install.sh | sudo bash -s -- -b /usr/local/bin ## Verify install worked syft version Application: syft Version: 0.68.1 JsonSchemaVersion: 6.2.0 BuildDate: 2023-01-25T17:46:33Z GitCommit: 4c0aef09b8d7fb78200b04416f474b90b79370de GitDescription: v0.68.1 Platform: linux/amd64 GoVersion: go1.18.10 Compiler: gc","title":"Install Syft"},{"location":"gh-actions/sbom/#test-syft","text":"Generate an SBOM for a container image: syft <image> The above output includes only software that is visible in the container (i.e., the squashed representation of the image). To include software from all image layers in the SBOM, regardless of its presence in the final image, provide --scope all-layers : syft <image> --scope all-layers","title":"Test Syft"},{"location":"hosting-and-deployment/enable_github_pages/","text":"Enable Github Pages Github pages requires permissions to be enabled but the process is pretty easy. Create a public repository Navigate to Settings > Pages Configure the branch and build directory. \u2757 github.io requires using the owner name to make the web site visible.","title":"Enable GH Pages"},{"location":"hosting-and-deployment/enable_github_pages/#enable-github-pages","text":"Github pages requires permissions to be enabled but the process is pretty easy. Create a public repository Navigate to Settings > Pages Configure the branch and build directory. \u2757 github.io requires using the owner name to make the web site visible.","title":"Enable Github Pages"},{"location":"hosting-and-deployment/gh-pages-private-repo/","text":"Github Pages Private Source Code Github pages are great, it provides a free static page hosting, but the only caveat is the repository has to be public repository. And, if you want to keep your source private, you will have to opt for premium plans to host pages from private repository. Here is what I have done, github allows unlimited private repositories, so I created a new private repo where I kept my source code and another repo where my site is hosted. Create Personal Token Create a personal access token. Navigate to Settings and create a PAT. Select Developer settings Select Personal access tokens Now generate a new token, with repo permissions. Once you are done copy the generated token, we will need to set this token during our build. Create secret in private repository Go to your private repo and click the settings: Create github action in private repoPermalink This is where the magic begins, we will build a github action in our private repo. You will need to create a file at .github/workflows/ci.yml name: Build & Publish on: push: branches: [ gh_pages ] pull_request: branches: [ gh_pages ] jobs: build: runs-on: ubuntu-latest steps: - name: Checkout local code uses: actions/checkout@v3 with: path: code token: ${{ secrets.GH_PAGES}} ref: gh_pages # - name: Show Directory Files # run : | # cd code # ls -la - name: python uses: actions/setup-python@v4 with: python-version: \"3.10\" - name: Checkout public repo site uses: actions/checkout@v3 with: token: ${{ secrets.GH_PAGES}} repository: np-completed/np-completed.github.io ref: gh_pages path: site - name: Install dependencies run: python3 -m pip install -r code/requirements.txt - name: Build website run: mkdocs build --config-file code/mkdocs.yml - name: Clean Website run: | pushd site git rm -rf . popd - name: Copy website run : | pushd site # cp -rvf ../code/build/* . cp -rvf ../code/site/* . popd ls -la site/ # ls -la code/site/ - name: Deploy and Publish run: | git config --global user.email \"${GITHUB_ACTOR}@users.noreply.github.com\" git config --global user.name \"github-actions\" pushd site git add . git commit -m \"mkdocs build from Action ${GITHUB_SHA}\" git push origin gh_pages popd Each push changes to the private repository triggers the github action. Next, the GH action job will be executed, to build and publish the site to the public repo without exposing your source code.","title":"Private Repo with GH Pages"},{"location":"hosting-and-deployment/gh-pages-private-repo/#github-pages-private-source-code","text":"Github pages are great, it provides a free static page hosting, but the only caveat is the repository has to be public repository. And, if you want to keep your source private, you will have to opt for premium plans to host pages from private repository. Here is what I have done, github allows unlimited private repositories, so I created a new private repo where I kept my source code and another repo where my site is hosted.","title":"Github Pages Private Source Code"},{"location":"hosting-and-deployment/gh-pages-private-repo/#create-personal-token","text":"Create a personal access token. Navigate to Settings and create a PAT. Select Developer settings Select Personal access tokens Now generate a new token, with repo permissions. Once you are done copy the generated token, we will need to set this token during our build.","title":"Create Personal Token"},{"location":"hosting-and-deployment/gh-pages-private-repo/#create-secret-in-private-repository","text":"Go to your private repo and click the settings:","title":"Create secret in private repository"},{"location":"hosting-and-deployment/gh-pages-private-repo/#create-github-action-in-private-repopermalink","text":"This is where the magic begins, we will build a github action in our private repo. You will need to create a file at .github/workflows/ci.yml name: Build & Publish on: push: branches: [ gh_pages ] pull_request: branches: [ gh_pages ] jobs: build: runs-on: ubuntu-latest steps: - name: Checkout local code uses: actions/checkout@v3 with: path: code token: ${{ secrets.GH_PAGES}} ref: gh_pages # - name: Show Directory Files # run : | # cd code # ls -la - name: python uses: actions/setup-python@v4 with: python-version: \"3.10\" - name: Checkout public repo site uses: actions/checkout@v3 with: token: ${{ secrets.GH_PAGES}} repository: np-completed/np-completed.github.io ref: gh_pages path: site - name: Install dependencies run: python3 -m pip install -r code/requirements.txt - name: Build website run: mkdocs build --config-file code/mkdocs.yml - name: Clean Website run: | pushd site git rm -rf . popd - name: Copy website run : | pushd site # cp -rvf ../code/build/* . cp -rvf ../code/site/* . popd ls -la site/ # ls -la code/site/ - name: Deploy and Publish run: | git config --global user.email \"${GITHUB_ACTOR}@users.noreply.github.com\" git config --global user.name \"github-actions\" pushd site git add . git commit -m \"mkdocs build from Action ${GITHUB_SHA}\" git push origin gh_pages popd Each push changes to the private repository triggers the github action. Next, the GH action job will be executed, to build and publish the site to the public repo without exposing your source code.","title":"Create github action in private repoPermalink"},{"location":"hosting-and-deployment/gh-pages/","text":"Host on GitHub Pages Demo site on GitHub Pages (build & deploy with GitHub Actions) Build and deploy with GitHub Actions peaceiris/actions-gh-pages: GitHub Actions for deploying to GitHub Pages with Static Site Generators Go to the repository and read the latest README.md for more details. Build and deploy with mkdocs gh-deploy pipenv pipenv run deploy # OR pipenv shell mkdocs gh-deploy # OR pipenv run mkdocs gh-deploy","title":"Github Pages"},{"location":"hosting-and-deployment/gh-pages/#host-on-github-pages","text":"Demo site on GitHub Pages (build & deploy with GitHub Actions)","title":"Host on GitHub Pages"},{"location":"hosting-and-deployment/gh-pages/#build-and-deploy-with-github-actions","text":"peaceiris/actions-gh-pages: GitHub Actions for deploying to GitHub Pages with Static Site Generators Go to the repository and read the latest README.md for more details.","title":"Build and deploy with GitHub Actions"},{"location":"hosting-and-deployment/gh-pages/#build-and-deploy-with-mkdocs-gh-deploy","text":"","title":"Build and deploy with mkdocs gh-deploy"},{"location":"hosting-and-deployment/gh-pages/#pipenv","text":"pipenv run deploy # OR pipenv shell mkdocs gh-deploy # OR pipenv run mkdocs gh-deploy","title":"pipenv"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/","text":"Securing Amazon SageMaker Studio internet traffic using AWS Network Firewall Building secure machine learning environments with Amazon SageMaker Securing Amazon SageMaker Studio connectivity using a private VPC. Configuring Amazon SageMaker Studio for teams and groups with complete resource isolation Securing Amazon SageMaker Studio connectivity using a private VPC Background Amazon SageMaker Studio is a web-based fully integrated development environment (IDE) where you can perform end-to-end machine learning (ML) development to prepare data and build, train, and deploy models. One of these fundamental security features allows you to launch Studio in your own Amazon Virtual Private Cloud (Amazon VPC). This allows you to control, monitor, and inspect network traffic within and outside your VPC using standard AWS networking and security capabilities. For more information, see Securing Amazon SageMaker Studio connectivity using a private VPC. SM Studio users may want to provide internet access but also have some controls such as domain name or URL filtering and allow access to only specific public repositories and websites, possibly packet inspection, or other network traffic-related security controls. For these cases, AWS Network Firewall and NAT gateway-based deployment may provide a suitable use case. In this post, I outline the use of network firewall to build a secure and compliant environment by restricting and monitoring internet access, inspecting traffic, and using stateless and stateful firewall engine rules to control the network flow between Studio notebooks and the internet. Depending on your security, compliance, and governance rules, you may not need to or cannot completely block internet access from Studio and your AI and ML workloads. You may have requirements beyond the scope of network security controls implemented by security groups and network access control lists (ACLs), such as application protocol protection, deep packet inspection, domain name filtering, and intrusion prevention system (IPS). Your network traffic controls may also require many more rules compared to what is currently supported in security groups and network ACLs. In these scenarios, you can use Network Firewall\u2014a managed network firewall and IPS for your VPC. Solution overview Sagemaker Studio deployed in a VPC, provides internet access control, using the parameter AppNetworkAccessType (via the Amazon SageMaker API ) or by selecting your preference on the console when you create a Studio domain. If you select Public internet Only ( PublicInternetOnly ), all the ingress and egress internet traffic from Amazon SageMaker notebooks flows through an AWS managed internet gateway attached to a VPC in your SageMaker account. The following diagram shows this network configuration. Studio provides public internet egress through a platform-managed VPC for data scientists to download notebooks, packages, and datasets. Traffic to the attached Amazon Elastic File System (Amazon EFS) volume always goes through the customer VPC and never through the public internet egress. To use your own control flow for the internet traffic, like a NAT or internet gateway, you must set the AppNetworkAccessType parameter to VpcOnly (or select VPC Only on the console). When you launch your app, this creates an elastic network interface in the specified subnets in your VPC. You can apply all available layers of security control\u2014 security groups , network ACLs , VPC endpoints , AWS PrivateLink , or Network Firewall endpoints \u2014to the internal network and internet traffic to exercise fine-grained control of network access in Studio. The following diagram shows the VpcOnly network configuration. In this mode, the direct internet access to or from notebooks is completely disabled, and all traffic is routed through an elastic network interface in your private VPC. This also includes traffic from Studio UI widgets and interfaces, such as Experiments , Autopilot , and Model Monitor , to their respective backend SageMaker APIs. VPC only option The solution in this post uses the VpcOnly option and deploys the Studio domain into a VPC with three subnets: SageMaker subnet \u2013 Hosts all Studio workloads. All ingress and egress network flow is controlled by a security group. NAT subnet \u2013 Contains a NAT gateway. We use the NAT gateway to access the internet without exposing any private IP addresses from our private network. Network Firewall subnet \u2013 Contains a Network Firewall endpoint. The route tables are configured so that all inbound and outbound external network traffic is routed via Network Firewall. You can configure stateful and stateless Network Firewall policies to inspect, monitor, and control the traffic. The following diagram shows the overview of the solution architecture and the deployed components. SageMaker resources Create a SageMaker domain and user profile. The solution uses only one Availability Zone and is not highly available. A best practice is to use a Multi-AZ configuration for any production deployment. We create an allow domain list rule to allow internet access to the specified network domains only and block traffic to any domain not on the allow list. AWS CloudFormation resources The source code and AWS CloudFormation template for solution deployment are provided in the GitHub repository . Network Firewall is a Regional service; for more information on Region availability, see the AWS Region Table . To start experimenting with the Network Firewall and stateful rules, you need first to deploy the provided CloudFormation template to the AWS account. Clone the GitHub repository: Create an S3 bucket in the Region where you deploy the solution: aws s3 mb s3://<your s3 bucket name> You can skip this step if you already have an S3 bucket. Deploy the CloudFormation stack: make deploy CFN_ARTEFACT_S3_BUCKET=<your s3 bucket name> The deployment procedure packages the CloudFormation template and copies it to the S3 bucket your provided. Then the CloudFormation template is deployed from the S3 bucket to your AWS account. The stack deploys all the needed resources like VPC, network devices, route tables, security groups, S3 buckets, IAM policies and roles, and VPC endpoints, and also creates a new Studio domain and user profile. When the deployment is complete, you can see the full list of stack output values by running the following command in terminal: aws cloudformation describe-stacks \\ --stack-name sagemaker-studio-demo \\ --output table \\ --query \"Stacks[0].Outputs[*].[OutputKey, OutputValue]\" Launch Studio via the SageMaker console. Experiment with Network Firewall Now you can learn how to control the internet inbound and outbound access with Network Firewall. In this section, we discuss the initial setup, accessing resources not on the allow list, adding domains to the allow list, configuring logging, and additional firewall rules. Initial setup The solution deploys a Network Firewall policy with a stateful rule group with an allow domain list. This policy is attached to the Network Firewall. All inbound and outbound internet traffic is blocked now, except for the .kaggle.com domain, which is on the allow list. Let\u2019s try to access https://kaggle.com by opening a new notebook in Studio and attempting to download the front page from kaggle.com : !wget https://kaggle.com The following screenshot shows that the request succeeds because the domain is allowed by the firewall policy. Users can connect to this and only to this domain from any Studio notebook. Access resources not on the allowed domain list In the Studio notebook, try to clone any public GitHub repository, such as the following: !git clone https://github.com/pytorch/examples.git This operation times out after 5 minutes because any internet traffic except to and from the .kaggle.com domain isn\u2019t allowed and is dropped by the firewall. Add a domain to the allowed domain list To be able to run the git clone command, you must allow internet traffic to the .github.com domain. On the Amazon VPC console, choose Firewall policies. Choose the policy network-firewall-policy- . In the Stateful rule groups section, select the group rule domain-allow-sagemaker- . You can see the domain .kaggle.com on the allow list. Choose Add domain. Enter .github.com . Choose Save. You now have two names on the allow domain list. Firewall policy is propagated in real time to Network Firewall and your changes take effect immediately. Any inbound or outbound traffic from or to these domains is now allowed by the firewall and all other traffic is dropped. To validate the new configuration, go to your Studio notebook and try to clone the same GitHub repository again: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git The operation succeeds this time\u2014Network Firewall allows access to the .github.com domain. Network Firewall logging In this section, you configure Network Firewall logging for your firewall\u2019s stateful engine. Logging gives you detailed information about network traffic, including the time that the stateful engine received a packet, detailed information about the packet, and any stateful rule action taken against the packet. The logs are published to the log destination that you configured, where you can retrieve and view them. On the Amazon VPC console, choose Firewalls . Choose your firewall. Choose the Firewall details tab. In the Logging section, choose Edit . Configure your firewall logging by selecting what log types you want to capture and providing the log destination. For this post, select Alert log type, set Log destination for alerts to CloudWatch Log group, and provide an existing or a new log group where the firewall logs are delivered. Choose Save . To check your settings, go back to Studio and try to access pypi.org to install a Python package: !pip install -U scikit-learn This command fails with ReadTimeoutError because Network Firewall drops any traffic to any domain not on the allow list (which contains only two domains: .github.com and .kaggle.com ). On the Amazon CloudWatch console , navigate to the log group and browse through the recent log streams. The pipy.org domain shows the blocked action. The log event also provides additional details such as various timestamps, protocol, port and IP details, event type, availability zone, and the firewall name. You can continue experimenting with Network Firewall by adding .pypi.org and .pythonhosted.org domains to the allowed domain list. Then validate your access to them via your Studio notebook. Additional firewall rules You can create any other stateless or stateful firewall rules and implement traffic filtering based on a standard stateful 5-tuple rule for network traffic inspection (protocol, source IP, source port, destination IP, destination port). Network Firewall also supports industry standard stateful Suricata compatible IPS rule groups. You can implement protocol-based rules to detect and block any non-standard or promiscuous usage or activity. For more information about creating and managing Network Firewall rule groups, see Rule groups in AWS Network Firewall. Additional security controls with Network Firewall In the previous section, we looked at one feature of the Network Firewall: filtering network traffic based on the domain name. In addition to stateless or stateful firewall rules, Network Firewall provides several tools and features for further security controls and monitoring: Central firewall management and visibility in AWS Firewall Manager . You can centrally manage security policies and automatically enforce mandatory security policies across existing and newly created accounts and VPCs. Network Firewall logging for the firewall\u2019s stateful engine. You can record flow and alert logs, and use the same or different logging destinations for each log type. Stateless rules to filter network traffic based on protocol, source IP addresses, ranges, source port ranges, destination IP addresses and ranges, and TCP flags. Integration into a broader set of AWS security components. For an example, see Automatically block suspicious traffic with AWS Network Firewall and Amazon GuardDuty. Integration in a diverse ecosystem of Network Firewall Partners that complement Network Firewall, enabling the deployment of a comprehensive security architecture. For example use cases, see Full VPC traffic visibility with AWS Network Firewall and Sumo Logic and Splunk Named Launch Partner of AWS Network Firewall. Build secure ML environments A robust security design normally includes multi-layer security controls for the system. For SageMaker environments and workloads, you can use the following AWS security services and concepts to secure, control, and monitor your environment: VPC and private subnets to perform secure API calls to other AWS services and restrict internet access for downloading packages. S3 bucket policies that restrict access to specific VPC endpoints. Encryption of ML model artifacts and other system artifacts that are either in transit or at rest. Requests to the SageMaker API and console are made over a Secure Sockets Layer (SSL) connection. Restricted IAM roles and policies for SageMaker runs and notebook access based on resource tags and project ID. Restricted access to Amazon public services, such as Amazon Elastic Container Registry (Amazon ECR) to VPC endpoints only. For a reference deployment architecture and ready-to-use deployable constructs for your environment, see Amazon SageMaker with Guardrails on AWS. Conclusion In this post, we showed how you can secure, log, and monitor internet ingress and egress traffic in Studio notebooks for your sensitive ML workloads using managed Network Firewall. You can use the provided CloudFormation templates to automate SageMaker deployment as part of your Infrastructure as Code (IaC) strategy. For more information about other possibilities to secure your SageMaker deployments and ML workloads, see Building secure machine learning environments with Amazon SageMaker.","title":"Secure Network Summary"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#securing-amazon-sagemaker-studio-internet-traffic-using-aws-network-firewall","text":"Building secure machine learning environments with Amazon SageMaker Securing Amazon SageMaker Studio connectivity using a private VPC. Configuring Amazon SageMaker Studio for teams and groups with complete resource isolation Securing Amazon SageMaker Studio connectivity using a private VPC","title":"Securing Amazon SageMaker Studio internet traffic using AWS Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#background","text":"Amazon SageMaker Studio is a web-based fully integrated development environment (IDE) where you can perform end-to-end machine learning (ML) development to prepare data and build, train, and deploy models. One of these fundamental security features allows you to launch Studio in your own Amazon Virtual Private Cloud (Amazon VPC). This allows you to control, monitor, and inspect network traffic within and outside your VPC using standard AWS networking and security capabilities. For more information, see Securing Amazon SageMaker Studio connectivity using a private VPC. SM Studio users may want to provide internet access but also have some controls such as domain name or URL filtering and allow access to only specific public repositories and websites, possibly packet inspection, or other network traffic-related security controls. For these cases, AWS Network Firewall and NAT gateway-based deployment may provide a suitable use case. In this post, I outline the use of network firewall to build a secure and compliant environment by restricting and monitoring internet access, inspecting traffic, and using stateless and stateful firewall engine rules to control the network flow between Studio notebooks and the internet. Depending on your security, compliance, and governance rules, you may not need to or cannot completely block internet access from Studio and your AI and ML workloads. You may have requirements beyond the scope of network security controls implemented by security groups and network access control lists (ACLs), such as application protocol protection, deep packet inspection, domain name filtering, and intrusion prevention system (IPS). Your network traffic controls may also require many more rules compared to what is currently supported in security groups and network ACLs. In these scenarios, you can use Network Firewall\u2014a managed network firewall and IPS for your VPC.","title":"Background"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#solution-overview","text":"Sagemaker Studio deployed in a VPC, provides internet access control, using the parameter AppNetworkAccessType (via the Amazon SageMaker API ) or by selecting your preference on the console when you create a Studio domain. If you select Public internet Only ( PublicInternetOnly ), all the ingress and egress internet traffic from Amazon SageMaker notebooks flows through an AWS managed internet gateway attached to a VPC in your SageMaker account. The following diagram shows this network configuration. Studio provides public internet egress through a platform-managed VPC for data scientists to download notebooks, packages, and datasets. Traffic to the attached Amazon Elastic File System (Amazon EFS) volume always goes through the customer VPC and never through the public internet egress. To use your own control flow for the internet traffic, like a NAT or internet gateway, you must set the AppNetworkAccessType parameter to VpcOnly (or select VPC Only on the console). When you launch your app, this creates an elastic network interface in the specified subnets in your VPC. You can apply all available layers of security control\u2014 security groups , network ACLs , VPC endpoints , AWS PrivateLink , or Network Firewall endpoints \u2014to the internal network and internet traffic to exercise fine-grained control of network access in Studio. The following diagram shows the VpcOnly network configuration. In this mode, the direct internet access to or from notebooks is completely disabled, and all traffic is routed through an elastic network interface in your private VPC. This also includes traffic from Studio UI widgets and interfaces, such as Experiments , Autopilot , and Model Monitor , to their respective backend SageMaker APIs.","title":"Solution overview"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#vpc-only-option","text":"The solution in this post uses the VpcOnly option and deploys the Studio domain into a VPC with three subnets: SageMaker subnet \u2013 Hosts all Studio workloads. All ingress and egress network flow is controlled by a security group. NAT subnet \u2013 Contains a NAT gateway. We use the NAT gateway to access the internet without exposing any private IP addresses from our private network. Network Firewall subnet \u2013 Contains a Network Firewall endpoint. The route tables are configured so that all inbound and outbound external network traffic is routed via Network Firewall. You can configure stateful and stateless Network Firewall policies to inspect, monitor, and control the traffic. The following diagram shows the overview of the solution architecture and the deployed components.","title":"VPC only option"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#sagemaker-resources","text":"Create a SageMaker domain and user profile. The solution uses only one Availability Zone and is not highly available. A best practice is to use a Multi-AZ configuration for any production deployment. We create an allow domain list rule to allow internet access to the specified network domains only and block traffic to any domain not on the allow list.","title":"SageMaker resources"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#aws-cloudformation-resources","text":"The source code and AWS CloudFormation template for solution deployment are provided in the GitHub repository . Network Firewall is a Regional service; for more information on Region availability, see the AWS Region Table . To start experimenting with the Network Firewall and stateful rules, you need first to deploy the provided CloudFormation template to the AWS account. Clone the GitHub repository: Create an S3 bucket in the Region where you deploy the solution: aws s3 mb s3://<your s3 bucket name> You can skip this step if you already have an S3 bucket. Deploy the CloudFormation stack: make deploy CFN_ARTEFACT_S3_BUCKET=<your s3 bucket name> The deployment procedure packages the CloudFormation template and copies it to the S3 bucket your provided. Then the CloudFormation template is deployed from the S3 bucket to your AWS account. The stack deploys all the needed resources like VPC, network devices, route tables, security groups, S3 buckets, IAM policies and roles, and VPC endpoints, and also creates a new Studio domain and user profile. When the deployment is complete, you can see the full list of stack output values by running the following command in terminal: aws cloudformation describe-stacks \\ --stack-name sagemaker-studio-demo \\ --output table \\ --query \"Stacks[0].Outputs[*].[OutputKey, OutputValue]\" Launch Studio via the SageMaker console.","title":"AWS CloudFormation resources"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#experiment-with-network-firewall","text":"Now you can learn how to control the internet inbound and outbound access with Network Firewall. In this section, we discuss the initial setup, accessing resources not on the allow list, adding domains to the allow list, configuring logging, and additional firewall rules.","title":"Experiment with Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#initial-setup","text":"The solution deploys a Network Firewall policy with a stateful rule group with an allow domain list. This policy is attached to the Network Firewall. All inbound and outbound internet traffic is blocked now, except for the .kaggle.com domain, which is on the allow list. Let\u2019s try to access https://kaggle.com by opening a new notebook in Studio and attempting to download the front page from kaggle.com : !wget https://kaggle.com The following screenshot shows that the request succeeds because the domain is allowed by the firewall policy. Users can connect to this and only to this domain from any Studio notebook.","title":"Initial setup"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#access-resources-not-on-the-allowed-domain-list","text":"In the Studio notebook, try to clone any public GitHub repository, such as the following: !git clone https://github.com/pytorch/examples.git This operation times out after 5 minutes because any internet traffic except to and from the .kaggle.com domain isn\u2019t allowed and is dropped by the firewall.","title":"Access resources not on the allowed domain list"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#add-a-domain-to-the-allowed-domain-list","text":"To be able to run the git clone command, you must allow internet traffic to the .github.com domain. On the Amazon VPC console, choose Firewall policies. Choose the policy network-firewall-policy- . In the Stateful rule groups section, select the group rule domain-allow-sagemaker- . You can see the domain .kaggle.com on the allow list. Choose Add domain. Enter .github.com . Choose Save. You now have two names on the allow domain list. Firewall policy is propagated in real time to Network Firewall and your changes take effect immediately. Any inbound or outbound traffic from or to these domains is now allowed by the firewall and all other traffic is dropped. To validate the new configuration, go to your Studio notebook and try to clone the same GitHub repository again: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git The operation succeeds this time\u2014Network Firewall allows access to the .github.com domain.","title":"Add a domain to the allowed domain list"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#network-firewall-logging","text":"In this section, you configure Network Firewall logging for your firewall\u2019s stateful engine. Logging gives you detailed information about network traffic, including the time that the stateful engine received a packet, detailed information about the packet, and any stateful rule action taken against the packet. The logs are published to the log destination that you configured, where you can retrieve and view them. On the Amazon VPC console, choose Firewalls . Choose your firewall. Choose the Firewall details tab. In the Logging section, choose Edit . Configure your firewall logging by selecting what log types you want to capture and providing the log destination. For this post, select Alert log type, set Log destination for alerts to CloudWatch Log group, and provide an existing or a new log group where the firewall logs are delivered. Choose Save . To check your settings, go back to Studio and try to access pypi.org to install a Python package: !pip install -U scikit-learn This command fails with ReadTimeoutError because Network Firewall drops any traffic to any domain not on the allow list (which contains only two domains: .github.com and .kaggle.com ). On the Amazon CloudWatch console , navigate to the log group and browse through the recent log streams. The pipy.org domain shows the blocked action. The log event also provides additional details such as various timestamps, protocol, port and IP details, event type, availability zone, and the firewall name. You can continue experimenting with Network Firewall by adding .pypi.org and .pythonhosted.org domains to the allowed domain list. Then validate your access to them via your Studio notebook.","title":"Network Firewall logging"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#additional-firewall-rules","text":"You can create any other stateless or stateful firewall rules and implement traffic filtering based on a standard stateful 5-tuple rule for network traffic inspection (protocol, source IP, source port, destination IP, destination port). Network Firewall also supports industry standard stateful Suricata compatible IPS rule groups. You can implement protocol-based rules to detect and block any non-standard or promiscuous usage or activity. For more information about creating and managing Network Firewall rule groups, see Rule groups in AWS Network Firewall.","title":"Additional firewall rules"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#additional-security-controls-with-network-firewall","text":"In the previous section, we looked at one feature of the Network Firewall: filtering network traffic based on the domain name. In addition to stateless or stateful firewall rules, Network Firewall provides several tools and features for further security controls and monitoring: Central firewall management and visibility in AWS Firewall Manager . You can centrally manage security policies and automatically enforce mandatory security policies across existing and newly created accounts and VPCs. Network Firewall logging for the firewall\u2019s stateful engine. You can record flow and alert logs, and use the same or different logging destinations for each log type. Stateless rules to filter network traffic based on protocol, source IP addresses, ranges, source port ranges, destination IP addresses and ranges, and TCP flags. Integration into a broader set of AWS security components. For an example, see Automatically block suspicious traffic with AWS Network Firewall and Amazon GuardDuty. Integration in a diverse ecosystem of Network Firewall Partners that complement Network Firewall, enabling the deployment of a comprehensive security architecture. For example use cases, see Full VPC traffic visibility with AWS Network Firewall and Sumo Logic and Splunk Named Launch Partner of AWS Network Firewall.","title":"Additional security controls with Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#build-secure-ml-environments","text":"A robust security design normally includes multi-layer security controls for the system. For SageMaker environments and workloads, you can use the following AWS security services and concepts to secure, control, and monitor your environment: VPC and private subnets to perform secure API calls to other AWS services and restrict internet access for downloading packages. S3 bucket policies that restrict access to specific VPC endpoints. Encryption of ML model artifacts and other system artifacts that are either in transit or at rest. Requests to the SageMaker API and console are made over a Secure Sockets Layer (SSL) connection. Restricted IAM roles and policies for SageMaker runs and notebook access based on resource tags and project ID. Restricted access to Amazon public services, such as Amazon Elastic Container Registry (Amazon ECR) to VPC endpoints only. For a reference deployment architecture and ready-to-use deployable constructs for your environment, see Amazon SageMaker with Guardrails on AWS.","title":"Build secure ML environments"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#conclusion","text":"In this post, we showed how you can secure, log, and monitor internet ingress and egress traffic in Studio notebooks for your sensitive ML workloads using managed Network Firewall. You can use the provided CloudFormation templates to automate SageMaker deployment as part of your Infrastructure as Code (IaC) strategy. For more information about other possibilities to secure your SageMaker deployments and ML workloads, see Building secure machine learning environments with Amazon SageMaker.","title":"Conclusion"},{"location":"sagemaker/secure-sagemaker-network-firewall/","text":"Securing Amazon SageMaker Studio internet traffic using AWS Network Firewall Full github repo with code The work in this document complements previous work: - Building secure machine learning environments with Amazon SageMaker Securing Amazon SageMaker Studio connectivity using a private VPC. Background Amazon SageMaker Studio is a web-based fully integrated development environment (IDE) where you can perform end-to-end machine learning (ML) development to prepare data and build, train, and deploy models. Like other AWS services, Studio supports a rich set of security-related features that allow you to build highly secure and compliant environments. One of these fundamental security features allows you to launch Studio in your own Amazon Virtual Private Cloud (Amazon VPC). This allows you to control, monitor, and inspect network traffic within and outside your VPC using standard AWS networking and security capabilities. For more information, see Securing Amazon SageMaker Studio connectivity using a private VPC. Customers in regulated industries, such as financial services, often don\u2019t allow any internet access in ML environments. They often use only VPC endpoints for AWS services, and connect only to private source code repositories in which all libraries have been vetted both in terms of security and licensing. Customers may want to provide internet access but also have some controls such as domain name or URL filtering and allow access to only specific public repositories and websites, possibly packet inspection, or other network traffic-related security controls. For these cases, AWS Network Firewall and NAT gateway-based deployment may provide a suitable use case. In this post, we show how you can use Network Firewall to build a secure and compliant environment by restricting and monitoring internet access, inspecting traffic, and using stateless and stateful firewall engine rules to control the network flow between Studio notebooks and the internet. Depending on your security, compliance, and governance rules, you may not need to or cannot completely block internet access from Studio and your AI and ML workloads. You may have requirements beyond the scope of network security controls implemented by security groups and network access control lists (ACLs), such as application protocol protection, deep packet inspection, domain name filtering, and intrusion prevention system (IPS). Your network traffic controls may also require many more rules compared to what is currently supported in security groups and network ACLs. In these scenarios, you can use Network Firewall\u2014a managed network firewall and IPS for your VPC. Solution overview When you deploy Studio in your VPC, you control how Studio accesses the internet with the parameter AppNetworkAccessType (via the Amazon SageMaker API ) or by selecting your preference on the console when you create a Studio domain. If you select Public internet Only ( PublicInternetOnly ), all the ingress and egress internet traffic from Amazon SageMaker notebooks flows through an AWS managed internet gateway attached to a VPC in your SageMaker account. The following diagram shows this network configuration. Studio provides public internet egress through a platform-managed VPC for data scientists to download notebooks, packages, and datasets. Traffic to the attached Amazon Elastic File System (Amazon EFS) volume always goes through the customer VPC and never through the public internet egress. To use your own control flow for the internet traffic, like a NAT or internet gateway, you must set the AppNetworkAccessType parameter to VpcOnly (or select VPC Only on the console). When you launch your app, this creates an elastic network interface in the specified subnets in your VPC. You can apply all available layers of security control\u2014 security groups , network ACLs , VPC endpoints , AWS PrivateLink , or Network Firewall endpoints \u2014to the internal network and internet traffic to exercise fine-grained control of network access in Studio. The following diagram shows the VpcOnly network configuration. In this mode, the direct internet access to or from notebooks is completely disabled, and all traffic is routed through an elastic network interface in your private VPC. This also includes traffic from Studio UI widgets and interfaces, such as Experiments , Autopilot , and Model Monitor , to their respective backend SageMaker APIs. For more information about network access parameters when creating a domain, see CreateDomain . The solution in this post uses the VpcOnly option and deploys the Studio domain into a VPC with three subnets: SageMaker subnet \u2013 Hosts all Studio workloads. All ingress and egress network flow is controlled by a security group. NAT subnet \u2013 Contains a NAT gateway. We use the NAT gateway to access the internet without exposing any private IP addresses from our private network. Network Firewall subnet \u2013 Contains a Network Firewall endpoint. The route tables are configured so that all inbound and outbound external network traffic is routed via Network Firewall. You can configure stateful and stateless Network Firewall policies to inspect, monitor, and control the traffic. The following diagram shows the overview of the solution architecture and the deployed components. VPC resources The solution deploys the following resources in your account: A VPC with a specified Classless Inter-Domain Routing (CIDR) block Three private subnets with specified CIDRs Internet gateway, NAT gateway, Network Firewall, and a Network Firewall endpoint in the Network Firewall subnet A Network Firewall policy and stateful domain list group with an allow domain list Elastic IP allocated to the NAT gateway Two security groups for SageMaker workloads and VPC endpoints, respectively Four route tables with configured routes An Amazon S3 VPC endpoint (type Gateway) AWS service access VPC endpoints (type Interface) for various AWS services that need to be accessed from Studio The solution also creates an AWS Identity and Access Management (IAM) execution role for SageMaker notebooks and Studio with preconfigured IAM policies. Network routing for targets outside the VPC is configured in such a way that all ingress and egress internet traffic goes via the Network Firewall and NAT gateway. For details and reference network architectures with Network Firewall and NAT gateway, see Architecture with an internet gateway and a NAT gateway , Deployment models for AWS Network Firewall , and Enforce your AWS Network Firewall protections at scale with AWS Firewall Manager . The AWS re:Invent 2020 video Which inspection architecture is right for you? discusses which inspection architecture is right for your use case. SageMaker resources The solution creates a SageMaker domain and user profile. The solution uses only one Availability Zone and is not highly available. A best practice is to use a Multi-AZ configuration for any production deployment. You can implement the highly available solution by duplicating the Single-AZ setup\u2014subnets, NAT gateway, and Network Firewall endpoints\u2014to additional Availability Zones. You use Network Firewall and its policies to control entry and exit of the internet traffic in your VPC. You create an allow domain list rule to allow internet access to the specified network domains only and block traffic to any domain not on the allow list. AWS CloudFormation resources The source code and AWS CloudFormation template for solution deployment are provided in the GitHub repository . To deploy the solution on your account, you need: An AWS account and the AWS Command Line Interface (AWS CLI) configured with administrator permissions An Amazon Simple Storage Service (Amazon S3) bucket in your account in the same Region where you deploy the solution Network Firewall is a Regional service; for more information on Region availability, see the AWS Region Table . Your CloudFormation stack doesn\u2019t have any required parameters. You may want to change the DomainName or *CIDR parameters to avoid naming conflicts with the existing resources and your VPC CIDR allocations. Otherwise, use the following default values: ProjectName \u2013 sagemaker-studio-vpc-firewall DomainName \u2013 sagemaker-anfw-domain UserProfileName \u2013 anfw-user-profile VPCCIDR \u2013 10.2.0.0/16 FirewallSubnetCIDR \u2013 10.2.1.0/24 NATGatewaySubnetCIDR \u2013 10.2.2.0/24 SageMakerStudioSubnetCIDR \u2013 10.2.3.0/24 Deploy the CloudFormation template To start experimenting with the Network Firewall and stateful rules, you need first to deploy the provided CloudFormation template to your AWS account. Clone the GitHub repository: git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git cd amazon-sagemaker-studio-vpc-networkfirewall Create an S3 bucket in the Region where you deploy the solution: aws s3 mb s3://<your s3 bucket name> You can skip this step if you already have an S3 bucket. Deploy the CloudFormation stack: make deploy CFN_ARTEFACT_S3_BUCKET=<your s3 bucket name> The deployment procedure packages the CloudFormation template and copies it to the S3 bucket your provided. Then the CloudFormation template is deployed from the S3 bucket to your AWS account. The stack deploys all the needed resources like VPC, network devices, route tables, security groups, S3 buckets, IAM policies and roles, and VPC endpoints, and also creates a new Studio domain and user profile. When the deployment is complete, you can see the full list of stack output values by running the following command in terminal: aws cloudformation describe-stacks \\ --stack-name sagemaker-studio-demo \\ --output table \\ --query \"Stacks[0].Outputs[*].[OutputKey, OutputValue]\" Launch Studio via the SageMaker console. Experiment with Network Firewall Now you can learn how to control the internet inbound and outbound access with Network Firewall. In this section, we discuss the initial setup, accessing resources not on the allow list, adding domains to the allow list, configuring logging, and additional firewall rules. Initial setup The solution deploys a Network Firewall policy with a stateful rule group with an allow domain list. This policy is attached to the Network Firewall. All inbound and outbound internet traffic is blocked now, except for the .kaggle.com domain, which is on the allow list. Let\u2019s try to access https://kaggle.com by opening a new notebook in Studio and attempting to download the front page from kaggle.com : !wget https://kaggle.com The following screenshot shows that the request succeeds because the domain is allowed by the firewall policy. Users can connect to this and only to this domain from any Studio notebook. Access resources not on the allowed domain list In the Studio notebook, try to clone any public GitHub repository, such as the following: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git This operation times out after 5 minutes because any internet traffic except to and from the .kaggle.com domain isn\u2019t allowed and is dropped by Network Firewall. Add a domain to the allowed domain list To be able to run the git clone command, you must allow internet traffic to the .github.com domain. On the Amazon VPC console, choose Firewall policies. Choose the policy network-firewall-policy- . In the Stateful rule groups section, select the group rule domain-allow-sagemaker- . You can see the domain .kaggle.com on the allow list. Choose Add domain. Enter .github.com . Choose Save. You now have two names on the allow domain list. Firewall policy is propagated in real time to Network Firewall and your changes take effect immediately. Any inbound or outbound traffic from or to these domains is now allowed by the firewall and all other traffic is dropped. To validate the new configuration, go to your Studio notebook and try to clone the same GitHub repository again: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git The operation succeeds this time\u2014Network Firewall allows access to the .github.com domain. Network Firewall logging In this section, you configure Network Firewall logging for your firewall\u2019s stateful engine. Logging gives you detailed information about network traffic, including the time that the stateful engine received a packet, detailed information about the packet, and any stateful rule action taken against the packet. The logs are published to the log destination that you configured, where you can retrieve and view them. On the Amazon VPC console, choose Firewalls . Choose your firewall. Choose the Firewall details tab. In the Logging section, choose Edit . Configure your firewall logging by selecting what log types you want to capture and providing the log destination. For this post, select Alert log type, set Log destination for alerts to CloudWatch Log group, and provide an existing or a new log group where the firewall logs are delivered. Choose Save . To check your settings, go back to Studio and try to access pypi.org to install a Python package: !pip install -U scikit-learn This command fails with ReadTimeoutError because Network Firewall drops any traffic to any domain not on the allow list (which contains only two domains: .github.com and .kaggle.com ). On the Amazon CloudWatch console , navigate to the log group and browse through the recent log streams. The pipy.org domain shows the blocked action. The log event also provides additional details such as various timestamps, protocol, port and IP details, event type, availability zone, and the firewall name. You can continue experimenting with Network Firewall by adding .pypi.org and .pythonhosted.org domains to the allowed domain list. Then validate your access to them via your Studio notebook. Additional firewall rules You can create any other stateless or stateful firewall rules and implement traffic filtering based on a standard stateful 5-tuple rule for network traffic inspection (protocol, source IP, source port, destination IP, destination port). Network Firewall also supports industry standard stateful Suricata compatible IPS rule groups. You can implement protocol-based rules to detect and block any non-standard or promiscuous usage or activity. For more information about creating and managing Network Firewall rule groups, see Rule groups in AWS Network Firewall. Additional security controls with Network Firewall In the previous section, we looked at one feature of the Network Firewall: filtering network traffic based on the domain name. In addition to stateless or stateful firewall rules, Network Firewall provides several tools and features for further security controls and monitoring: Central firewall management and visibility in AWS Firewall Manager . You can centrally manage security policies and automatically enforce mandatory security policies across existing and newly created accounts and VPCs. Network Firewall logging for the firewall\u2019s stateful engine. You can record flow and alert logs, and use the same or different logging destinations for each log type. Stateless rules to filter network traffic based on protocol, source IP addresses, ranges, source port ranges, destination IP addresses and ranges, and TCP flags. Integration into a broader set of AWS security components. For an example, see Automatically block suspicious traffic with AWS Network Firewall and Amazon GuardDuty. Integration in a diverse ecosystem of Network Firewall Partners that complement Network Firewall, enabling the deployment of a comprehensive security architecture. For example use cases, see Full VPC traffic visibility with AWS Network Firewall and Sumo Logic and Splunk Named Launch Partner of AWS Network Firewall. Build secure ML environments A robust security design normally includes multi-layer security controls for the system. For SageMaker environments and workloads, you can use the following AWS security services and concepts to secure, control, and monitor your environment: VPC and private subnets to perform secure API calls to other AWS services and restrict internet access for downloading packages. S3 bucket policies that restrict access to specific VPC endpoints. Encryption of ML model artifacts and other system artifacts that are either in transit or at rest. Requests to the SageMaker API and console are made over a Secure Sockets Layer (SSL) connection. Restricted IAM roles and policies for SageMaker runs and notebook access based on resource tags and project ID. Restricted access to Amazon public services, such as Amazon Elastic Container Registry (Amazon ECR) to VPC endpoints only. For a reference deployment architecture and ready-to-use deployable constructs for your environment, see Amazon SageMaker with Guardrails on AWS. Conclusion In this post, we showed how you can secure, log, and monitor internet ingress and egress traffic in Studio notebooks for your sensitive ML workloads using managed Network Firewall. You can use the provided CloudFormation templates to automate SageMaker deployment as part of your Infrastructure as Code (IaC) strategy. For more information about other possibilities to secure your SageMaker deployments and ML workloads, see Building secure machine learning environments with Amazon SageMaker.","title":"Secure Network"},{"location":"sagemaker/secure-sagemaker-network-firewall/#securing-amazon-sagemaker-studio-internet-traffic-using-aws-network-firewall","text":"Full github repo with code The work in this document complements previous work: - Building secure machine learning environments with Amazon SageMaker Securing Amazon SageMaker Studio connectivity using a private VPC.","title":"Securing Amazon SageMaker Studio internet traffic using AWS Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall/#background","text":"Amazon SageMaker Studio is a web-based fully integrated development environment (IDE) where you can perform end-to-end machine learning (ML) development to prepare data and build, train, and deploy models. Like other AWS services, Studio supports a rich set of security-related features that allow you to build highly secure and compliant environments. One of these fundamental security features allows you to launch Studio in your own Amazon Virtual Private Cloud (Amazon VPC). This allows you to control, monitor, and inspect network traffic within and outside your VPC using standard AWS networking and security capabilities. For more information, see Securing Amazon SageMaker Studio connectivity using a private VPC. Customers in regulated industries, such as financial services, often don\u2019t allow any internet access in ML environments. They often use only VPC endpoints for AWS services, and connect only to private source code repositories in which all libraries have been vetted both in terms of security and licensing. Customers may want to provide internet access but also have some controls such as domain name or URL filtering and allow access to only specific public repositories and websites, possibly packet inspection, or other network traffic-related security controls. For these cases, AWS Network Firewall and NAT gateway-based deployment may provide a suitable use case. In this post, we show how you can use Network Firewall to build a secure and compliant environment by restricting and monitoring internet access, inspecting traffic, and using stateless and stateful firewall engine rules to control the network flow between Studio notebooks and the internet. Depending on your security, compliance, and governance rules, you may not need to or cannot completely block internet access from Studio and your AI and ML workloads. You may have requirements beyond the scope of network security controls implemented by security groups and network access control lists (ACLs), such as application protocol protection, deep packet inspection, domain name filtering, and intrusion prevention system (IPS). Your network traffic controls may also require many more rules compared to what is currently supported in security groups and network ACLs. In these scenarios, you can use Network Firewall\u2014a managed network firewall and IPS for your VPC.","title":"Background"},{"location":"sagemaker/secure-sagemaker-network-firewall/#solution-overview","text":"When you deploy Studio in your VPC, you control how Studio accesses the internet with the parameter AppNetworkAccessType (via the Amazon SageMaker API ) or by selecting your preference on the console when you create a Studio domain. If you select Public internet Only ( PublicInternetOnly ), all the ingress and egress internet traffic from Amazon SageMaker notebooks flows through an AWS managed internet gateway attached to a VPC in your SageMaker account. The following diagram shows this network configuration. Studio provides public internet egress through a platform-managed VPC for data scientists to download notebooks, packages, and datasets. Traffic to the attached Amazon Elastic File System (Amazon EFS) volume always goes through the customer VPC and never through the public internet egress. To use your own control flow for the internet traffic, like a NAT or internet gateway, you must set the AppNetworkAccessType parameter to VpcOnly (or select VPC Only on the console). When you launch your app, this creates an elastic network interface in the specified subnets in your VPC. You can apply all available layers of security control\u2014 security groups , network ACLs , VPC endpoints , AWS PrivateLink , or Network Firewall endpoints \u2014to the internal network and internet traffic to exercise fine-grained control of network access in Studio. The following diagram shows the VpcOnly network configuration. In this mode, the direct internet access to or from notebooks is completely disabled, and all traffic is routed through an elastic network interface in your private VPC. This also includes traffic from Studio UI widgets and interfaces, such as Experiments , Autopilot , and Model Monitor , to their respective backend SageMaker APIs. For more information about network access parameters when creating a domain, see CreateDomain . The solution in this post uses the VpcOnly option and deploys the Studio domain into a VPC with three subnets: SageMaker subnet \u2013 Hosts all Studio workloads. All ingress and egress network flow is controlled by a security group. NAT subnet \u2013 Contains a NAT gateway. We use the NAT gateway to access the internet without exposing any private IP addresses from our private network. Network Firewall subnet \u2013 Contains a Network Firewall endpoint. The route tables are configured so that all inbound and outbound external network traffic is routed via Network Firewall. You can configure stateful and stateless Network Firewall policies to inspect, monitor, and control the traffic. The following diagram shows the overview of the solution architecture and the deployed components.","title":"Solution overview"},{"location":"sagemaker/secure-sagemaker-network-firewall/#vpc-resources","text":"The solution deploys the following resources in your account: A VPC with a specified Classless Inter-Domain Routing (CIDR) block Three private subnets with specified CIDRs Internet gateway, NAT gateway, Network Firewall, and a Network Firewall endpoint in the Network Firewall subnet A Network Firewall policy and stateful domain list group with an allow domain list Elastic IP allocated to the NAT gateway Two security groups for SageMaker workloads and VPC endpoints, respectively Four route tables with configured routes An Amazon S3 VPC endpoint (type Gateway) AWS service access VPC endpoints (type Interface) for various AWS services that need to be accessed from Studio The solution also creates an AWS Identity and Access Management (IAM) execution role for SageMaker notebooks and Studio with preconfigured IAM policies. Network routing for targets outside the VPC is configured in such a way that all ingress and egress internet traffic goes via the Network Firewall and NAT gateway. For details and reference network architectures with Network Firewall and NAT gateway, see Architecture with an internet gateway and a NAT gateway , Deployment models for AWS Network Firewall , and Enforce your AWS Network Firewall protections at scale with AWS Firewall Manager . The AWS re:Invent 2020 video Which inspection architecture is right for you? discusses which inspection architecture is right for your use case.","title":"VPC resources"},{"location":"sagemaker/secure-sagemaker-network-firewall/#sagemaker-resources","text":"The solution creates a SageMaker domain and user profile. The solution uses only one Availability Zone and is not highly available. A best practice is to use a Multi-AZ configuration for any production deployment. You can implement the highly available solution by duplicating the Single-AZ setup\u2014subnets, NAT gateway, and Network Firewall endpoints\u2014to additional Availability Zones. You use Network Firewall and its policies to control entry and exit of the internet traffic in your VPC. You create an allow domain list rule to allow internet access to the specified network domains only and block traffic to any domain not on the allow list.","title":"SageMaker resources"},{"location":"sagemaker/secure-sagemaker-network-firewall/#aws-cloudformation-resources","text":"The source code and AWS CloudFormation template for solution deployment are provided in the GitHub repository . To deploy the solution on your account, you need: An AWS account and the AWS Command Line Interface (AWS CLI) configured with administrator permissions An Amazon Simple Storage Service (Amazon S3) bucket in your account in the same Region where you deploy the solution Network Firewall is a Regional service; for more information on Region availability, see the AWS Region Table . Your CloudFormation stack doesn\u2019t have any required parameters. You may want to change the DomainName or *CIDR parameters to avoid naming conflicts with the existing resources and your VPC CIDR allocations. Otherwise, use the following default values: ProjectName \u2013 sagemaker-studio-vpc-firewall DomainName \u2013 sagemaker-anfw-domain UserProfileName \u2013 anfw-user-profile VPCCIDR \u2013 10.2.0.0/16 FirewallSubnetCIDR \u2013 10.2.1.0/24 NATGatewaySubnetCIDR \u2013 10.2.2.0/24 SageMakerStudioSubnetCIDR \u2013 10.2.3.0/24 Deploy the CloudFormation template To start experimenting with the Network Firewall and stateful rules, you need first to deploy the provided CloudFormation template to your AWS account. Clone the GitHub repository: git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git cd amazon-sagemaker-studio-vpc-networkfirewall Create an S3 bucket in the Region where you deploy the solution: aws s3 mb s3://<your s3 bucket name> You can skip this step if you already have an S3 bucket. Deploy the CloudFormation stack: make deploy CFN_ARTEFACT_S3_BUCKET=<your s3 bucket name> The deployment procedure packages the CloudFormation template and copies it to the S3 bucket your provided. Then the CloudFormation template is deployed from the S3 bucket to your AWS account. The stack deploys all the needed resources like VPC, network devices, route tables, security groups, S3 buckets, IAM policies and roles, and VPC endpoints, and also creates a new Studio domain and user profile. When the deployment is complete, you can see the full list of stack output values by running the following command in terminal: aws cloudformation describe-stacks \\ --stack-name sagemaker-studio-demo \\ --output table \\ --query \"Stacks[0].Outputs[*].[OutputKey, OutputValue]\" Launch Studio via the SageMaker console.","title":"AWS CloudFormation resources"},{"location":"sagemaker/secure-sagemaker-network-firewall/#experiment-with-network-firewall","text":"Now you can learn how to control the internet inbound and outbound access with Network Firewall. In this section, we discuss the initial setup, accessing resources not on the allow list, adding domains to the allow list, configuring logging, and additional firewall rules.","title":"Experiment with Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall/#initial-setup","text":"The solution deploys a Network Firewall policy with a stateful rule group with an allow domain list. This policy is attached to the Network Firewall. All inbound and outbound internet traffic is blocked now, except for the .kaggle.com domain, which is on the allow list. Let\u2019s try to access https://kaggle.com by opening a new notebook in Studio and attempting to download the front page from kaggle.com : !wget https://kaggle.com The following screenshot shows that the request succeeds because the domain is allowed by the firewall policy. Users can connect to this and only to this domain from any Studio notebook.","title":"Initial setup"},{"location":"sagemaker/secure-sagemaker-network-firewall/#access-resources-not-on-the-allowed-domain-list","text":"In the Studio notebook, try to clone any public GitHub repository, such as the following: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git This operation times out after 5 minutes because any internet traffic except to and from the .kaggle.com domain isn\u2019t allowed and is dropped by Network Firewall.","title":"Access resources not on the allowed domain list"},{"location":"sagemaker/secure-sagemaker-network-firewall/#add-a-domain-to-the-allowed-domain-list","text":"To be able to run the git clone command, you must allow internet traffic to the .github.com domain. On the Amazon VPC console, choose Firewall policies. Choose the policy network-firewall-policy- . In the Stateful rule groups section, select the group rule domain-allow-sagemaker- . You can see the domain .kaggle.com on the allow list. Choose Add domain. Enter .github.com . Choose Save. You now have two names on the allow domain list. Firewall policy is propagated in real time to Network Firewall and your changes take effect immediately. Any inbound or outbound traffic from or to these domains is now allowed by the firewall and all other traffic is dropped. To validate the new configuration, go to your Studio notebook and try to clone the same GitHub repository again: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git The operation succeeds this time\u2014Network Firewall allows access to the .github.com domain.","title":"Add a domain to the allowed domain list"},{"location":"sagemaker/secure-sagemaker-network-firewall/#network-firewall-logging","text":"In this section, you configure Network Firewall logging for your firewall\u2019s stateful engine. Logging gives you detailed information about network traffic, including the time that the stateful engine received a packet, detailed information about the packet, and any stateful rule action taken against the packet. The logs are published to the log destination that you configured, where you can retrieve and view them. On the Amazon VPC console, choose Firewalls . Choose your firewall. Choose the Firewall details tab. In the Logging section, choose Edit . Configure your firewall logging by selecting what log types you want to capture and providing the log destination. For this post, select Alert log type, set Log destination for alerts to CloudWatch Log group, and provide an existing or a new log group where the firewall logs are delivered. Choose Save . To check your settings, go back to Studio and try to access pypi.org to install a Python package: !pip install -U scikit-learn This command fails with ReadTimeoutError because Network Firewall drops any traffic to any domain not on the allow list (which contains only two domains: .github.com and .kaggle.com ). On the Amazon CloudWatch console , navigate to the log group and browse through the recent log streams. The pipy.org domain shows the blocked action. The log event also provides additional details such as various timestamps, protocol, port and IP details, event type, availability zone, and the firewall name. You can continue experimenting with Network Firewall by adding .pypi.org and .pythonhosted.org domains to the allowed domain list. Then validate your access to them via your Studio notebook.","title":"Network Firewall logging"},{"location":"sagemaker/secure-sagemaker-network-firewall/#additional-firewall-rules","text":"You can create any other stateless or stateful firewall rules and implement traffic filtering based on a standard stateful 5-tuple rule for network traffic inspection (protocol, source IP, source port, destination IP, destination port). Network Firewall also supports industry standard stateful Suricata compatible IPS rule groups. You can implement protocol-based rules to detect and block any non-standard or promiscuous usage or activity. For more information about creating and managing Network Firewall rule groups, see Rule groups in AWS Network Firewall.","title":"Additional firewall rules"},{"location":"sagemaker/secure-sagemaker-network-firewall/#additional-security-controls-with-network-firewall","text":"In the previous section, we looked at one feature of the Network Firewall: filtering network traffic based on the domain name. In addition to stateless or stateful firewall rules, Network Firewall provides several tools and features for further security controls and monitoring: Central firewall management and visibility in AWS Firewall Manager . You can centrally manage security policies and automatically enforce mandatory security policies across existing and newly created accounts and VPCs. Network Firewall logging for the firewall\u2019s stateful engine. You can record flow and alert logs, and use the same or different logging destinations for each log type. Stateless rules to filter network traffic based on protocol, source IP addresses, ranges, source port ranges, destination IP addresses and ranges, and TCP flags. Integration into a broader set of AWS security components. For an example, see Automatically block suspicious traffic with AWS Network Firewall and Amazon GuardDuty. Integration in a diverse ecosystem of Network Firewall Partners that complement Network Firewall, enabling the deployment of a comprehensive security architecture. For example use cases, see Full VPC traffic visibility with AWS Network Firewall and Sumo Logic and Splunk Named Launch Partner of AWS Network Firewall.","title":"Additional security controls with Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall/#build-secure-ml-environments","text":"A robust security design normally includes multi-layer security controls for the system. For SageMaker environments and workloads, you can use the following AWS security services and concepts to secure, control, and monitor your environment: VPC and private subnets to perform secure API calls to other AWS services and restrict internet access for downloading packages. S3 bucket policies that restrict access to specific VPC endpoints. Encryption of ML model artifacts and other system artifacts that are either in transit or at rest. Requests to the SageMaker API and console are made over a Secure Sockets Layer (SSL) connection. Restricted IAM roles and policies for SageMaker runs and notebook access based on resource tags and project ID. Restricted access to Amazon public services, such as Amazon Elastic Container Registry (Amazon ECR) to VPC endpoints only. For a reference deployment architecture and ready-to-use deployable constructs for your environment, see Amazon SageMaker with Guardrails on AWS.","title":"Build secure ML environments"},{"location":"sagemaker/secure-sagemaker-network-firewall/#conclusion","text":"In this post, we showed how you can secure, log, and monitor internet ingress and egress traffic in Studio notebooks for your sensitive ML workloads using managed Network Firewall. You can use the provided CloudFormation templates to automate SageMaker deployment as part of your Infrastructure as Code (IaC) strategy. For more information about other possibilities to secure your SageMaker deployments and ML workloads, see Building secure machine learning environments with Amazon SageMaker.","title":"Conclusion"}]}