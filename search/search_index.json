{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"So much emptyness","title":"Home"},{"location":"environment/Makefile/","text":"GNU Make Make is a project management tool for building executables and program files. It ensures our project is consistent across different environments, locally and remote server. This document provides a simple template for starting a project with make . Commands should be executed in project root, using make <command> . For example run make install to invoke python library install for project. In the makefile see this block: install: cat requirements.txt | xargs poetry add Makefile template SHELL := /bin/bash # Target section and Global definitions # ----------------------------------------------------------------------------- .PHONY: all clean test install run deploy down all: clean test install run deploy down hello: @echo \"Hello World\" install: cat requirements.txt | xargs poetry add # poetry add tox setuptools post-install: python -m textblob.download_corpora git: # Update Git Repo bash sync_git.sh format: # format code using black black *.py mylib/*.py lint: # format code using pylint or flake8 pylint --disable=R,C *.py mylib/*.py test: # test dockerfile docker run --rm -i hadolint/hadolint < Dockerfile # test code python -m pytest -vv --cov=mylib --cov=main test_*.py build: #build container docker build -t deploy-fastapi . a-rule: some proxypass uuid=$$(docker-compose ps -q myService);\\ docker cp \"$$uuid\":/a/b/c . run: #run docker docker run -p 127.0.0.1:8080:8080 deploy-fastapi deploy: aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 073416988478.dkr.ecr.us-east-1.amazonaws.com docker build -t mlops_scaffold . docker tag mlops_scaffold:latest 073416988478.dkr.ecr.us-east-1.amazonaws.com/mlops_scaffold:latest docker push 073416988478.dkr.ecr.us-east-1.amazonaws.com/mlops_scaffold:latest run: - python -c \"import subprocess;print(subprocess.run(['hostname','-I'],capture_output=True,text=True).stdout.strip())\" PYTHONPATH=huggingfastapi/ uvicorn huggingfastapi.main:app --reload --host 0.0.0.0 build: docker-compose build deploy: docker-compose up -d down: docker-compose down clean: -find . -name '*.pyc' -exec rm -rf {} \\; -find . -name '__pycache__' -exec rm -rf {} \\; -find . -name 'Thumbs.db' -exec rm -rf {} \\; -find . -name '*~' -exec rm -rf {} \\; -rm -rf .cache -rm -rf build -rm -rf dist -rm -rf *.egg-info -rm -rf htmlcov* -rm -rf .tox/ -rm -rf docs/_build -rm -r .coverage","title":"Make Workflow"},{"location":"environment/Makefile/#gnu-make","text":"Make is a project management tool for building executables and program files. It ensures our project is consistent across different environments, locally and remote server. This document provides a simple template for starting a project with make . Commands should be executed in project root, using make <command> . For example run make install to invoke python library install for project. In the makefile see this block: install: cat requirements.txt | xargs poetry add","title":"GNU Make"},{"location":"environment/Makefile/#makefile-template","text":"SHELL := /bin/bash # Target section and Global definitions # ----------------------------------------------------------------------------- .PHONY: all clean test install run deploy down all: clean test install run deploy down hello: @echo \"Hello World\" install: cat requirements.txt | xargs poetry add # poetry add tox setuptools post-install: python -m textblob.download_corpora git: # Update Git Repo bash sync_git.sh format: # format code using black black *.py mylib/*.py lint: # format code using pylint or flake8 pylint --disable=R,C *.py mylib/*.py test: # test dockerfile docker run --rm -i hadolint/hadolint < Dockerfile # test code python -m pytest -vv --cov=mylib --cov=main test_*.py build: #build container docker build -t deploy-fastapi . a-rule: some proxypass uuid=$$(docker-compose ps -q myService);\\ docker cp \"$$uuid\":/a/b/c . run: #run docker docker run -p 127.0.0.1:8080:8080 deploy-fastapi deploy: aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 073416988478.dkr.ecr.us-east-1.amazonaws.com docker build -t mlops_scaffold . docker tag mlops_scaffold:latest 073416988478.dkr.ecr.us-east-1.amazonaws.com/mlops_scaffold:latest docker push 073416988478.dkr.ecr.us-east-1.amazonaws.com/mlops_scaffold:latest run: - python -c \"import subprocess;print(subprocess.run(['hostname','-I'],capture_output=True,text=True).stdout.strip())\" PYTHONPATH=huggingfastapi/ uvicorn huggingfastapi.main:app --reload --host 0.0.0.0 build: docker-compose build deploy: docker-compose up -d down: docker-compose down clean: -find . -name '*.pyc' -exec rm -rf {} \\; -find . -name '__pycache__' -exec rm -rf {} \\; -find . -name 'Thumbs.db' -exec rm -rf {} \\; -find . -name '*~' -exec rm -rf {} \\; -rm -rf .cache -rm -rf build -rm -rf dist -rm -rf *.egg-info -rm -rf htmlcov* -rm -rf .tox/ -rm -rf docs/_build -rm -r .coverage","title":"Makefile template"},{"location":"environment/poetry_install/","text":"Poetry package manager Poetry helps you declare, manage and install dependencies of Python projects, ensuring you have the right stack everywhere. Personally , I use pyenv and poetry for production projects. These decouple system settings from individual projects. Features The pyproject.toml is a standardized file to manage the dependencies. poetry will also detect if you are inside a virtualenv and install the packages accordingly. So, poetry can be installed globally and used everywhere. :fire: Poetry is isolated from your system. poetry also comes with a full fledged dependency resolution library. Install Install on macOS. curl -sSL https://install.python-poetry.org | python3 - Retrieving Poetry metadata # Welcome to Poetry! This will download and install the latest version of Poetry, a dependency and package manager for Python. It will add the `poetry` command to Poetry's bin directory, located at: /Users/elxsj/.local/bin You can uninstall at any time by executing this script with the --uninstall option, and these changes will be reverted. Installing Poetry (1.3.2): Installing Poetry To get started you need Poetry's bin directory (/Users/elxsj/.local/bin) in your `PATH` environment variable. Add `export PATH=\"/Users/elxsj/.local/bin:$PATH\"` to your shell configuration file. Alternatively, you can call Poetry explicitly with `/Users/elxsj/.local/bin/poetry`. You can test that everything is set up by executing: `poetry --version` After install the default config output shows updates to $PATH and executable information. To configure your current shell run source $HOME/.poetry/env Verify Install works as expected $ poetry config --list cache-dir = \"/Users/elxsj/Library/Caches/pypoetry\" experimental.new-installer = true experimental.system-git-client = false installer.max-workers = null installer.no-binary = null installer.parallel = true virtualenvs.create = true virtualenvs.in-project = true virtualenvs.options.always-copy = false virtualenvs.options.no-pip = false virtualenvs.options.no-setuptools = false virtualenvs.options.system-site-packages = false virtualenvs.path = \"{cache-dir}/virtualenvs\" # /Users/elxsj/Library/Caches/pypoetry/virtualenvs virtualenvs.prefer-active-python = false virtualenvs.prompt = \"{project_name}-py{python_version}\" # Check Poetry Path $HOME/.poetry/bin End","title":"Poetry Installation"},{"location":"environment/poetry_install/#poetry-package-manager","text":"Poetry helps you declare, manage and install dependencies of Python projects, ensuring you have the right stack everywhere. Personally , I use pyenv and poetry for production projects. These decouple system settings from individual projects.","title":"Poetry package manager"},{"location":"environment/poetry_install/#features","text":"The pyproject.toml is a standardized file to manage the dependencies. poetry will also detect if you are inside a virtualenv and install the packages accordingly. So, poetry can be installed globally and used everywhere. :fire: Poetry is isolated from your system. poetry also comes with a full fledged dependency resolution library.","title":"Features"},{"location":"environment/poetry_install/#install","text":"Install on macOS. curl -sSL https://install.python-poetry.org | python3 - Retrieving Poetry metadata # Welcome to Poetry! This will download and install the latest version of Poetry, a dependency and package manager for Python. It will add the `poetry` command to Poetry's bin directory, located at: /Users/elxsj/.local/bin You can uninstall at any time by executing this script with the --uninstall option, and these changes will be reverted. Installing Poetry (1.3.2): Installing Poetry To get started you need Poetry's bin directory (/Users/elxsj/.local/bin) in your `PATH` environment variable. Add `export PATH=\"/Users/elxsj/.local/bin:$PATH\"` to your shell configuration file. Alternatively, you can call Poetry explicitly with `/Users/elxsj/.local/bin/poetry`. You can test that everything is set up by executing: `poetry --version` After install the default config output shows updates to $PATH and executable information. To configure your current shell run source $HOME/.poetry/env","title":"Install"},{"location":"environment/poetry_install/#verify-install-works-as-expected","text":"$ poetry config --list cache-dir = \"/Users/elxsj/Library/Caches/pypoetry\" experimental.new-installer = true experimental.system-git-client = false installer.max-workers = null installer.no-binary = null installer.parallel = true virtualenvs.create = true virtualenvs.in-project = true virtualenvs.options.always-copy = false virtualenvs.options.no-pip = false virtualenvs.options.no-setuptools = false virtualenvs.options.system-site-packages = false virtualenvs.path = \"{cache-dir}/virtualenvs\" # /Users/elxsj/Library/Caches/pypoetry/virtualenvs virtualenvs.prefer-active-python = false virtualenvs.prompt = \"{project_name}-py{python_version}\" # Check Poetry Path $HOME/.poetry/bin","title":"Verify Install works as expected"},{"location":"environment/poetry_install/#end","text":"","title":"End"},{"location":"environment/poetry_new_project/","text":"Poetry package manager Poetry helps you declare, manage and install dependencies of Python projects, ensuring you have the right stack everywhere. Personally , I use pyenv and poetry for production projects. These decouple system settings from individual projects. Poetry Features The pyproject.toml is a standardized file to manage the dependencies. poetry will also detect if you are inside a virtualenv and install the packages accordingly. So, poetry can be installed globally and used everywhere. :fire: Poetry is isolated from your system. This is a really good thing, bc each OS is a unique environment. poetry also comes with a full fledged dependency resolution library. Create new poetry project Abbreviated: Create new project with poetry env This is the abbreviated directions for power users. Scroll past this section to see detailed explanations. poetry new test_env :exclamation: Use poetry init for existing project cd $_ pyenv local 3.9.1 This will update the .python_version file pyenv shell 3.9.1 poetry env use $(pyenv which python) modify python version, in pyproject.toml by hand if required. Show correct python version is being used - poetry env info open VSCode and the shell shows the correct environment - (test-env-py3.9) [elxsj@WUST040517:~/test_env]$ Activate Virtual Environment Open existing poetry environment, by runnning poetry shell The poetry environment will display in shell: (breeding-apd-simulator-datapipeline-dw-py3.10) bash-3.2$ Verbose: Create new project with poetry env In a shell generate a default project scaffold poetry new poetry_env cd $_ switch into directory OR Simulate an existing project. Create directory and add pyproject.toml :pencil: poetry new poetry-demo creates a directory for a new project. This is not required for an existing project. For an existing project run poetry init in the existing project directory and step through the interactive dialogue. mkdir ~/test_error && cd ~/test_error echo -e \"[tool.poetry] \\nname = 'smol-cls-mwaa-dags' \\nversion = '0.1.0' \\ndescription = '' \\nauthors = ['memadsen <michael.madsen@bayer.com>'] \\n\\n[tool.poetry.dependencies] \\npython = '^3.9' \\n\\n[tool.poetry.dev-dependencies] \\n\\n[build-system] \\nrequires = ['poetry-core>=1.0.0'] \\nbuild-backend = 'poetry.core.masonry.api'\" > pyproject.toml cd $_ switch into directory My directory scaffold has this structure $ tree . \u251c\u2500\u2500 README.md \u251c\u2500\u2500 poetry_env \u2502 \u2514\u2500\u2500 __init__.py \u251c\u2500\u2500 pyproject.toml \u2514\u2500\u2500 tests \u2514\u2500\u2500 __init__.py pyenv install 3.9.5 Optional, if previously installed pyenv local 3.9.1 Add python version This creates a .python_version file. cat .python-version 3.9.1 poetry env use 3.9.1 set the Python used for the Poetry-managed environment, creating it if it doesn't already exist. envs.toml is created to record what the 'current interpreter' for the environment is (as the user has explicitly selected one, instead of letting Poetry select the interpreter implicitly) Notice the pyproject.toml . This is where we define everything from our project\u2019s metadata, dependencies, scripts, and more. If you\u2019re familiar with Node.js, consider the pyproject.toml as an equivalent of the Node.js package.json . poetry env use $(pyenv which python) modify python version, in pyproject.toml by hand if required. poetry install Install and activate the virtual environment Add python interpreter to path, required for Pycharm . Check poetry .toml file for virtualenvs My preference is to have all the logic to my virtualenv in one place, e.g the .toml file. [tool.poetry] name = \"microservice-aws-app-runner\" version = \"0.1.0\" description = \"\" authors = [\"memadsen <michael.madsen@bayer.com>\"] [tool.poetry.dependencies] python = \"^3.9\" [tool.poetry.dev-dependencies] [build-system] requires = [\"poetry-core>=1.0.0\"] build-backend = \"poetry.core.masonry.api\" [virtualenvs] create = true in-project = true Project Dependencies Track project dependencies using poetry show --tree . Next poetry show --tree requests-toolbelt 0.8.0 A utility belt for advanced users... \u2514\u2500\u2500 requests <3.0.0,>=2.0.1 \u251c\u2500\u2500 certifi >=2017.4.17 \u251c\u2500\u2500 chardet >=3.0.2,<3.1.0 \u251c\u2500\u2500 idna >=2.5,<2.7 \u2514\u2500\u2500 urllib3 <1.23,>=1.21.1 $ poetry show --latest pendulum 2.0.4 1.4.5 Python datetimes made easy. django 1.11.11 2.0.3 A high-level Python Web framework ... requests 2.18.4 2.18.4 Python HTTP for Humans. Add libraries poetry add mlrun==1.0.2 ## Specify constraints when adding library poetry add pendulum@^2.0.5 poetry add \"pendulum>=2.0.5\" Options to add libraries --dev (-D) : Add package as development dependency. --path : The path to a dependency. --optional : Add as an optional dependency. --dry-run : Outputs the operations but will not execute anything (implicitly enables \u2013verbose). --lock : Do not perform install (only update the lockfile). Update libraries If you just want to update a few packages and not all, you can list them as such: poetry update requests toml Note that this will not update versions for dependencies outside their version constraints specified in the pyproject.toml file. In other terms, poetry update foo will be a no-op if the version constraint specified for foo is ~2.3 or 2.3 and 2.4 is available. In order for foo to be updated, you must update the constraint, for example ^2.3 . You can do this using the add command. Options --dry-run : Outputs the operations but will not execute anything (implicitly enables \u2013verbose). --no-dev : Do not install dev dependencies. --lock : Do not perform install (only update the lockfile). poetry lock --no-update This makes it possible to remove a dependency from pyproject.toml and update the lock file without upgrading dependencies. Dependency Group poetry add --group dev httpx Current Configuration List the current configuration. $ poetry config --list cache-dir = \"/Users/elxsj/Library/Caches/pypoetry\" experimental.new-installer = true experimental.system-git-client = false installer.max-workers = null installer.no-binary = null installer.parallel = true virtualenvs.create = true virtualenvs.in-project = null virtualenvs.options.always-copy = false virtualenvs.options.no-pip = false virtualenvs.options.no-setuptools = false virtualenvs.options.system-site-packages = false virtualenvs.path = \"{cache-dir}/virtualenvs\" # /Users/elxsj/Library/Caches/pypoetry/virtualenvs virtualenvs.prefer-active-python = false virtualenvs.prompt = \"{project_name}-py{python_version}\" Check the Path and Executable for this poetry environment: $ poetry env info System Platform: darwin OS: posix Python: 3.10.0 Path: /Users/elxsj/.pyenv/versions/3.10.0 Executable: /Users/elxsj/.pyenv/versions/3.10.0/bin/python3.10 Poetry Export If you have a Poetry project, you can create a requirements.txt file from your poetry.lock file: poetry export --output requirements.txt Poetry Commands Create a new project, create a virtual envrionment and add and remove dependencies using these commands: Command Description poetry new [package-name] Start a new Python Project. poetry init Create a pyproject.toml file interactively. poetry install Install the packages inside the pyproject.toml file. poetry add [package-name] Add a package to a Virtual Environment. poetry add -D [package-name] Add a dev package to a Virtual Environment. poetry remove [package-name] Remove a package from a Virtual Environment. poetry remove -D [package-name] Remove a dev package from a Virtual Environment. poetry self:update Update poetry to the latest stable version. Environment poetry env list List all environments poetry env remove env-name Remove environment Troubleshooting Some things to try if poetry has unusual errors. poetry cache clear --all . Clear cache rm -f ./poetry.lock poetry install --remove-untracked References Poetry github https://github.com/python-poetry/poetry","title":"Poetry New Project"},{"location":"environment/poetry_new_project/#poetry-package-manager","text":"Poetry helps you declare, manage and install dependencies of Python projects, ensuring you have the right stack everywhere. Personally , I use pyenv and poetry for production projects. These decouple system settings from individual projects.","title":"Poetry package manager"},{"location":"environment/poetry_new_project/#poetry-features","text":"The pyproject.toml is a standardized file to manage the dependencies. poetry will also detect if you are inside a virtualenv and install the packages accordingly. So, poetry can be installed globally and used everywhere. :fire: Poetry is isolated from your system. This is a really good thing, bc each OS is a unique environment. poetry also comes with a full fledged dependency resolution library.","title":"Poetry Features"},{"location":"environment/poetry_new_project/#create-new-poetry-project","text":"","title":"Create new poetry project"},{"location":"environment/poetry_new_project/#abbreviated-create-new-project-with-poetry-env","text":"This is the abbreviated directions for power users. Scroll past this section to see detailed explanations. poetry new test_env :exclamation: Use poetry init for existing project cd $_ pyenv local 3.9.1 This will update the .python_version file pyenv shell 3.9.1 poetry env use $(pyenv which python) modify python version, in pyproject.toml by hand if required. Show correct python version is being used - poetry env info open VSCode and the shell shows the correct environment - (test-env-py3.9) [elxsj@WUST040517:~/test_env]$","title":"Abbreviated:  Create new project with poetry env"},{"location":"environment/poetry_new_project/#activate-virtual-environment","text":"Open existing poetry environment, by runnning poetry shell The poetry environment will display in shell: (breeding-apd-simulator-datapipeline-dw-py3.10) bash-3.2$","title":"Activate Virtual Environment"},{"location":"environment/poetry_new_project/#verbose-create-new-project-with-poetry-env","text":"In a shell generate a default project scaffold poetry new poetry_env cd $_ switch into directory OR Simulate an existing project. Create directory and add pyproject.toml :pencil: poetry new poetry-demo creates a directory for a new project. This is not required for an existing project. For an existing project run poetry init in the existing project directory and step through the interactive dialogue. mkdir ~/test_error && cd ~/test_error echo -e \"[tool.poetry] \\nname = 'smol-cls-mwaa-dags' \\nversion = '0.1.0' \\ndescription = '' \\nauthors = ['memadsen <michael.madsen@bayer.com>'] \\n\\n[tool.poetry.dependencies] \\npython = '^3.9' \\n\\n[tool.poetry.dev-dependencies] \\n\\n[build-system] \\nrequires = ['poetry-core>=1.0.0'] \\nbuild-backend = 'poetry.core.masonry.api'\" > pyproject.toml cd $_ switch into directory My directory scaffold has this structure $ tree . \u251c\u2500\u2500 README.md \u251c\u2500\u2500 poetry_env \u2502 \u2514\u2500\u2500 __init__.py \u251c\u2500\u2500 pyproject.toml \u2514\u2500\u2500 tests \u2514\u2500\u2500 __init__.py pyenv install 3.9.5 Optional, if previously installed pyenv local 3.9.1 Add python version This creates a .python_version file. cat .python-version 3.9.1 poetry env use 3.9.1 set the Python used for the Poetry-managed environment, creating it if it doesn't already exist. envs.toml is created to record what the 'current interpreter' for the environment is (as the user has explicitly selected one, instead of letting Poetry select the interpreter implicitly) Notice the pyproject.toml . This is where we define everything from our project\u2019s metadata, dependencies, scripts, and more. If you\u2019re familiar with Node.js, consider the pyproject.toml as an equivalent of the Node.js package.json . poetry env use $(pyenv which python) modify python version, in pyproject.toml by hand if required. poetry install Install and activate the virtual environment","title":"Verbose:  Create new project with poetry env"},{"location":"environment/poetry_new_project/#add-python-interpreter-to-path-required-for-pycharm","text":"","title":"Add python interpreter to path, required for Pycharm."},{"location":"environment/poetry_new_project/#check-poetry-toml-file-for-virtualenvs","text":"My preference is to have all the logic to my virtualenv in one place, e.g the .toml file. [tool.poetry] name = \"microservice-aws-app-runner\" version = \"0.1.0\" description = \"\" authors = [\"memadsen <michael.madsen@bayer.com>\"] [tool.poetry.dependencies] python = \"^3.9\" [tool.poetry.dev-dependencies] [build-system] requires = [\"poetry-core>=1.0.0\"] build-backend = \"poetry.core.masonry.api\" [virtualenvs] create = true in-project = true","title":"Check poetry .toml file for virtualenvs"},{"location":"environment/poetry_new_project/#project-dependencies","text":"Track project dependencies using poetry show --tree . Next poetry show --tree requests-toolbelt 0.8.0 A utility belt for advanced users... \u2514\u2500\u2500 requests <3.0.0,>=2.0.1 \u251c\u2500\u2500 certifi >=2017.4.17 \u251c\u2500\u2500 chardet >=3.0.2,<3.1.0 \u251c\u2500\u2500 idna >=2.5,<2.7 \u2514\u2500\u2500 urllib3 <1.23,>=1.21.1 $ poetry show --latest pendulum 2.0.4 1.4.5 Python datetimes made easy. django 1.11.11 2.0.3 A high-level Python Web framework ... requests 2.18.4 2.18.4 Python HTTP for Humans.","title":"Project Dependencies"},{"location":"environment/poetry_new_project/#add-libraries","text":"poetry add mlrun==1.0.2 ## Specify constraints when adding library poetry add pendulum@^2.0.5 poetry add \"pendulum>=2.0.5\"","title":"Add libraries"},{"location":"environment/poetry_new_project/#options-to-add-libraries","text":"--dev (-D) : Add package as development dependency. --path : The path to a dependency. --optional : Add as an optional dependency. --dry-run : Outputs the operations but will not execute anything (implicitly enables \u2013verbose). --lock : Do not perform install (only update the lockfile).","title":"Options to add libraries"},{"location":"environment/poetry_new_project/#update-libraries","text":"If you just want to update a few packages and not all, you can list them as such: poetry update requests toml Note that this will not update versions for dependencies outside their version constraints specified in the pyproject.toml file. In other terms, poetry update foo will be a no-op if the version constraint specified for foo is ~2.3 or 2.3 and 2.4 is available. In order for foo to be updated, you must update the constraint, for example ^2.3 . You can do this using the add command.","title":"Update libraries"},{"location":"environment/poetry_new_project/#options","text":"--dry-run : Outputs the operations but will not execute anything (implicitly enables \u2013verbose). --no-dev : Do not install dev dependencies. --lock : Do not perform install (only update the lockfile). poetry lock --no-update This makes it possible to remove a dependency from pyproject.toml and update the lock file without upgrading dependencies.","title":"Options"},{"location":"environment/poetry_new_project/#dependency-group","text":"poetry add --group dev httpx","title":"Dependency Group"},{"location":"environment/poetry_new_project/#current-configuration","text":"List the current configuration. $ poetry config --list cache-dir = \"/Users/elxsj/Library/Caches/pypoetry\" experimental.new-installer = true experimental.system-git-client = false installer.max-workers = null installer.no-binary = null installer.parallel = true virtualenvs.create = true virtualenvs.in-project = null virtualenvs.options.always-copy = false virtualenvs.options.no-pip = false virtualenvs.options.no-setuptools = false virtualenvs.options.system-site-packages = false virtualenvs.path = \"{cache-dir}/virtualenvs\" # /Users/elxsj/Library/Caches/pypoetry/virtualenvs virtualenvs.prefer-active-python = false virtualenvs.prompt = \"{project_name}-py{python_version}\" Check the Path and Executable for this poetry environment: $ poetry env info System Platform: darwin OS: posix Python: 3.10.0 Path: /Users/elxsj/.pyenv/versions/3.10.0 Executable: /Users/elxsj/.pyenv/versions/3.10.0/bin/python3.10","title":"Current Configuration"},{"location":"environment/poetry_new_project/#poetry-export","text":"If you have a Poetry project, you can create a requirements.txt file from your poetry.lock file: poetry export --output requirements.txt","title":"Poetry Export"},{"location":"environment/poetry_new_project/#poetry-commands","text":"Create a new project, create a virtual envrionment and add and remove dependencies using these commands: Command Description poetry new [package-name] Start a new Python Project. poetry init Create a pyproject.toml file interactively. poetry install Install the packages inside the pyproject.toml file. poetry add [package-name] Add a package to a Virtual Environment. poetry add -D [package-name] Add a dev package to a Virtual Environment. poetry remove [package-name] Remove a package from a Virtual Environment. poetry remove -D [package-name] Remove a dev package from a Virtual Environment. poetry self:update Update poetry to the latest stable version.","title":"Poetry Commands"},{"location":"environment/poetry_new_project/#environment","text":"poetry env list List all environments poetry env remove env-name Remove environment","title":"Environment"},{"location":"environment/poetry_new_project/#troubleshooting","text":"Some things to try if poetry has unusual errors. poetry cache clear --all . Clear cache rm -f ./poetry.lock poetry install --remove-untracked","title":"Troubleshooting"},{"location":"environment/poetry_new_project/#references","text":"Poetry github https://github.com/python-poetry/poetry","title":"References"},{"location":"environment/proj_environment/","text":"Setup Environment for New Project At the start of this project clone the environment from git and setup the virtual environment. These are one time configurations, only required to run 1x at the beginning of a new project. How to use: Open VSCode or IDE of choice Configure environment For a new project we have to configure a local environment. Skip this if not required. Local Environment Setup Next setup python version in project directory cd ~/ pyenv install 3.8.10 ## install python version for this project pyenv local 3.8.10 ## make this available locally in this directory Initialize poetry for this (existing) project. poetry init ## follow the prompt to setup new project poetry install ## install packages and create virtualenv Set vscode python interpreter in VSCode. The python interpreter path must be set using the poetry env path. $ poetry env info --path Save the path from this output, it should look like this: /Users/elxsj/Library/Caches/pypoetry/virtualenvs/gh-pages-_kCswBDT-py3.10 Each IDE has a similar process to setting the python interpreter path. In VSCode, we set the python interpreter path by navigating to VSCode command pallete, e.g. View >> command pallete and search for python interpreter. Insert the path saved in the last step and open a new shell to verify the poetry environment is working. Manually invoke this environment in the project; source /Users/elxsj/Library/Caches/pypoetry/virtualenvs/gh-pages-_kCswBDT-py3.10/bin/activate Next, confirm the virualenvs is declared in the .toml file for the poetry environment. [virtualenvs] create = true in-project = true Install python libraries from requirements.txt make install Docker Build docker container from laptop. The build step takes ~15 minutes the first time. Run the contatiner to make sure the predictions are working as expected. docker build -t local-fastapi:v0.1 -f Dockerfile_pip . ## docker run -d --name mycontainer -p 80:80 myimage docker run --rm --name local-fastapi -p 8000:8000 local-fastapi docker run -d --name hf_ghcr -p 8000:8000 local-fastapi GH Actions Github Actions uses GH container registry to store the docker image.","title":"Environment Setup"},{"location":"environment/proj_environment/#setup-environment-for-new-project","text":"At the start of this project clone the environment from git and setup the virtual environment. These are one time configurations, only required to run 1x at the beginning of a new project. How to use: Open VSCode or IDE of choice Configure environment For a new project we have to configure a local environment. Skip this if not required.","title":"Setup Environment for New Project"},{"location":"environment/proj_environment/#local-environment-setup","text":"Next setup python version in project directory cd ~/ pyenv install 3.8.10 ## install python version for this project pyenv local 3.8.10 ## make this available locally in this directory Initialize poetry for this (existing) project. poetry init ## follow the prompt to setup new project poetry install ## install packages and create virtualenv","title":"Local Environment Setup"},{"location":"environment/proj_environment/#set-vscode-python-interpreter-in-vscode","text":"The python interpreter path must be set using the poetry env path. $ poetry env info --path Save the path from this output, it should look like this: /Users/elxsj/Library/Caches/pypoetry/virtualenvs/gh-pages-_kCswBDT-py3.10 Each IDE has a similar process to setting the python interpreter path. In VSCode, we set the python interpreter path by navigating to VSCode command pallete, e.g. View >> command pallete and search for python interpreter. Insert the path saved in the last step and open a new shell to verify the poetry environment is working. Manually invoke this environment in the project; source /Users/elxsj/Library/Caches/pypoetry/virtualenvs/gh-pages-_kCswBDT-py3.10/bin/activate Next, confirm the virualenvs is declared in the .toml file for the poetry environment. [virtualenvs] create = true in-project = true Install python libraries from requirements.txt make install","title":"Set vscode python interpreter in VSCode."},{"location":"environment/proj_environment/#docker","text":"Build docker container from laptop. The build step takes ~15 minutes the first time. Run the contatiner to make sure the predictions are working as expected. docker build -t local-fastapi:v0.1 -f Dockerfile_pip . ## docker run -d --name mycontainer -p 80:80 myimage docker run --rm --name local-fastapi -p 8000:8000 local-fastapi docker run -d --name hf_ghcr -p 8000:8000 local-fastapi","title":"Docker"},{"location":"environment/proj_environment/#gh-actions","text":"Github Actions uses GH container registry to store the docker image.","title":"GH Actions"},{"location":"environment/pyenv_cheatsheet/","text":"PYENV Install pyenv brew install pyenv brew install pyenv pyenv-virtualenv Next we update bash_profile export PATH=\"$HOME/.pyenv/bin:$PATH\" eval \"$(pyenv init -)\" eval \"$(pyenv virtualenv-init -)\" eval \"$(pyenv init -path)\" eval \"$(pyenv virtualenv-init -)\" alias brew='env PATH=\"${PATH//$(pyenv root)\\/shims:/}\" brew' Restart shell so changes take effect: exec \"$SHELL\" Tutorials Working With Multiple Environments https://realpython.com/intro-to-pyenv/#working-with-multiple-environments Managing multiple python versions with pyenv https://realpython.com/intro-to-pyenv/ https://wilsonmar.github.io/pyenv/ https://switowski.com/blog/pyenv https://unop.uk/python-pyenv-shims-not-in-path-fix/ List all available python versions You have many versions of Python to choose from. The list of all versions is long, however to see only the available CPython 3.6 through 3.8, you can do this: pyenv install --list | grep \" 3\\.[678]\" Create pyenv local project for aws-sso pyenv local changes the Python version only for the current folder and all the subfolders. That\u2019s exactly what you want for your project - you want to use a different Python version in this folder without changing the global one. pyenv local command creates a .python-version file in the current directory and puts the version number inside. When pyenv tries to determine what Python version it should use, it will search for that file in the current folder and all the parent folders. If it finds one, it uses the version specified in that file. And if it gets all the way up to your home folder without finding the .python-version , it will use the global version. cd ~/aws-sso pyenv install 3.8.10 pyenv local 3.8.10 This will create a .python-version file in the folder indicating the current local Python version for the project. Also, if you run python -V in that folder, you will see the local version, and not the global one. verify python version python -V 3.8.10 Verify all versions installed to laptop ls ~/.pyenv/versions 3.8.10 3.9.0 pyenv versions system * 3.8.10 (set by /Users/elxsj/aws_sso/.python-version) 3.9.0 pyenv versions pyenv shell 3.8.10 pyenv shell pyenv which pip3 /Users/elxsj/.pyenv/versions/3.8.10/bin/pip3 ENV var Verify $PYENV_VERSION environment variable: echo $PYENV_VERSION pip freeze > requirements.txt # list libraries installed pip install -r requirements.txt # import libraries","title":"Pyenv"},{"location":"environment/pyenv_cheatsheet/#pyenv","text":"","title":"PYENV"},{"location":"environment/pyenv_cheatsheet/#install-pyenv","text":"brew install pyenv brew install pyenv pyenv-virtualenv Next we update bash_profile export PATH=\"$HOME/.pyenv/bin:$PATH\" eval \"$(pyenv init -)\" eval \"$(pyenv virtualenv-init -)\" eval \"$(pyenv init -path)\" eval \"$(pyenv virtualenv-init -)\" alias brew='env PATH=\"${PATH//$(pyenv root)\\/shims:/}\" brew' Restart shell so changes take effect: exec \"$SHELL\"","title":"Install pyenv"},{"location":"environment/pyenv_cheatsheet/#tutorials","text":"Working With Multiple Environments https://realpython.com/intro-to-pyenv/#working-with-multiple-environments Managing multiple python versions with pyenv https://realpython.com/intro-to-pyenv/ https://wilsonmar.github.io/pyenv/ https://switowski.com/blog/pyenv https://unop.uk/python-pyenv-shims-not-in-path-fix/","title":"Tutorials"},{"location":"environment/pyenv_cheatsheet/#list-all-available-python-versions","text":"You have many versions of Python to choose from. The list of all versions is long, however to see only the available CPython 3.6 through 3.8, you can do this: pyenv install --list | grep \" 3\\.[678]\"","title":"List all available python versions"},{"location":"environment/pyenv_cheatsheet/#create-pyenv-local-project-for-aws-sso","text":"pyenv local changes the Python version only for the current folder and all the subfolders. That\u2019s exactly what you want for your project - you want to use a different Python version in this folder without changing the global one. pyenv local command creates a .python-version file in the current directory and puts the version number inside. When pyenv tries to determine what Python version it should use, it will search for that file in the current folder and all the parent folders. If it finds one, it uses the version specified in that file. And if it gets all the way up to your home folder without finding the .python-version , it will use the global version. cd ~/aws-sso pyenv install 3.8.10 pyenv local 3.8.10 This will create a .python-version file in the folder indicating the current local Python version for the project. Also, if you run python -V in that folder, you will see the local version, and not the global one.","title":"Create pyenv local project for aws-sso"},{"location":"environment/pyenv_cheatsheet/#verify-python-version","text":"python -V 3.8.10","title":"verify python version"},{"location":"environment/pyenv_cheatsheet/#verify-all-versions-installed-to-laptop","text":"ls ~/.pyenv/versions 3.8.10 3.9.0 pyenv versions system * 3.8.10 (set by /Users/elxsj/aws_sso/.python-version) 3.9.0 pyenv versions pyenv shell 3.8.10 pyenv shell pyenv which pip3 /Users/elxsj/.pyenv/versions/3.8.10/bin/pip3","title":"Verify all versions installed to laptop"},{"location":"environment/pyenv_cheatsheet/#env-var","text":"Verify $PYENV_VERSION environment variable: echo $PYENV_VERSION pip freeze > requirements.txt # list libraries installed pip install -r requirements.txt # import libraries","title":"ENV var"},{"location":"environment/pyproject_toml/","text":"Simple pyproject.toml An example .toml for use in poetry virtual environments. [tool.poetry] name = \"huggingface_ghcr\" version = \"0.1.0\" description = \"\" authors = [\"memadsen <michael.madsen@bayer.com>\"] [tool.poetry.dependencies] python = \"^3.8\" transformers = \"4.20.1\" fastapi = \"0.78.0\" uvicorn = {extras = [\"standard\"], version = \"^0.18.3\"} tensorflow = \"2.10.0\" [tool.poetry.dev-dependencies] [build-system] requires = [\"poetry-core>=1.0.0\"] build-backend = \"poetry.core.masonry.api\" [virtualenvs] create = true in-project = true","title":"Poetry toml"},{"location":"environment/pyproject_toml/#simple-pyprojecttoml","text":"An example .toml for use in poetry virtual environments. [tool.poetry] name = \"huggingface_ghcr\" version = \"0.1.0\" description = \"\" authors = [\"memadsen <michael.madsen@bayer.com>\"] [tool.poetry.dependencies] python = \"^3.8\" transformers = \"4.20.1\" fastapi = \"0.78.0\" uvicorn = {extras = [\"standard\"], version = \"^0.18.3\"} tensorflow = \"2.10.0\" [tool.poetry.dev-dependencies] [build-system] requires = [\"poetry-core>=1.0.0\"] build-backend = \"poetry.core.masonry.api\" [virtualenvs] create = true in-project = true","title":"Simple pyproject.toml"},{"location":"environment/python/","text":"python path Where does python live on my laptop? which python3 /usr/local/bin/python3 ## ---- This is a symbolic link ## ---- Locate actual python3 executable ls -al /usr/local/bin/python3 lrwxr-xr-x 1 elxsj admin 40 Oct 10 20:15 /usr/local/bin/python3 -> ../Cellar/python@3.10/3.10.7/bin/python3 Application Main def main(): print(\"hello, world\") if __name__ == '__main__' main()","title":"Python"},{"location":"environment/python/#python-path","text":"Where does python live on my laptop? which python3 /usr/local/bin/python3 ## ---- This is a symbolic link ## ---- Locate actual python3 executable ls -al /usr/local/bin/python3 lrwxr-xr-x 1 elxsj admin 40 Oct 10 20:15 /usr/local/bin/python3 -> ../Cellar/python@3.10/3.10.7/bin/python3","title":"python path"},{"location":"environment/python/#application-main","text":"def main(): print(\"hello, world\") if __name__ == '__main__' main()","title":"Application Main"},{"location":"environment/vscode/","text":"settings In project root navigate to .vscode directory and open settings.json { \"python.pythonPath\": \"/Users/elxsj/Library/Caches/pypoetry/virtualenvs/poetry-pyenv-uqIKaYYi-py3.10\" }","title":"VS Code"},{"location":"environment/vscode/#settings","text":"In project root navigate to .vscode directory and open settings.json { \"python.pythonPath\": \"/Users/elxsj/Library/Caches/pypoetry/virtualenvs/poetry-pyenv-uqIKaYYi-py3.10\" }","title":"settings"},{"location":"gh_actions/broken_links_report/","text":"Report Broken URL Links Technical documentation requires URL links. These links provide essential support for robust programmatic methods. Broken URL links are easy to test and fix. This is a great use case for unit testing. Unit testing evaluates atomic elements of code; the objective is to isolate discrete parts of the code for testing. The devdocs static HTML site is a great use case for unit testing. There are hundreds of files and each file can contain multiple URLs. Manual editing to fix will never happen, so automation summarizes the work for efficiency. Also, project management tools are not productive for this problem. Summary Enable github repo to test for broken url links Review report Read the report for our team devdocs github repo: https://github.com/bayer-int/smol-cls-cloud-docs navigate to issues Open the issue with the report, showing something similar to \"Link Checker Report\". The summary shows the total URL links reviewed \"Total\" (1,166) and \"Errors\" (115). Each markdown file is displayed with URL errors. The network error should also be displayed. Developers can search for their individual files and make corrections.","title":"Broken URL Report"},{"location":"gh_actions/broken_links_report/#report-broken-url-links","text":"Technical documentation requires URL links. These links provide essential support for robust programmatic methods. Broken URL links are easy to test and fix. This is a great use case for unit testing. Unit testing evaluates atomic elements of code; the objective is to isolate discrete parts of the code for testing. The devdocs static HTML site is a great use case for unit testing. There are hundreds of files and each file can contain multiple URLs. Manual editing to fix will never happen, so automation summarizes the work for efficiency. Also, project management tools are not productive for this problem.","title":"Report Broken URL Links"},{"location":"gh_actions/broken_links_report/#summary","text":"Enable github repo to test for broken url links Review report Read the report for our team devdocs github repo: https://github.com/bayer-int/smol-cls-cloud-docs navigate to issues Open the issue with the report, showing something similar to \"Link Checker Report\". The summary shows the total URL links reviewed \"Total\" (1,166) and \"Errors\" (115). Each markdown file is displayed with URL errors. The network error should also be displayed. Developers can search for their individual files and make corrections.","title":"Summary"},{"location":"gh_actions/build-push-image/","text":"Github Actions Build and Push Image to Repository Package Manager No PAT required. This github action uses the GITHUB_TOKEN , available to each repository. # Checkout the files from the Git repository. # Login to the ghcr.io container registry. # Setup Docker # Get metadata for use later in Docker. This avoids having to do manual work to set up the tags and labels for the Docker images. # Finally, build the image and push it. The build and push has two steps name: Docker Build & Publish to GitHub Container Registry on: push: branches: - 'main' # anything under a build/ folder will be used as testing the build processes. # - 'build/*' tags: - 'v*' workflow_dispatch: inputs: git-ref: description: Git Ref (Optional) required: false env: REGISTRY: ghcr.io IMAGE_NAME: ${{ github.repository }} jobs: build-and-push-docker-image: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Log into registry ${{ env.REGISTRY }} uses: docker/login-action@v1 with: registry: ${{ env.REGISTRY }} username: ${{ github.actor }} password: ${{ secrets.GITHUB_TOKEN }} - name: Setup Docker buildx uses: docker/setup-buildx-action@v1 - name: Extract Docker metadata id: meta uses: docker/metadata-action@v2 with: images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} # - name: Build and Push Versioned Docker Image # id: build-and-push # uses: docker/build-push-action@v2 # if: ${{ github.ref != 'refs/heads/main' }} # with: # context: ./build-push-image # push: true # tags: ${{ steps.meta.outputs.tags }} # labels: ${{ steps.meta.outputs.labels }} - name: Build and Push Latest Docker Image id: build-and-push-latest uses: docker/build-push-action@v2 if: ${{ github.ref == 'refs/heads/main' }} with: context: ./build-push-image push: true tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest labels: ${{ steps.meta.outputs.labels }}","title":"Build and Push Image to ghcr"},{"location":"gh_actions/build-push-image/#github-actions-build-and-push-image-to-repository-package-manager","text":"No PAT required. This github action uses the GITHUB_TOKEN , available to each repository. # Checkout the files from the Git repository. # Login to the ghcr.io container registry. # Setup Docker # Get metadata for use later in Docker. This avoids having to do manual work to set up the tags and labels for the Docker images. # Finally, build the image and push it. The build and push has two steps name: Docker Build & Publish to GitHub Container Registry on: push: branches: - 'main' # anything under a build/ folder will be used as testing the build processes. # - 'build/*' tags: - 'v*' workflow_dispatch: inputs: git-ref: description: Git Ref (Optional) required: false env: REGISTRY: ghcr.io IMAGE_NAME: ${{ github.repository }} jobs: build-and-push-docker-image: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 - name: Log into registry ${{ env.REGISTRY }} uses: docker/login-action@v1 with: registry: ${{ env.REGISTRY }} username: ${{ github.actor }} password: ${{ secrets.GITHUB_TOKEN }} - name: Setup Docker buildx uses: docker/setup-buildx-action@v1 - name: Extract Docker metadata id: meta uses: docker/metadata-action@v2 with: images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} # - name: Build and Push Versioned Docker Image # id: build-and-push # uses: docker/build-push-action@v2 # if: ${{ github.ref != 'refs/heads/main' }} # with: # context: ./build-push-image # push: true # tags: ${{ steps.meta.outputs.tags }} # labels: ${{ steps.meta.outputs.labels }} - name: Build and Push Latest Docker Image id: build-and-push-latest uses: docker/build-push-action@v2 if: ${{ github.ref == 'refs/heads/main' }} with: context: ./build-push-image push: true tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest labels: ${{ steps.meta.outputs.labels }}","title":"Github Actions Build and Push Image to Repository Package Manager"},{"location":"gh_actions/cachetest/","text":"Caching Docker builds in github actions: Which approach is fastest? https://dev.to/dtinth/caching-docker-builds-in-github-actions-which-approach-is-the-fastest-a-research-18ei Abstract: In this post, I experimented with 6 different approaches for caching Docker builds in GitHub Actions to speed up the build process and compared the results. After trying out every approach, 10 times each, the results show that using GitHub Packages\u2019 Docker registry as a build cache, as opposed to GitHub Actions\u2019 built-in cache, yields the highest performance gain. Unlike self-hosted runners like Jenkins, most cloud-hosted build runners are stateless, providing us with a pristine environment each run. We cannot keep files from the previous runs around; anything that needs to be persisted must be externalized. GitHub Actions has a built-in cache to help do this. But there are many ways of creating that cache ( docker save and docker load first comes to mind). Will the performance gains outweight the overhead caused by saving and loading caches? Are there more approaches other than using GitHub Action\u2019s built-in cache? That\u2019s what this research is about. Dockerfile FROM node:14.21.2 RUN yarn create react-app my-react-app RUN cd my-react-app && yarn build RUN npm install -g @vue/cli && (yes | vue create my-vue-app --default) RUN cd my-vue-app && yarn build RUN mkdir -p my-tests && cd my-tests && yarn add playwright # test # test # test # test # test # test # test # test # test # test","title":"Cache Testing"},{"location":"gh_actions/cachetest/#caching-docker-builds-in-github-actions-which-approach-is-fastest","text":"https://dev.to/dtinth/caching-docker-builds-in-github-actions-which-approach-is-the-fastest-a-research-18ei","title":"Caching Docker builds in github actions: Which approach is fastest?"},{"location":"gh_actions/cachetest/#abstract","text":"In this post, I experimented with 6 different approaches for caching Docker builds in GitHub Actions to speed up the build process and compared the results. After trying out every approach, 10 times each, the results show that using GitHub Packages\u2019 Docker registry as a build cache, as opposed to GitHub Actions\u2019 built-in cache, yields the highest performance gain. Unlike self-hosted runners like Jenkins, most cloud-hosted build runners are stateless, providing us with a pristine environment each run. We cannot keep files from the previous runs around; anything that needs to be persisted must be externalized. GitHub Actions has a built-in cache to help do this. But there are many ways of creating that cache ( docker save and docker load first comes to mind). Will the performance gains outweight the overhead caused by saving and loading caches? Are there more approaches other than using GitHub Action\u2019s built-in cache? That\u2019s what this research is about.","title":"Abstract:"},{"location":"gh_actions/cachetest/#dockerfile","text":"FROM node:14.21.2 RUN yarn create react-app my-react-app RUN cd my-react-app && yarn build RUN npm install -g @vue/cli && (yes | vue create my-vue-app --default) RUN cd my-vue-app && yarn build RUN mkdir -p my-tests && cd my-tests && yarn add playwright # test # test # test # test # test # test # test # test # test # test","title":"Dockerfile"},{"location":"gh_actions/dependabot/","text":"Github Actions Dependabot Create pull requests to keep dependencies up-to-date. version: 2 updates: - package-ecosystem: \"github-actions\" directory: \"/\" schedule: interval: \"weekly\" labels: \"github-actions-dependencies\" assignees: - \"memadsen\" - package-ecosystem: \"pip\" # poetry directory: \"/\" schedule: interval: \"weekly\" labels: \"python-dependencies\" assignees: - \"memadsen\"","title":"Requirements Dependabot"},{"location":"gh_actions/dependabot/#github-actions","text":"","title":"Github Actions"},{"location":"gh_actions/dependabot/#dependabot","text":"Create pull requests to keep dependencies up-to-date. version: 2 updates: - package-ecosystem: \"github-actions\" directory: \"/\" schedule: interval: \"weekly\" labels: \"github-actions-dependencies\" assignees: - \"memadsen\" - package-ecosystem: \"pip\" # poetry directory: \"/\" schedule: interval: \"weekly\" labels: \"python-dependencies\" assignees: - \"memadsen\"","title":"Dependabot"},{"location":"gh_actions/docker_build_push/","text":"Docker Build and Push Image Use github actions to build and push an image to github packages. Source code has an example. The background displayed in these repos is out of scope with the utility of github actions and docker. In this document I reduce the problem to focus on using github actions for docker development (building and debugging docker containers). Artifactory and ECR are optimal however I simplify the problem by ignoring these options and use the repository for hosting the image. hf_ghcr repo in bayer-int huggingface_ghcr repo in memadsen Github Action To authenticate to a GitHub Packages registry within a GitHub Actions workflow, you can use: GITHUB_TOKEN to publish packages associated with the workflow repository. a personal access token (classic) with at least read:packages scope to install packages associated with other private repositories (which GITHUB_TOKEN can't access). Authenticate to github, on behalf of github actions using GITHUB_TOKEN . This allows us to write our docker container to github. Github Actions documentation on token authentication name: docker_build_push on: workflow_dispatch: jobs: build: runs-on:: ubuntu-latest steps: - uses: actions/checkout@v2 - name: docker build python run: | docker build ./python -t name: CI on: workflow_dispatch: jobs: # This workflow contains a single job called \"build\" build: runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v3 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v1 - name: Authenticate to GitHub container registry uses: docker/login-action@v1.10.0 with: registry: ghcr.io username: ${{ github.actor }} password: ${{ secrets.GITHUB_TOKEN }} #password: ${{ github.token }} - name: Lowercase the repo name and username run: echo \"REPO=${GITHUB_REPOSITORY,,}\" >>${GITHUB_ENV} - name: Build and push container image to registry uses: docker/build-push-action@v2 with: push: true tags: ghcr.io/${{ env.REPO }}:${{ github.sha }} file: ./Dockerfile_pip Dockerfile FROM python:3.9 WORKDIR /code COPY ./requirements.txt /code/requirements.txt RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt COPY ./app /code/app CMD [\"uvicorn\", \"app.main:app\", \"--proxy-headers\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"] Python 3.7.5 dockerfile FROM python:3.7.5-slim # Set up and activate virtual environment ENV VIRTUAL_ENV \"/venv\" RUN python -m venv $VIRTUAL_ENV ENV PATH \"$VIRTUAL_ENV/bin:$PATH\" # Python commands run inside the virtual environment RUN python -m pip install \\ parse \\ realpython-reader Python Latest dockerfile Code for hello.py is print (\"Hello World\") Code for a.py is print (\"Overriden Hello\") #Deriving the latest base image FROM python:latest #Labels as key value pair LABEL Maintainer=\"michael.madsen@bayer.com\" ADD hello.py /home/hello.py ADD a.py /home/a.py CMD [\"/home/hello.py\"] ENTRYPOINT [\"python\"]","title":"Docker Build and Push"},{"location":"gh_actions/docker_build_push/#docker-build-and-push-image","text":"Use github actions to build and push an image to github packages. Source code has an example. The background displayed in these repos is out of scope with the utility of github actions and docker. In this document I reduce the problem to focus on using github actions for docker development (building and debugging docker containers). Artifactory and ECR are optimal however I simplify the problem by ignoring these options and use the repository for hosting the image. hf_ghcr repo in bayer-int huggingface_ghcr repo in memadsen","title":"Docker Build and Push Image"},{"location":"gh_actions/docker_build_push/#github-action","text":"To authenticate to a GitHub Packages registry within a GitHub Actions workflow, you can use: GITHUB_TOKEN to publish packages associated with the workflow repository. a personal access token (classic) with at least read:packages scope to install packages associated with other private repositories (which GITHUB_TOKEN can't access). Authenticate to github, on behalf of github actions using GITHUB_TOKEN . This allows us to write our docker container to github. Github Actions documentation on token authentication name: docker_build_push on: workflow_dispatch: jobs: build: runs-on:: ubuntu-latest steps: - uses: actions/checkout@v2 - name: docker build python run: | docker build ./python -t name: CI on: workflow_dispatch: jobs: # This workflow contains a single job called \"build\" build: runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v3 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v1 - name: Authenticate to GitHub container registry uses: docker/login-action@v1.10.0 with: registry: ghcr.io username: ${{ github.actor }} password: ${{ secrets.GITHUB_TOKEN }} #password: ${{ github.token }} - name: Lowercase the repo name and username run: echo \"REPO=${GITHUB_REPOSITORY,,}\" >>${GITHUB_ENV} - name: Build and push container image to registry uses: docker/build-push-action@v2 with: push: true tags: ghcr.io/${{ env.REPO }}:${{ github.sha }} file: ./Dockerfile_pip","title":"Github Action"},{"location":"gh_actions/docker_build_push/#dockerfile","text":"FROM python:3.9 WORKDIR /code COPY ./requirements.txt /code/requirements.txt RUN pip install --no-cache-dir --upgrade -r /code/requirements.txt COPY ./app /code/app CMD [\"uvicorn\", \"app.main:app\", \"--proxy-headers\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]","title":"Dockerfile"},{"location":"gh_actions/docker_build_push/#python-375-dockerfile","text":"FROM python:3.7.5-slim # Set up and activate virtual environment ENV VIRTUAL_ENV \"/venv\" RUN python -m venv $VIRTUAL_ENV ENV PATH \"$VIRTUAL_ENV/bin:$PATH\" # Python commands run inside the virtual environment RUN python -m pip install \\ parse \\ realpython-reader","title":"Python 3.7.5 dockerfile"},{"location":"gh_actions/docker_build_push/#python-latest-dockerfile","text":"Code for hello.py is print (\"Hello World\") Code for a.py is print (\"Overriden Hello\") #Deriving the latest base image FROM python:latest #Labels as key value pair LABEL Maintainer=\"michael.madsen@bayer.com\" ADD hello.py /home/hello.py ADD a.py /home/a.py CMD [\"/home/hello.py\"] ENTRYPOINT [\"python\"]","title":"Python Latest dockerfile"},{"location":"gh_actions/ecr_actions_workflow/","text":"CICD Pipeline for Docker Images This is a new repository using DevOps best practices and Python. A project scaffold is setup to use cloud microservices in a CICD workflow. This scaffold can be modified to fit a typical data science project. Access this code at (bayer-int/smol-cls-ecr)[https://github.com/bayer-int/smol-cls-ecr] Summary Build production docker images using CICD pipeline (GH Actions), lint docker/python and push to AWS ECR. Authentication using OIDC is preferred, because there are no keys/secrets to manage. GH Actions is used to build a docker image and directly pushed to ECR from GH Actions. MLOps Best Practices My web application is a microservice flowchart LR CICD(CICD) --> Container(Container) Microservice(Microservice) Container --> Microservice fxn(Function) <--> Web(Web) Microservice --> fxn Scaffold My preferred process for every new project. This GitHub repo has all the ingredients for a building a container based API deployed to AWS: Makefile , requirements.txt , virtual environment, directory structure, application files, application test files and Dockerfile . flowchart LR GH(GitHub Checkout) --> code(Codebase <br> _______ <br> - App Scripts <br> - App Directories <br> - Test App Logic <br> - Virtual Environment <br> - Library Requirements <br> - Container) The Makefile and GH Actions .yml orchestrate all the logic. This minimizes debugging and collaboration/ramping-up. The GH Actions runner implements directly from the Makefile . In addition the Makefile can be used for early development in local environment. Production code should run exactly like local code but in practice something usually breaks and minor manual changes are required; typically there is a bias towards production. Project Makefile : install: # Install Py lib pip install --upgrade pip &&\\ pip install -r requirements.txt #cat requirements.txt | xargs poetry add post-install: python -m textblob.download_corpora git: # Update Git Repo bash sync_git.sh format: # format code using black black *.py mylib/*.py lint: # format code using pylint or flake8 pylint --disable=R,C *.py mylib/*.py test: # test code python -m pytest -vv --cov=mylib --cov=main test_*.py build: #build container docker build -t deploy-fastapi . run: #run docker docker run -p 127.0.0.1:8080:8080 deploy-fastapi deploy: aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 722540083300.dkr.ecr.us-east-1.amazonaws.com docker build -t smol-cls-ecr . ## This is the ECR name docker tag smol-cls-ecr:latest 722540083300.dkr.ecr.us-east-1.amazonaws.com/smol-cls-ecr:latest docker push 722540083300.dkr.ecr.us-east-1.amazonaws.com/smol-cls-ecr:latest all: install post-install lint test deploy Development Write code in local environment, use GH Actions to test and then deploy to AWS. Workflow OIDC authenticate Allow GH Actions to authenticate to AWS using OIDC. Build docker image using GH Actions and push to ECR. In your cloud provider, create an OIDC trust between your cloud role and your GitHub workflow(s) that need access to the cloud. Every time your job runs, GitHub's OIDC Provider auto-generates an OIDC token. This token contains multiple claims to establish a security-hardened and verifiable identity about the specific workflow that is trying to authenticate. You could include a step or action in your job to request this token from GitHub's OIDC provider, and present it to the cloud provider. Once the cloud provider successfully validates the claims presented in the token, it then provides a short-lived cloud access token that is available only for the duration of the job. :closed_book: For more information see the github docs for security hardening production deployments link: https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect AWS Create Service catalog product [ ] TODO Launch this CF stack using CLI. This project is currently provisioned using the AWS console for CF and IAM. Start Work: Navigate to AWS Console. From the AWS console >> Service Catalog >> Products the github-oidc-provider will show up like this: Next, build CloudFormation stack for cloud engineering product: github oidc provider . In CloudFormation parameters set bayer-int and repo name smol-cls-cicd :pencil: Update repo name for each new project. Next set CF parameters. parameter content required GitHub org bayer-int true OIDCProviderArn When catalog item was already used once. Use arn of generated OIDC Provider. false Repository Name Technical name of the repository, as seen in the url. e.g smol-cls-cicd true AWS IAM setup Trusted entitites policy is attached during CloudFormation build. It should look like this: { \"Version\": \"2008-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Federated\": \"arn:aws:iam::722540083300:oidc-provider/token.actions.githubusercontent.com\", \"AWS\": \"arn:aws:iam::722540083300:role/cloudops\" }, \"Action\": \"sts:AssumeRoleWithWebIdentity\", \"Condition\": { \"StringLike\": { \"token.actions.githubusercontent.com:sub\": \"repo:bayer-int/smol-cls-mwaa-cicd:*\" } } }, { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::722540083300:role/cloudops\" }, \"Action\": \"sts:AssumeRole\" } ] } Attach ECR policy to OIDC role Attach existing policies directly. In \"find policies\" search for AmazonEC2ContainerRegistryFullAccess and check it which will give this User Account permission to push on Private ECR. GitHub Actions Add file for GH Actions and document workflow events. A simple project has the following directories: \u251c\u2500\u2500 .github \u2502 \u2514\u2500\u2500 workflows \u2502 \u2514\u2500\u2500 deploy_ecr.yml ## GitHub Actions \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 Dockerfile ## Dockerfile in project root \u251c\u2500\u2500 Makefile ## Makefile instructs my GH Actions \u251c\u2500\u2500 README.md \u251c\u2500\u2500 img \u251c\u2500\u2500 main.py \u251c\u2500\u2500 mylib ## python logic \u251c\u2500\u2500 requirements.txt ## virtual environment \u251c\u2500\u2500 sync_git.sh ## optional sync git \u2514\u2500\u2500 test_main.py Include GitHub actions permissions ## This allows your GitHub Actions job to save the temporary ## credentials it gets when authenticating with the Cloud Provider. permissions: contents: 'read' id-token: 'write' Use the aws-actions/configure-aws-credentials action. - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v1 with: role-to-assume: arn:aws:iam::123456789100:role/github-actions-role aws-region: eu-east-1 Test GH Actions server runs as expected Push code to git Verify docker image is in ECR Reference This project builds from the OIDC auth method documented in Bayer go docs. To review the details go to Authenticate to Cloud - Bayer go docs End","title":"ECR Build & Push"},{"location":"gh_actions/ecr_actions_workflow/#cicd-pipeline-for-docker-images","text":"This is a new repository using DevOps best practices and Python. A project scaffold is setup to use cloud microservices in a CICD workflow. This scaffold can be modified to fit a typical data science project. Access this code at (bayer-int/smol-cls-ecr)[https://github.com/bayer-int/smol-cls-ecr]","title":"CICD Pipeline for Docker Images"},{"location":"gh_actions/ecr_actions_workflow/#summary","text":"Build production docker images using CICD pipeline (GH Actions), lint docker/python and push to AWS ECR. Authentication using OIDC is preferred, because there are no keys/secrets to manage. GH Actions is used to build a docker image and directly pushed to ECR from GH Actions.","title":"Summary"},{"location":"gh_actions/ecr_actions_workflow/#mlops-best-practices","text":"My web application is a microservice flowchart LR CICD(CICD) --> Container(Container) Microservice(Microservice) Container --> Microservice fxn(Function) <--> Web(Web) Microservice --> fxn","title":"MLOps Best Practices"},{"location":"gh_actions/ecr_actions_workflow/#scaffold","text":"My preferred process for every new project. This GitHub repo has all the ingredients for a building a container based API deployed to AWS: Makefile , requirements.txt , virtual environment, directory structure, application files, application test files and Dockerfile . flowchart LR GH(GitHub Checkout) --> code(Codebase <br> _______ <br> - App Scripts <br> - App Directories <br> - Test App Logic <br> - Virtual Environment <br> - Library Requirements <br> - Container) The Makefile and GH Actions .yml orchestrate all the logic. This minimizes debugging and collaboration/ramping-up. The GH Actions runner implements directly from the Makefile . In addition the Makefile can be used for early development in local environment. Production code should run exactly like local code but in practice something usually breaks and minor manual changes are required; typically there is a bias towards production.","title":"Scaffold"},{"location":"gh_actions/ecr_actions_workflow/#project-makefile","text":"install: # Install Py lib pip install --upgrade pip &&\\ pip install -r requirements.txt #cat requirements.txt | xargs poetry add post-install: python -m textblob.download_corpora git: # Update Git Repo bash sync_git.sh format: # format code using black black *.py mylib/*.py lint: # format code using pylint or flake8 pylint --disable=R,C *.py mylib/*.py test: # test code python -m pytest -vv --cov=mylib --cov=main test_*.py build: #build container docker build -t deploy-fastapi . run: #run docker docker run -p 127.0.0.1:8080:8080 deploy-fastapi deploy: aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 722540083300.dkr.ecr.us-east-1.amazonaws.com docker build -t smol-cls-ecr . ## This is the ECR name docker tag smol-cls-ecr:latest 722540083300.dkr.ecr.us-east-1.amazonaws.com/smol-cls-ecr:latest docker push 722540083300.dkr.ecr.us-east-1.amazonaws.com/smol-cls-ecr:latest all: install post-install lint test deploy","title":"Project Makefile:"},{"location":"gh_actions/ecr_actions_workflow/#development","text":"Write code in local environment, use GH Actions to test and then deploy to AWS.","title":"Development"},{"location":"gh_actions/ecr_actions_workflow/#workflow","text":"","title":"Workflow"},{"location":"gh_actions/ecr_actions_workflow/#oidc-authenticate","text":"Allow GH Actions to authenticate to AWS using OIDC. Build docker image using GH Actions and push to ECR. In your cloud provider, create an OIDC trust between your cloud role and your GitHub workflow(s) that need access to the cloud. Every time your job runs, GitHub's OIDC Provider auto-generates an OIDC token. This token contains multiple claims to establish a security-hardened and verifiable identity about the specific workflow that is trying to authenticate. You could include a step or action in your job to request this token from GitHub's OIDC provider, and present it to the cloud provider. Once the cloud provider successfully validates the claims presented in the token, it then provides a short-lived cloud access token that is available only for the duration of the job. :closed_book: For more information see the github docs for security hardening production deployments link: https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/about-security-hardening-with-openid-connect","title":"OIDC authenticate"},{"location":"gh_actions/ecr_actions_workflow/#aws-create-service-catalog-product","text":"[ ] TODO Launch this CF stack using CLI. This project is currently provisioned using the AWS console for CF and IAM. Start Work: Navigate to AWS Console. From the AWS console >> Service Catalog >> Products the github-oidc-provider will show up like this: Next, build CloudFormation stack for cloud engineering product: github oidc provider . In CloudFormation parameters set bayer-int and repo name smol-cls-cicd :pencil: Update repo name for each new project. Next set CF parameters. parameter content required GitHub org bayer-int true OIDCProviderArn When catalog item was already used once. Use arn of generated OIDC Provider. false Repository Name Technical name of the repository, as seen in the url. e.g smol-cls-cicd true","title":"AWS Create Service catalog product"},{"location":"gh_actions/ecr_actions_workflow/#aws-iam-setup","text":"Trusted entitites policy is attached during CloudFormation build. It should look like this: { \"Version\": \"2008-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Federated\": \"arn:aws:iam::722540083300:oidc-provider/token.actions.githubusercontent.com\", \"AWS\": \"arn:aws:iam::722540083300:role/cloudops\" }, \"Action\": \"sts:AssumeRoleWithWebIdentity\", \"Condition\": { \"StringLike\": { \"token.actions.githubusercontent.com:sub\": \"repo:bayer-int/smol-cls-mwaa-cicd:*\" } } }, { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::722540083300:role/cloudops\" }, \"Action\": \"sts:AssumeRole\" } ] }","title":"AWS IAM setup"},{"location":"gh_actions/ecr_actions_workflow/#attach-ecr-policy-to-oidc-role","text":"Attach existing policies directly. In \"find policies\" search for AmazonEC2ContainerRegistryFullAccess and check it which will give this User Account permission to push on Private ECR.","title":"Attach ECR policy to OIDC role"},{"location":"gh_actions/ecr_actions_workflow/#github-actions","text":"Add file for GH Actions and document workflow events. A simple project has the following directories: \u251c\u2500\u2500 .github \u2502 \u2514\u2500\u2500 workflows \u2502 \u2514\u2500\u2500 deploy_ecr.yml ## GitHub Actions \u251c\u2500\u2500 .gitignore \u251c\u2500\u2500 Dockerfile ## Dockerfile in project root \u251c\u2500\u2500 Makefile ## Makefile instructs my GH Actions \u251c\u2500\u2500 README.md \u251c\u2500\u2500 img \u251c\u2500\u2500 main.py \u251c\u2500\u2500 mylib ## python logic \u251c\u2500\u2500 requirements.txt ## virtual environment \u251c\u2500\u2500 sync_git.sh ## optional sync git \u2514\u2500\u2500 test_main.py","title":"GitHub Actions"},{"location":"gh_actions/ecr_actions_workflow/#include-github-actions-permissions","text":"## This allows your GitHub Actions job to save the temporary ## credentials it gets when authenticating with the Cloud Provider. permissions: contents: 'read' id-token: 'write' Use the aws-actions/configure-aws-credentials action. - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v1 with: role-to-assume: arn:aws:iam::123456789100:role/github-actions-role aws-region: eu-east-1","title":"Include GitHub actions permissions"},{"location":"gh_actions/ecr_actions_workflow/#test-gh-actions-server-runs-as-expected","text":"Push code to git Verify docker image is in ECR","title":"Test GH Actions server runs as expected"},{"location":"gh_actions/ecr_actions_workflow/#reference","text":"This project builds from the OIDC auth method documented in Bayer go docs. To review the details go to Authenticate to Cloud - Bayer go docs","title":"Reference"},{"location":"gh_actions/ecr_actions_workflow/#end","text":"","title":"End"},{"location":"gh_actions/env_var/","text":"Github Actions Environment Variables Example jobs.<job_id>.if Only run job for specific repository. This example uses if to control when the production-deploy job can run. It will only run if the repository is named MY_REPO and is within the bayer-int organization. Otherwise, the job will be marked as skipped. github actions workflow syntax docs name: example-workflow on: [push] jobs: production-deploy: if: github.repository == 'bayer-int/MY_REPO' runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-node@v3 with: node-version: '14' - run: echo 'Hello World' Contexts Contexts are a way to access information about workflow runs, variables, runner environments, jobs, and steps. Each context is an object that contains properties, which can be strings or other objects. github actions contexts docs Example usage of vars context This example workflow shows how configuration variables set at the repository, environment, or organization levels are automatically available using the vars context. on: workflow_dispatch: env: # Setting an environment variable with the value of a configuration variable env_var: ${{ vars.ENV_CONTEXT_VAR }} jobs: display-variables: name: ${{ vars.JOB_NAME }} # You can use configuration variables with the `vars` context for dynamic jobs if: ${{ vars.USE_VARIABLES == 'true' }} runs-on: ${{ vars.RUNNER }} environment: ${{ vars.ENVIRONMENT_STAGE }} steps: - name: Use variables run: | echo \"repository variable : ${{ vars.REPOSITORY_VAR }}\" echo \"organization variable : ${{ vars.ORGANIZATION_VAR }}\" echo \"overridden variable : ${{ vars.OVERRIDE_VAR }}\" echo \"variable from shell environment : $env_var\"","title":"Github Actions Environment Variables"},{"location":"gh_actions/env_var/#github-actions-environment-variables","text":"","title":"Github Actions Environment Variables"},{"location":"gh_actions/env_var/#example-jobsjob_idif","text":"Only run job for specific repository. This example uses if to control when the production-deploy job can run. It will only run if the repository is named MY_REPO and is within the bayer-int organization. Otherwise, the job will be marked as skipped. github actions workflow syntax docs name: example-workflow on: [push] jobs: production-deploy: if: github.repository == 'bayer-int/MY_REPO' runs-on: ubuntu-latest steps: - uses: actions/checkout@v3 - uses: actions/setup-node@v3 with: node-version: '14' - run: echo 'Hello World'","title":"Example jobs.&lt;job_id&gt;.if"},{"location":"gh_actions/env_var/#contexts","text":"Contexts are a way to access information about workflow runs, variables, runner environments, jobs, and steps. Each context is an object that contains properties, which can be strings or other objects. github actions contexts docs","title":"Contexts"},{"location":"gh_actions/env_var/#example-usage-of-vars-context","text":"This example workflow shows how configuration variables set at the repository, environment, or organization levels are automatically available using the vars context. on: workflow_dispatch: env: # Setting an environment variable with the value of a configuration variable env_var: ${{ vars.ENV_CONTEXT_VAR }} jobs: display-variables: name: ${{ vars.JOB_NAME }} # You can use configuration variables with the `vars` context for dynamic jobs if: ${{ vars.USE_VARIABLES == 'true' }} runs-on: ${{ vars.RUNNER }} environment: ${{ vars.ENVIRONMENT_STAGE }} steps: - name: Use variables run: | echo \"repository variable : ${{ vars.REPOSITORY_VAR }}\" echo \"organization variable : ${{ vars.ORGANIZATION_VAR }}\" echo \"overridden variable : ${{ vars.OVERRIDE_VAR }}\" echo \"variable from shell environment : $env_var\"","title":"Example usage of vars context"},{"location":"gh_actions/gh_actions_cheatsheet/","text":"GitHub Actions Basic Template Template for using GitHub actions. This file lives in the workflows directory, <my_repo/><.github/workflows/gh_action.yml> My directory tree showing the workflows dir, relative to the project root. Actions Template . \u251c\u2500\u2500 docs \u251c\u2500\u2500 .github \u2502 \u2514\u2500\u2500 workflows \u2502 \u2514\u2500\u2500 gh_action.yml name: OIDC auth Push ECR from GH Actions docker build ## Trigger #on: [push] on: push: paths: - 's3_bucket/**' - '.github/**' workflow_dispatch: permissions: contents: 'read' id-token: 'write' jobs: test: name: github oidc sync to AWS runs-on: ubuntu-latest steps: - name: Git clone the repository uses: actions/checkout@v2 ## Requires team_users.txt with github users, e.g. memadsen - name: User list to authorize GH Action build run: | # if user not in list, exit while read line; do if [ ${{ github.actor }} == \"$line\" ]; then echo \"----- ${{ github.actor }} is authorized user -----\" ALLOWED_USER=${{ github.actor }} break fi done < \".github/team_users.txt\" if [ -z \"$ALLOWED_USER\"]; then echo \"----- Job triggered by unauthorized user -----\" exit 1 fi ## OIDC Auth ## Requires AWS IAM Role ARN - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v1 with: role-to-assume: arn:aws:iam::073416988478:role/SC-073416988478-pp-jgiui7c5d7xx2-Role-SLI0NYCKDL9J aws-region: us-east-1 - name: STS verify AWS connect to OIDC auth run: aws sts get-caller-identity - name: s3 sync and rm S3 files not in local run: | aws s3 sync s3_bucket/ s3://mulesoft-fastapi/local_folder/ --delete - name: Update AWS Lambda run: | aws lambda update-function-code \\ --function-name mulesoft-fastapi \\ --s3-bucket mulesoft-fastapi \\ --s3-key local_folder/deployment-package.zip \\ --publish Event Triggers Event to run job. Trigger using a regex pattern. on: push: tags: - 'v*' You can make a advanced rule that only triggers on v1 and up or excludes -alpha releases, if that matters to you. Trigger on a push to main or a tag on: push: branches: - main tags: Trigger on a push to main and a tag. on: push: branches: - main tags: jobs: build-deploy: if: startsWith(github.ref, 'refs/tags/') steps: # ... There is no on.tag or on.tags option, but there is on.release - see below.","title":"GH Actions Cheatsheet"},{"location":"gh_actions/gh_actions_cheatsheet/#github-actions-basic-template","text":"Template for using GitHub actions. This file lives in the workflows directory, <my_repo/><.github/workflows/gh_action.yml> My directory tree showing the workflows dir, relative to the project root.","title":"GitHub Actions Basic Template"},{"location":"gh_actions/gh_actions_cheatsheet/#actions-template","text":". \u251c\u2500\u2500 docs \u251c\u2500\u2500 .github \u2502 \u2514\u2500\u2500 workflows \u2502 \u2514\u2500\u2500 gh_action.yml name: OIDC auth Push ECR from GH Actions docker build ## Trigger #on: [push] on: push: paths: - 's3_bucket/**' - '.github/**' workflow_dispatch: permissions: contents: 'read' id-token: 'write' jobs: test: name: github oidc sync to AWS runs-on: ubuntu-latest steps: - name: Git clone the repository uses: actions/checkout@v2 ## Requires team_users.txt with github users, e.g. memadsen - name: User list to authorize GH Action build run: | # if user not in list, exit while read line; do if [ ${{ github.actor }} == \"$line\" ]; then echo \"----- ${{ github.actor }} is authorized user -----\" ALLOWED_USER=${{ github.actor }} break fi done < \".github/team_users.txt\" if [ -z \"$ALLOWED_USER\"]; then echo \"----- Job triggered by unauthorized user -----\" exit 1 fi ## OIDC Auth ## Requires AWS IAM Role ARN - name: Configure AWS Credentials uses: aws-actions/configure-aws-credentials@v1 with: role-to-assume: arn:aws:iam::073416988478:role/SC-073416988478-pp-jgiui7c5d7xx2-Role-SLI0NYCKDL9J aws-region: us-east-1 - name: STS verify AWS connect to OIDC auth run: aws sts get-caller-identity - name: s3 sync and rm S3 files not in local run: | aws s3 sync s3_bucket/ s3://mulesoft-fastapi/local_folder/ --delete - name: Update AWS Lambda run: | aws lambda update-function-code \\ --function-name mulesoft-fastapi \\ --s3-bucket mulesoft-fastapi \\ --s3-key local_folder/deployment-package.zip \\ --publish","title":"Actions Template"},{"location":"gh_actions/gh_actions_cheatsheet/#event-triggers","text":"Event to run job. Trigger using a regex pattern. on: push: tags: - 'v*' You can make a advanced rule that only triggers on v1 and up or excludes -alpha releases, if that matters to you. Trigger on a push to main or a tag on: push: branches: - main tags: Trigger on a push to main and a tag. on: push: branches: - main tags: jobs: build-deploy: if: startsWith(github.ref, 'refs/tags/') steps: # ... There is no on.tag or on.tags option, but there is on.release - see below.","title":"Event Triggers"},{"location":"gh_actions/gh_actions_tutorial/","text":"GitHub Actions Github actions is a virtual machine used to do work. Unlike self-hosted runners like Jenkins, most cloud-hosted build runners are stateless, providing us with a pristine environment each run. We cannot keep files from the previous runs around; anything that needs to be persisted must be externalized. Github Actions - Architecture GitHub Actions are formed by a set of components. There are six main components of GitHub Actions: Workflows: Automated procedure added to the repository, and is the actual Action itself Events: An activity that triggers a workflow; these can be based on events such as push or pull requests, but they can also be scheduled using the crontab syntax Jobs: A group of one or more steps that are executed inside a runner Steps: These are tasks from a job that can be used to run commands Actions: The standalone commands from the steps Runners: A server that has the GHA runner application installed. The runner is a server provided by GitHub to run your workflows (also known as Actions). They are deployed and are terminated after your automation is completed. Although there are some limits regarding this service, users do not pay anything to use it, even with a free GitHub account. A useful cheatsheet for syntax to GitHub action workflows Network security testing on GitHub Actions End","title":"GH Actions Description"},{"location":"gh_actions/gh_actions_tutorial/#github-actions","text":"Github actions is a virtual machine used to do work. Unlike self-hosted runners like Jenkins, most cloud-hosted build runners are stateless, providing us with a pristine environment each run. We cannot keep files from the previous runs around; anything that needs to be persisted must be externalized.","title":"GitHub Actions"},{"location":"gh_actions/gh_actions_tutorial/#github-actions-architecture","text":"GitHub Actions are formed by a set of components. There are six main components of GitHub Actions: Workflows: Automated procedure added to the repository, and is the actual Action itself Events: An activity that triggers a workflow; these can be based on events such as push or pull requests, but they can also be scheduled using the crontab syntax Jobs: A group of one or more steps that are executed inside a runner Steps: These are tasks from a job that can be used to run commands Actions: The standalone commands from the steps Runners: A server that has the GHA runner application installed. The runner is a server provided by GitHub to run your workflows (also known as Actions). They are deployed and are terminated after your automation is completed. Although there are some limits regarding this service, users do not pay anything to use it, even with a free GitHub account. A useful cheatsheet for syntax to GitHub action workflows Network security testing on GitHub Actions","title":"Github Actions - Architecture"},{"location":"gh_actions/gh_actions_tutorial/#end","text":"","title":"End"},{"location":"gh_actions/push_file_remote/","text":"Update Remote Repository A centralized repository is used for documenting data science governance. Information on CSP, best practices and announcements. This is the \"source of truth\" to provide guidance to CLS SMol teams, working on data science projects. Update projects at scale Documentation updates need to scale across projects. Github is the standard for source code management. Templates provide boilerplate to ensure alignment on sharing data and ML-governance. Project source code is updated automagically from the ML governance documentation. Project files are independent of updates from ML-Governance. gitGraph commit id: \"1\" branch ML-Governance commit id: \"2\" commit id: \"3\" commit id: \"4\" checkout main commit id: \"5\" commit id: \"6\" merge ML-Governance id: \"Merge ML Docs\" tag: \"V 1.0\" type: HIGHLIGHT commit id: \"7\" commit id: \"8\" Implementation Generate PAT in my personal repo and scope for GH Actions. Navigate to my personal repo and open settings --> Developer settings: Next generate a personal access token and save it somewhere safe: In another tab open the source repo used to write files, bayer-int/smol-cls-docs . Open the Security --> Secrets --> Actions and add the secret. GH Actions Workflow The workflow to push files to another repo. name: Push File on: push: branches: - main workflow_dispatch: jobs: copy-file: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 - name: Pushes test file uses: dmnemec/copy_file_to_another_repo_action@main env: API_TOKEN_GITHUB: ${{ secrets.PUSH_FILE }} with: source_file: 'poetry.lock' destination_repo: 'bayer-int/hf_ghcr' destination_folder: 'test-dir' user_email: 'michael.madsen@bayer.com' user_name: 'memadsen' commit_message: 'A custom message for the commit'","title":"Push Remote File"},{"location":"gh_actions/push_file_remote/#update-remote-repository","text":"A centralized repository is used for documenting data science governance. Information on CSP, best practices and announcements. This is the \"source of truth\" to provide guidance to CLS SMol teams, working on data science projects.","title":"Update Remote Repository"},{"location":"gh_actions/push_file_remote/#update-projects-at-scale","text":"Documentation updates need to scale across projects. Github is the standard for source code management. Templates provide boilerplate to ensure alignment on sharing data and ML-governance. Project source code is updated automagically from the ML governance documentation. Project files are independent of updates from ML-Governance. gitGraph commit id: \"1\" branch ML-Governance commit id: \"2\" commit id: \"3\" commit id: \"4\" checkout main commit id: \"5\" commit id: \"6\" merge ML-Governance id: \"Merge ML Docs\" tag: \"V 1.0\" type: HIGHLIGHT commit id: \"7\" commit id: \"8\"","title":"Update projects at scale"},{"location":"gh_actions/push_file_remote/#implementation","text":"Generate PAT in my personal repo and scope for GH Actions. Navigate to my personal repo and open settings --> Developer settings: Next generate a personal access token and save it somewhere safe: In another tab open the source repo used to write files, bayer-int/smol-cls-docs . Open the Security --> Secrets --> Actions and add the secret.","title":"Implementation"},{"location":"gh_actions/push_file_remote/#gh-actions-workflow","text":"The workflow to push files to another repo. name: Push File on: push: branches: - main workflow_dispatch: jobs: copy-file: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 - name: Pushes test file uses: dmnemec/copy_file_to_another_repo_action@main env: API_TOKEN_GITHUB: ${{ secrets.PUSH_FILE }} with: source_file: 'poetry.lock' destination_repo: 'bayer-int/hf_ghcr' destination_folder: 'test-dir' user_email: 'michael.madsen@bayer.com' user_name: 'memadsen' commit_message: 'A custom message for the commit'","title":"GH Actions Workflow"},{"location":"gh_actions/read_project_file/","text":"Github Actions Read Files in Project Configure github actions to access files locally. Team User List User list limits user access to the github action build. Add file in .github/team_users.txt and add github user, e.g. memadsen. Now, only memadsen is authorized to build on github actions. jobs: build: runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: - name: Checks-out repository under $GITHUB_WORKSPACE, so your job can access it uses: actions/checkout@v3 ## Requires team_users.txt with github users, e.g. memadsen - name: User list to authorize GH Action build run: | # if user not in list, exit while read line; do if [ ${{ github.actor }} == \"$line\" ]; then echo \"----- ${{ github.actor }} is authorized user -----\" ALLOWED_USER=${{ github.actor }} break fi done < \".github/team_users.txt\" if [ -z \"$ALLOWED_USER\"]; then echo \"----- Job triggered by unauthorized user -----\" exit 1 fi Github metadata and environment variables name: Context Example on: [push] jobs: build: name: Inspect context runs-on: ubuntu-latest steps: - name: Inspect context run: | echo 'Github Repository ------ \\n ${{ github.repository }} ' echo 'Github use ---------- \\n ${{ github.actor }}'' build: runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v2 # Runs commands using the runners shell - name: Run the build php script run: | cd build php build.php # This file reads a few json files and then creates a set of html files in the doc folder cd ../ - name: Commit files # transfer the new html files back into the repository run: | git config --local user.name \"jpadfield\" git add ./docs git commit -m \"Updating the repository GitHub html pages in the docs folder\" - name: Push changes # push the output folder to your repo uses: ad-m/github-push-action@master with: github_token: ${{ secrets.GITHUB_TOKEN }} force: true Check if File exists Check (e.g. with git diff --exit-code ) if there actually are any changes, and skip the commit if not. Definitely better than committing deletion first and then (possibly identical) new files. Example: - id: commit_files name: Commit files run: git config --local user.name actions-user git config --local user.email \"actions@github.com\" if ! git diff --exit-code; then git add your/files/here git commit -am \"GH Action Files added $(date)\" git push -f origin main fi","title":"Read Project File"},{"location":"gh_actions/read_project_file/#github-actions-read-files-in-project","text":"Configure github actions to access files locally.","title":"Github Actions Read Files in Project"},{"location":"gh_actions/read_project_file/#team-user-list","text":"User list limits user access to the github action build. Add file in .github/team_users.txt and add github user, e.g. memadsen. Now, only memadsen is authorized to build on github actions. jobs: build: runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: - name: Checks-out repository under $GITHUB_WORKSPACE, so your job can access it uses: actions/checkout@v3 ## Requires team_users.txt with github users, e.g. memadsen - name: User list to authorize GH Action build run: | # if user not in list, exit while read line; do if [ ${{ github.actor }} == \"$line\" ]; then echo \"----- ${{ github.actor }} is authorized user -----\" ALLOWED_USER=${{ github.actor }} break fi done < \".github/team_users.txt\" if [ -z \"$ALLOWED_USER\"]; then echo \"----- Job triggered by unauthorized user -----\" exit 1 fi","title":"Team User List"},{"location":"gh_actions/read_project_file/#github-metadata-and-environment-variables","text":"name: Context Example on: [push] jobs: build: name: Inspect context runs-on: ubuntu-latest steps: - name: Inspect context run: | echo 'Github Repository ------ \\n ${{ github.repository }} ' echo 'Github use ---------- \\n ${{ github.actor }}'' build: runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v2 # Runs commands using the runners shell - name: Run the build php script run: | cd build php build.php # This file reads a few json files and then creates a set of html files in the doc folder cd ../ - name: Commit files # transfer the new html files back into the repository run: | git config --local user.name \"jpadfield\" git add ./docs git commit -m \"Updating the repository GitHub html pages in the docs folder\" - name: Push changes # push the output folder to your repo uses: ad-m/github-push-action@master with: github_token: ${{ secrets.GITHUB_TOKEN }} force: true","title":"Github metadata and environment variables"},{"location":"gh_actions/read_project_file/#check-if-file-exists","text":"Check (e.g. with git diff --exit-code ) if there actually are any changes, and skip the commit if not. Definitely better than committing deletion first and then (possibly identical) new files. Example: - id: commit_files name: Commit files run: git config --local user.name actions-user git config --local user.email \"actions@github.com\" if ! git diff --exit-code; then git add your/files/here git commit -am \"GH Action Files added $(date)\" git push -f origin main fi","title":"Check if File exists"},{"location":"gh_actions/runner/","text":"Self Hosted Runner Github Actions using self hosted runner. name: Github runner demo on: [push] jobs: runner-demo: runs-on: [self-hosted, linux] steps: - run: echo \"I'm using my self-hosted runner for this.\"","title":"Self Hosted Runner"},{"location":"gh_actions/runner/#self-hosted-runner","text":"Github Actions using self hosted runner. name: Github runner demo on: [push] jobs: runner-demo: runs-on: [self-hosted, linux] steps: - run: echo \"I'm using my self-hosted runner for this.\"","title":"Self Hosted Runner"},{"location":"gh_actions/sbom/","text":"SBOM Software Bill of Material with Docker Container and Github Actions Generate an SBOM from within a GitHub Actions workflow. In this way, the SBOM is shipped with the container image and is made available without having to scan the image each time. What is SBOM? From Wikipedia: A software bill of materials (SBOM) is a list of components in a piece of software. Software vendors often create products by assembling open source and commercial software components. The SBOM describes the components in a product. It is analogous to a list of ingredients on food packaging: where you might consult a label to avoid foods that may cause an allergies, SBOMs can help companies avoid consumption of software that could harm their organization. The concept of a BOM is well-established in traditional manufacturing as part of supply chain management. A manufacturer uses a BOM to track the parts it uses to create a product. If defects are later found in a specific part, the BOM makes it easy to locate affected products. Crane crane is a tool for interacting with remote images and registries. Install crane sudo snap install go --classic ## Install go go install github.com/google/go-containerregistry/cmd/crane@latest curl -sL \"https://github.com/google/go-containerregistry/releases/latest/download/go-containerregistry_Linux_x86_64.tar.gz\" > go-containerregistry.tar.gz curl -sL https://api.github.com/repos/konveyor/crane/releases/latest | jq -r \".assets[] | select(.name | contains(\\\"amd64-linux\\\")) | .browser_download_url\" | wget -i- Imagine you have the following Dockerfile: FROM alpine:3.17.0 RUN apk add --no-cache curl ca-certificates CMD [\"curl\", \"https://www.google.com\"] I know that there's a vulnerability in alpine 3.17.0 in the OpenSSL library. How do I know that? I recently updated every OpenFaaS Pro component to use 3.17.1 to fix a specific vulnerability. Now a typical workflow for this Dockerfile would look like the below: name: build on: push: branches: [ master, main ] pull_request: branches: [ master, main ] permissions: actions: read checks: write contents: read packages: write jobs: publish: runs-on: ubuntu-latest steps: - uses: actions/checkout@master with: fetch-depth: 1 - name: Build Docker image run: docker build . --file Dockerfile.sbom --tag my-image-name:$(date +%s) # - name: Set up Docker Buildx # uses: docker/setup-buildx-action@v2 # - name: Login to Docker Registry # uses: docker/login-action@v2 # with: # username: ${{ github.repository_owner }} # password: ${{ secrets.GITHUB_TOKEN }} # registry: ghcr.io - name: Publish image uses: docker/build-push-action@v3 with: build-args: | GitCommit=${{ github.sha }} outputs: \"type=registry,push=true\" tags: | ghcr.io/alexellis/gha-sbom:${{ github.sha }} Upon each commit, an image is published to GitHub's Container Registry with the image name of: ghcr.io/np-completed/gha-sbom:SHA . To generate an SBOM, we just need to update the docker/build-push-action to use the sbom flag: - name: Local build id: local_build uses: docker/build-push-action@v3 with: sbom: true provenance: false View the SBOM: syft ghcr.io/np-completed/gha-sbom:840fc5b2f3c94099e5dc74434a6bbcc156407a6f \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] NAME VERSION TYPE alpine-baselayout 3.4.0-r0 apk alpine-baselayout-data 3.4.0-r0 apk alpine-keys 2.4-r1 apk apk-tools 2.12.10-r1 apk brotli-libs 1.0.9-r9 apk busybox 1.35.0 binary busybox 1.35.0-r29 apk busybox-binsh 1.35.0-r29 apk ca-certificates 20220614-r4 apk ca-certificates-bundle 20220614-r2 apk curl 7.87.0-r1 apk libc-utils 0.7.2-r3 apk libcrypto3 3.0.7-r0 apk libcurl 7.87.0-r1 apk libssl3 3.0.7-r0 apk musl 1.2.3-r4 apk musl-utils 1.2.3-r4 apk nghttp2-libs 1.51.0-r0 apk scanelf 1.3.5-r1 apk ssl_client 1.35.0-r29 apk zlib 1.2.13-r0 apk grype ghcr.io/np-completed/gha-sbom:840fc5b2f3c94099e5dc74434a6bbcc156407a6f \u2714 Vulnerability DB [no update available] \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] \u2714 Scanned image [2 vulnerabilities] NAME INSTALLED FIXED-IN TYPE VULNERABILITY SEVERITY libcrypto3 3.0.7-r0 3.0.7-r2 apk CVE-2022-3996 High libssl3 3.0.7-r0 3.0.7-r2 apk CVE-2022-3996 High The image: alpine:3.17.0 contains two High vulnerabilities, and from reading the notes, we can see that both have been fixed. We can resolve the issue by changing the Dockerfile to use alpine:latest instead, and re-running the build. syft ghcr.io/np-completed/gha-sbom:1a7f4c36bad2a506d7403fe4dd904a356bd8bbfa \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] NAME VERSION TYPE alpine-baselayout 3.4.0-r0 apk alpine-baselayout-data 3.4.0-r0 apk alpine-keys 2.4-r1 apk apk-tools 2.12.10-r1 apk brotli-libs 1.0.9-r9 apk busybox 1.35.0 binary busybox 1.35.0-r29 apk busybox-binsh 1.35.0-r29 apk ca-certificates 20220614-r4 apk ca-certificates-bundle 20220614-r4 apk curl 7.87.0-r1 apk libc-utils 0.7.2-r3 apk libcrypto3 3.0.7-r2 apk libcurl 7.87.0-r1 apk libssl3 3.0.7-r2 apk musl 1.2.3-r4 apk musl-utils 1.2.3-r4 apk nghttp2-libs 1.51.0-r0 apk scanelf 1.3.5-r1 apk ssl_client 1.35.0-r29 apk zlib 1.2.13-r0 apk grype ghcr.io/np-completed/gha-sbom:1a7f4c36bad2a506d7403fe4dd904a356bd8bbfa \u2714 Vulnerability DB [no update available] \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] \u2714 Scanned image [0 vulnerabilities] Install Grype and Syft Anchore provides commercial solutions for creating, managing and inspecting SBOMs, however they also have two very useful open source tools that we can try out for free. syft - a command line tool that can be used to generate an SBOM for a container image. grype - a command line tool that can be used to scan an SBOM for vulnerabilities. Grype Run the following command to install the latest version of Grype to the /usr/local/bin directory: wget -qO - https://raw.githubusercontent.com/anchore/grype/main/install.sh | sudo bash -s -- -b /usr/local/bin ## Verify install worked grype version Run the grype command and specify the container image as argument: $ grype ubuntu:latest \u2714 Vulnerability DB [updated] \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [101 packages] \u2714 Scanned image [18 vulnerabilities] NAME INSTALLED FIXED-IN TYPE VULNERABILITY SEVERITY bash 5.1-6ubuntu1 deb CVE-2022-3715 Low coreutils 8.32-4.1ubuntu1 deb CVE-2016-2781 Low gpgv 2.2.27-3ubuntu2.1 deb CVE-2022-3219 Low libc-bin 2.35-0ubuntu3.1 deb CVE-2016-20013 Negligible libc6 2.35-0ubuntu3.1 deb CVE-2016-20013 Negligible libgssapi-krb5-2 1.19.2-2 deb CVE-2022-42898 Medium libk5crypto3 1.19.2-2 deb CVE-2022-42898 Medium Uninstall grype sudo rm -rf /usr/local/bin/grype and remove vulnerabilities database rm -rf ~/.cache/grype Install Syft Run the following command to install the latest version of Syft to the /usr/local/bin directory: wget -qO - https://raw.githubusercontent.com/anchore/syft/main/install.sh | sudo bash -s -- -b /usr/local/bin ## Verify install worked syft version Application: syft Version: 0.68.1 JsonSchemaVersion: 6.2.0 BuildDate: 2023-01-25T17:46:33Z GitCommit: 4c0aef09b8d7fb78200b04416f474b90b79370de GitDescription: v0.68.1 Platform: linux/amd64 GoVersion: go1.18.10 Compiler: gc Test Syft Generate an SBOM for a container image: syft <image> The above output includes only software that is visible in the container (i.e., the squashed representation of the image). To include software from all image layers in the SBOM, regardless of its presence in the final image, provide --scope all-layers : syft <image> --scope all-layers","title":"Software Bill of Materials"},{"location":"gh_actions/sbom/#sbom-software-bill-of-material-with-docker-container-and-github-actions","text":"Generate an SBOM from within a GitHub Actions workflow. In this way, the SBOM is shipped with the container image and is made available without having to scan the image each time.","title":"SBOM Software Bill of Material with Docker Container and Github Actions"},{"location":"gh_actions/sbom/#what-is-sbom","text":"From Wikipedia: A software bill of materials (SBOM) is a list of components in a piece of software. Software vendors often create products by assembling open source and commercial software components. The SBOM describes the components in a product. It is analogous to a list of ingredients on food packaging: where you might consult a label to avoid foods that may cause an allergies, SBOMs can help companies avoid consumption of software that could harm their organization. The concept of a BOM is well-established in traditional manufacturing as part of supply chain management. A manufacturer uses a BOM to track the parts it uses to create a product. If defects are later found in a specific part, the BOM makes it easy to locate affected products.","title":"What is SBOM?"},{"location":"gh_actions/sbom/#crane","text":"crane is a tool for interacting with remote images and registries. Install crane sudo snap install go --classic ## Install go go install github.com/google/go-containerregistry/cmd/crane@latest curl -sL \"https://github.com/google/go-containerregistry/releases/latest/download/go-containerregistry_Linux_x86_64.tar.gz\" > go-containerregistry.tar.gz curl -sL https://api.github.com/repos/konveyor/crane/releases/latest | jq -r \".assets[] | select(.name | contains(\\\"amd64-linux\\\")) | .browser_download_url\" | wget -i-","title":"Crane"},{"location":"gh_actions/sbom/#imagine-you-have-the-following-dockerfile","text":"FROM alpine:3.17.0 RUN apk add --no-cache curl ca-certificates CMD [\"curl\", \"https://www.google.com\"] I know that there's a vulnerability in alpine 3.17.0 in the OpenSSL library. How do I know that? I recently updated every OpenFaaS Pro component to use 3.17.1 to fix a specific vulnerability. Now a typical workflow for this Dockerfile would look like the below: name: build on: push: branches: [ master, main ] pull_request: branches: [ master, main ] permissions: actions: read checks: write contents: read packages: write jobs: publish: runs-on: ubuntu-latest steps: - uses: actions/checkout@master with: fetch-depth: 1 - name: Build Docker image run: docker build . --file Dockerfile.sbom --tag my-image-name:$(date +%s) # - name: Set up Docker Buildx # uses: docker/setup-buildx-action@v2 # - name: Login to Docker Registry # uses: docker/login-action@v2 # with: # username: ${{ github.repository_owner }} # password: ${{ secrets.GITHUB_TOKEN }} # registry: ghcr.io - name: Publish image uses: docker/build-push-action@v3 with: build-args: | GitCommit=${{ github.sha }} outputs: \"type=registry,push=true\" tags: | ghcr.io/alexellis/gha-sbom:${{ github.sha }} Upon each commit, an image is published to GitHub's Container Registry with the image name of: ghcr.io/np-completed/gha-sbom:SHA . To generate an SBOM, we just need to update the docker/build-push-action to use the sbom flag: - name: Local build id: local_build uses: docker/build-push-action@v3 with: sbom: true provenance: false View the SBOM: syft ghcr.io/np-completed/gha-sbom:840fc5b2f3c94099e5dc74434a6bbcc156407a6f \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] NAME VERSION TYPE alpine-baselayout 3.4.0-r0 apk alpine-baselayout-data 3.4.0-r0 apk alpine-keys 2.4-r1 apk apk-tools 2.12.10-r1 apk brotli-libs 1.0.9-r9 apk busybox 1.35.0 binary busybox 1.35.0-r29 apk busybox-binsh 1.35.0-r29 apk ca-certificates 20220614-r4 apk ca-certificates-bundle 20220614-r2 apk curl 7.87.0-r1 apk libc-utils 0.7.2-r3 apk libcrypto3 3.0.7-r0 apk libcurl 7.87.0-r1 apk libssl3 3.0.7-r0 apk musl 1.2.3-r4 apk musl-utils 1.2.3-r4 apk nghttp2-libs 1.51.0-r0 apk scanelf 1.3.5-r1 apk ssl_client 1.35.0-r29 apk zlib 1.2.13-r0 apk grype ghcr.io/np-completed/gha-sbom:840fc5b2f3c94099e5dc74434a6bbcc156407a6f \u2714 Vulnerability DB [no update available] \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] \u2714 Scanned image [2 vulnerabilities] NAME INSTALLED FIXED-IN TYPE VULNERABILITY SEVERITY libcrypto3 3.0.7-r0 3.0.7-r2 apk CVE-2022-3996 High libssl3 3.0.7-r0 3.0.7-r2 apk CVE-2022-3996 High The image: alpine:3.17.0 contains two High vulnerabilities, and from reading the notes, we can see that both have been fixed. We can resolve the issue by changing the Dockerfile to use alpine:latest instead, and re-running the build. syft ghcr.io/np-completed/gha-sbom:1a7f4c36bad2a506d7403fe4dd904a356bd8bbfa \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] NAME VERSION TYPE alpine-baselayout 3.4.0-r0 apk alpine-baselayout-data 3.4.0-r0 apk alpine-keys 2.4-r1 apk apk-tools 2.12.10-r1 apk brotli-libs 1.0.9-r9 apk busybox 1.35.0 binary busybox 1.35.0-r29 apk busybox-binsh 1.35.0-r29 apk ca-certificates 20220614-r4 apk ca-certificates-bundle 20220614-r4 apk curl 7.87.0-r1 apk libc-utils 0.7.2-r3 apk libcrypto3 3.0.7-r2 apk libcurl 7.87.0-r1 apk libssl3 3.0.7-r2 apk musl 1.2.3-r4 apk musl-utils 1.2.3-r4 apk nghttp2-libs 1.51.0-r0 apk scanelf 1.3.5-r1 apk ssl_client 1.35.0-r29 apk zlib 1.2.13-r0 apk grype ghcr.io/np-completed/gha-sbom:1a7f4c36bad2a506d7403fe4dd904a356bd8bbfa \u2714 Vulnerability DB [no update available] \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [21 packages] \u2714 Scanned image [0 vulnerabilities]","title":"Imagine you have the following Dockerfile:"},{"location":"gh_actions/sbom/#install-grype-and-syft","text":"Anchore provides commercial solutions for creating, managing and inspecting SBOMs, however they also have two very useful open source tools that we can try out for free. syft - a command line tool that can be used to generate an SBOM for a container image. grype - a command line tool that can be used to scan an SBOM for vulnerabilities.","title":"Install Grype and Syft"},{"location":"gh_actions/sbom/#grype","text":"Run the following command to install the latest version of Grype to the /usr/local/bin directory: wget -qO - https://raw.githubusercontent.com/anchore/grype/main/install.sh | sudo bash -s -- -b /usr/local/bin ## Verify install worked grype version Run the grype command and specify the container image as argument: $ grype ubuntu:latest \u2714 Vulnerability DB [updated] \u2714 Pulled image \u2714 Loaded image \u2714 Parsed image \u2714 Cataloged packages [101 packages] \u2714 Scanned image [18 vulnerabilities] NAME INSTALLED FIXED-IN TYPE VULNERABILITY SEVERITY bash 5.1-6ubuntu1 deb CVE-2022-3715 Low coreutils 8.32-4.1ubuntu1 deb CVE-2016-2781 Low gpgv 2.2.27-3ubuntu2.1 deb CVE-2022-3219 Low libc-bin 2.35-0ubuntu3.1 deb CVE-2016-20013 Negligible libc6 2.35-0ubuntu3.1 deb CVE-2016-20013 Negligible libgssapi-krb5-2 1.19.2-2 deb CVE-2022-42898 Medium libk5crypto3 1.19.2-2 deb CVE-2022-42898 Medium","title":"Grype"},{"location":"gh_actions/sbom/#uninstall-grype","text":"sudo rm -rf /usr/local/bin/grype and remove vulnerabilities database rm -rf ~/.cache/grype","title":"Uninstall grype"},{"location":"gh_actions/sbom/#install-syft","text":"Run the following command to install the latest version of Syft to the /usr/local/bin directory: wget -qO - https://raw.githubusercontent.com/anchore/syft/main/install.sh | sudo bash -s -- -b /usr/local/bin ## Verify install worked syft version Application: syft Version: 0.68.1 JsonSchemaVersion: 6.2.0 BuildDate: 2023-01-25T17:46:33Z GitCommit: 4c0aef09b8d7fb78200b04416f474b90b79370de GitDescription: v0.68.1 Platform: linux/amd64 GoVersion: go1.18.10 Compiler: gc","title":"Install Syft"},{"location":"gh_actions/sbom/#test-syft","text":"Generate an SBOM for a container image: syft <image> The above output includes only software that is visible in the container (i.e., the squashed representation of the image). To include software from all image layers in the SBOM, regardless of its presence in the final image, provide --scope all-layers : syft <image> --scope all-layers","title":"Test Syft"},{"location":"gh_actions/share_docker_job/","text":"Share Artifacts Sharing a Docker image between two jobs, here is how I did it: jobs: docker-build: name: Docker build runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 - name: Build Docker image run: | docker build -t foo/bar:$GITHUB_SHA mkdir -p path/to/artifacts docker save foo/bar:$GITHUB_SHA > path/to/artifacts/docker-image.tar - name: Temporarily save Docker image uses: actions/upload-artifact@v2 with: name: docker-artifact path: path/to/artifacts retention-days: 1 docker-deploy: name: Deploy to Docker Hub runs-on: ubuntu-latest needs: docker-build steps: - name: Checkout uses: actions/checkout@v2 - name: Retrieve saved Docker image uses: actions/download-artifact@v2 with: name: docker-artifact path: path/to/artifacts - name: Docker load run: | cd path/to/artifacts docker load < docker-image.tar # docker_build_push.sh","title":"Share Artifacts"},{"location":"gh_actions/share_docker_job/#share-artifacts","text":"Sharing a Docker image between two jobs, here is how I did it: jobs: docker-build: name: Docker build runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 - name: Build Docker image run: | docker build -t foo/bar:$GITHUB_SHA mkdir -p path/to/artifacts docker save foo/bar:$GITHUB_SHA > path/to/artifacts/docker-image.tar - name: Temporarily save Docker image uses: actions/upload-artifact@v2 with: name: docker-artifact path: path/to/artifacts retention-days: 1 docker-deploy: name: Deploy to Docker Hub runs-on: ubuntu-latest needs: docker-build steps: - name: Checkout uses: actions/checkout@v2 - name: Retrieve saved Docker image uses: actions/download-artifact@v2 with: name: docker-artifact path: path/to/artifacts - name: Docker load run: | cd path/to/artifacts docker load < docker-image.tar # docker_build_push.sh","title":"Share Artifacts"},{"location":"gh_actions/url_test_in_cloudfront/","text":"Github Actions Check URL Links Check for broken url links in published markdown html. The json and yaml files are required. links.yml is located in .github/workflows/links.yml name: Check Markdown Links on: workflow_call jobs: markdown-link-check: runs-on: ubuntu-latest env: ZENML_DEBUG: 1 ZENML_ANALYTICS_OPT_IN: false steps: - uses: actions/checkout@master - uses: gaurav-nelson/github-action-markdown-link-check@v1 with: use-quiet-mode: 'yes' use-verbose-mode: 'no' config-file: .github/workflows/markdown_check_config.json continue-on-error: true { \"ignorePatterns\": [ { \"pattern\": \"^http://0.0.0.0\" }, { \"pattern\": \"^http://127.0.0.1\" }, { \"pattern\": \"^http://localhost\" } ] } Broken links report to issue name: Broken Links Report to GH Issues on: push: branches: - main repository_dispatch: workflow_dispatch: # schedule: # - cron: \"00 18 * * *\" concurrency: # New commit on branch cancels running workflows of the same branch group: ${{ github.workflow }}-${{ github.ref }} cancel-in-progress: true jobs: links: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2.3.4 - name: Link Checker uses: lycheeverse/lychee-action@v1.5.1 with: # TODO TOML is causing kernel panick and fails to render report --config .github/lychee.toml # TODO --exclude-path .lychee.excludes NOT WORKING AS EXPECTED args: > --exclude-mail --no-progress --timeout 45 './**/*.md' './**/*.html' # --cache --max-cache-age 1d -- **/*.md *.md **/*.html # --verbose # --accept=200,403,429 # --exclude-mail **/*.html **/*.md **/*.txt **/*.json --exclude-file .lychee.excludes # --exclude-all-private --insecure # --max-retries 4 # -- **/*.md *.md '**/*.md' # --cache --max-cache-age 1d '**/*.md' README.md patterns/ output: out.md jobSummary: true env: GITHUB_TOKEN: ${{ secrets.actions }} - name: Create Issue From File # if: github.event_name != 'pull_request' # if: steps.lychee.outputs.exit_code != 0 uses: peter-evans/create-issue-from-file@v4 with: title: Link Checker Report content-filepath: out.md # token: ${{ secrets.actions }} #content-filepath: ./link-checker/out.md labels: | report links automated issue issue-number: 15 Use file to ignore URLs. Add .lycheeingnore to project root directory: file://* http://127.0.0.1:8000/ ON Event ## Manual Trigger from Github UI on: workflow_dispatch: ## Push Trigger on: push: paths: - 'docs/**' - 'mkdocs.yml' - '.github/workflows/main.yml' - 'pyproject.toml' branches: - main pull_request: # The branches below must be a subset of the branches above ## types: [opened, synchronize, reopened] branches: [ \"main\" ] concurrency: # New commit on branch cancels running workflows of the same branch group: ${{ github.workflow }}-${{ github.ref }} cancel-in-progress: true ## Workflow Call on: workflow_call Reusable workflows TODO Workflow for Github Actions TODO Using Github Actions to push to AWS ECR with Credentials https://aws.plainenglish.io/build-a-docker-image-and-publish-it-to-aws-ecr-using-github-actions-f20accd774c3 Using Github Actions OpenID Connect to push to AWS ECR without Credentials https://blog.tedivm.com/guides/2021/10/github-actions-push-to-aws-ecr-without-credentials-oidc/ Pushing the Container WIth all that out of the way here\u2019s full action to build and deploy an image to ECR. In this we\u2019re chaining together a variety of published actions from other vendors- actions/checkout to actually pull the repository. docker/setup-qemu-action to install an emulation layer to build multiplatform images. docker/setup-buildx-action to use the docker buildx system, again for multiplatform images. aws-actions/configure-aws-credentials to log into AWS. aws-actions/amazon-ecr-login to log into AWS ECR. docker/metadata-action to create a bunch of tags for our docker container. docker/build-push-action to push the container.","title":"Test URLs in Cloudfront"},{"location":"gh_actions/url_test_in_cloudfront/#github-actions","text":"","title":"Github Actions"},{"location":"gh_actions/url_test_in_cloudfront/#check-url-links","text":"Check for broken url links in published markdown html. The json and yaml files are required. links.yml is located in .github/workflows/links.yml name: Check Markdown Links on: workflow_call jobs: markdown-link-check: runs-on: ubuntu-latest env: ZENML_DEBUG: 1 ZENML_ANALYTICS_OPT_IN: false steps: - uses: actions/checkout@master - uses: gaurav-nelson/github-action-markdown-link-check@v1 with: use-quiet-mode: 'yes' use-verbose-mode: 'no' config-file: .github/workflows/markdown_check_config.json continue-on-error: true { \"ignorePatterns\": [ { \"pattern\": \"^http://0.0.0.0\" }, { \"pattern\": \"^http://127.0.0.1\" }, { \"pattern\": \"^http://localhost\" } ] }","title":"Check URL Links"},{"location":"gh_actions/url_test_in_cloudfront/#broken-links-report-to-issue","text":"name: Broken Links Report to GH Issues on: push: branches: - main repository_dispatch: workflow_dispatch: # schedule: # - cron: \"00 18 * * *\" concurrency: # New commit on branch cancels running workflows of the same branch group: ${{ github.workflow }}-${{ github.ref }} cancel-in-progress: true jobs: links: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2.3.4 - name: Link Checker uses: lycheeverse/lychee-action@v1.5.1 with: # TODO TOML is causing kernel panick and fails to render report --config .github/lychee.toml # TODO --exclude-path .lychee.excludes NOT WORKING AS EXPECTED args: > --exclude-mail --no-progress --timeout 45 './**/*.md' './**/*.html' # --cache --max-cache-age 1d -- **/*.md *.md **/*.html # --verbose # --accept=200,403,429 # --exclude-mail **/*.html **/*.md **/*.txt **/*.json --exclude-file .lychee.excludes # --exclude-all-private --insecure # --max-retries 4 # -- **/*.md *.md '**/*.md' # --cache --max-cache-age 1d '**/*.md' README.md patterns/ output: out.md jobSummary: true env: GITHUB_TOKEN: ${{ secrets.actions }} - name: Create Issue From File # if: github.event_name != 'pull_request' # if: steps.lychee.outputs.exit_code != 0 uses: peter-evans/create-issue-from-file@v4 with: title: Link Checker Report content-filepath: out.md # token: ${{ secrets.actions }} #content-filepath: ./link-checker/out.md labels: | report links automated issue issue-number: 15 Use file to ignore URLs. Add .lycheeingnore to project root directory: file://* http://127.0.0.1:8000/","title":"Broken links report to issue"},{"location":"gh_actions/url_test_in_cloudfront/#on-event","text":"## Manual Trigger from Github UI on: workflow_dispatch: ## Push Trigger on: push: paths: - 'docs/**' - 'mkdocs.yml' - '.github/workflows/main.yml' - 'pyproject.toml' branches: - main pull_request: # The branches below must be a subset of the branches above ## types: [opened, synchronize, reopened] branches: [ \"main\" ] concurrency: # New commit on branch cancels running workflows of the same branch group: ${{ github.workflow }}-${{ github.ref }} cancel-in-progress: true ## Workflow Call on: workflow_call","title":"ON Event"},{"location":"gh_actions/url_test_in_cloudfront/#reusable-workflows","text":"TODO","title":"Reusable workflows"},{"location":"gh_actions/url_test_in_cloudfront/#workflow-for-github-actions","text":"TODO","title":"Workflow for Github Actions"},{"location":"gh_actions/url_test_in_cloudfront/#using-github-actions-to-push-to-aws-ecr-with-credentials","text":"https://aws.plainenglish.io/build-a-docker-image-and-publish-it-to-aws-ecr-using-github-actions-f20accd774c3","title":"Using Github Actions to push to AWS ECR with Credentials"},{"location":"gh_actions/url_test_in_cloudfront/#using-github-actions-openid-connect-to-push-to-aws-ecr-without-credentials","text":"https://blog.tedivm.com/guides/2021/10/github-actions-push-to-aws-ecr-without-credentials-oidc/","title":"Using Github Actions OpenID Connect to push to AWS ECR without Credentials"},{"location":"gh_actions/url_test_in_cloudfront/#pushing-the-container","text":"WIth all that out of the way here\u2019s full action to build and deploy an image to ECR. In this we\u2019re chaining together a variety of published actions from other vendors- actions/checkout to actually pull the repository. docker/setup-qemu-action to install an emulation layer to build multiplatform images. docker/setup-buildx-action to use the docker buildx system, again for multiplatform images. aws-actions/configure-aws-credentials to log into AWS. aws-actions/amazon-ecr-login to log into AWS ECR. docker/metadata-action to create a bunch of tags for our docker container. docker/build-push-action to push the container.","title":"Pushing the Container"},{"location":"gh_actions/checks/actions/","text":"Actions Connection Check What is this check for? Make sure the runner has access to actions service for GitHub.com or GitHub Enterprise Server For GitHub.com The runner needs to access https://api.github.com for downloading actions. The runner needs to access https://vstoken.actions.githubusercontent.com/_apis/.../ for requesting an access token. The runner needs to access https://pipelines.actions.githubusercontent.com/_apis/.../ for receiving workflow jobs. These can by tested by running the following curl commands from your self-hosted runner machine: ``` curl -v https://api.github.com/api/v3/zen curl -v https://vstoken.actions.githubusercontent.com/_apis/health curl -v https://pipelines.actions.githubusercontent.com/_apis/health ``` For GitHub Enterprise Server The runner needs to access https://[hostname]/api/v3 for downloading actions. The runner needs to access https://[hostname]/_services/vstoken/_apis/.../ for requesting an access token. The runner needs to access https://[hostname]/_services/pipelines/_apis/.../ for receiving workflow jobs. These can by tested by running the following curl commands from your self-hosted runner machine, replacing [hostname] with the hostname of your appliance, for instance github.example.com : ``` curl -v https://[hostname]/api/v3/zen curl -v https://[hostname]/_services/vstoken/_apis/health curl -v https://[hostname]/_services/pipelines/_apis/health ``` A common cause of this these connectivity issues is if your to GitHub Enterprise Server appliance is using [the self-signed certificate that is enabled the first time](https://docs.github.com/en/enterprise-server/admin/configuration/configuring-network-settings/configuring-tls) your appliance is started. As self-signed certificates are not trusted by web browsers and Git clients, these clients (including the GitHub Actions runner) will report certificate warnings. We recommend [upload a certificate signed by a trusted authority](https://docs.github.com/en/enterprise-server/admin/configuration/configuring-network-settings/configuring-tls) to GitHub Enterprise Server, or enabling the built-in ][Let's Encrypt support](https://docs.github.com/en/enterprise-server/admin/configuration/configuring-network-settings/configuring-tls). What is checked? DNS lookup for api.github.com or myGHES.com using dotnet Ping api.github.com or myGHES.com using dotnet Make HTTP GET to https://api.github.com or https://myGHES.com/api/v3 using dotnet, check response headers contains X-GitHub-Request-Id DNS lookup for vstoken.actions.githubusercontent.com using dotnet Ping vstoken.actions.githubusercontent.com using dotnet Make HTTP GET to https://vstoken.actions.githubusercontent.com/_apis/health or https://myGHES.com/_services/vstoken/_apis/health using dotnet, check response headers contains x-vss-e2eid DNS lookup for pipelines.actions.githubusercontent.com using dotnet Ping pipelines.actions.githubusercontent.com using dotnet Make HTTP GET to https://pipelines.actions.githubusercontent.com/_apis/health or https://myGHES.com/_services/pipelines/_apis/health using dotnet, check response headers contains x-vss-e2eid Make HTTP POST to https://pipelines.actions.githubusercontent.com/_apis/health or https://myGHES.com/_services/pipelines/_apis/health using dotnet, check response headers contains x-vss-e2eid How to fix the issue? 1. Check the common network issue Please check the network doc 2. SSL certificate related issue If you are seeing System.Net.Http.HttpRequestException: The SSL connection could not be established, see inner exception. in the log, it means the runner can't connect to Actions service due to SSL handshake failure. Please check the SSL cert doc Still not working? Contact GitHub Support if you have further questuons, or log an issue at https://github.com/actions/runner if you think it's a runner issue.","title":"Actions"},{"location":"gh_actions/checks/actions/#actions-connection-check","text":"","title":"Actions Connection Check"},{"location":"gh_actions/checks/actions/#what-is-this-check-for","text":"Make sure the runner has access to actions service for GitHub.com or GitHub Enterprise Server For GitHub.com The runner needs to access https://api.github.com for downloading actions. The runner needs to access https://vstoken.actions.githubusercontent.com/_apis/.../ for requesting an access token. The runner needs to access https://pipelines.actions.githubusercontent.com/_apis/.../ for receiving workflow jobs. These can by tested by running the following curl commands from your self-hosted runner machine: ``` curl -v https://api.github.com/api/v3/zen curl -v https://vstoken.actions.githubusercontent.com/_apis/health curl -v https://pipelines.actions.githubusercontent.com/_apis/health ``` For GitHub Enterprise Server The runner needs to access https://[hostname]/api/v3 for downloading actions. The runner needs to access https://[hostname]/_services/vstoken/_apis/.../ for requesting an access token. The runner needs to access https://[hostname]/_services/pipelines/_apis/.../ for receiving workflow jobs. These can by tested by running the following curl commands from your self-hosted runner machine, replacing [hostname] with the hostname of your appliance, for instance github.example.com : ``` curl -v https://[hostname]/api/v3/zen curl -v https://[hostname]/_services/vstoken/_apis/health curl -v https://[hostname]/_services/pipelines/_apis/health ``` A common cause of this these connectivity issues is if your to GitHub Enterprise Server appliance is using [the self-signed certificate that is enabled the first time](https://docs.github.com/en/enterprise-server/admin/configuration/configuring-network-settings/configuring-tls) your appliance is started. As self-signed certificates are not trusted by web browsers and Git clients, these clients (including the GitHub Actions runner) will report certificate warnings. We recommend [upload a certificate signed by a trusted authority](https://docs.github.com/en/enterprise-server/admin/configuration/configuring-network-settings/configuring-tls) to GitHub Enterprise Server, or enabling the built-in ][Let's Encrypt support](https://docs.github.com/en/enterprise-server/admin/configuration/configuring-network-settings/configuring-tls).","title":"What is this check for?"},{"location":"gh_actions/checks/actions/#what-is-checked","text":"DNS lookup for api.github.com or myGHES.com using dotnet Ping api.github.com or myGHES.com using dotnet Make HTTP GET to https://api.github.com or https://myGHES.com/api/v3 using dotnet, check response headers contains X-GitHub-Request-Id DNS lookup for vstoken.actions.githubusercontent.com using dotnet Ping vstoken.actions.githubusercontent.com using dotnet Make HTTP GET to https://vstoken.actions.githubusercontent.com/_apis/health or https://myGHES.com/_services/vstoken/_apis/health using dotnet, check response headers contains x-vss-e2eid DNS lookup for pipelines.actions.githubusercontent.com using dotnet Ping pipelines.actions.githubusercontent.com using dotnet Make HTTP GET to https://pipelines.actions.githubusercontent.com/_apis/health or https://myGHES.com/_services/pipelines/_apis/health using dotnet, check response headers contains x-vss-e2eid Make HTTP POST to https://pipelines.actions.githubusercontent.com/_apis/health or https://myGHES.com/_services/pipelines/_apis/health using dotnet, check response headers contains x-vss-e2eid","title":"What is checked?"},{"location":"gh_actions/checks/actions/#how-to-fix-the-issue","text":"","title":"How to fix the issue?"},{"location":"gh_actions/checks/actions/#1-check-the-common-network-issue","text":"Please check the network doc","title":"1. Check the common network issue"},{"location":"gh_actions/checks/actions/#2-ssl-certificate-related-issue","text":"If you are seeing System.Net.Http.HttpRequestException: The SSL connection could not be established, see inner exception. in the log, it means the runner can't connect to Actions service due to SSL handshake failure. Please check the SSL cert doc","title":"2. SSL certificate related issue"},{"location":"gh_actions/checks/actions/#still-not-working","text":"Contact GitHub Support if you have further questuons, or log an issue at https://github.com/actions/runner if you think it's a runner issue.","title":"Still not working?"},{"location":"gh_actions/checks/auth/","text":"Runner Authentication and Authorization Goals Support runner installs in untrusted domains. The account that configures or runs the runner process is not relevant for accessing GitHub resources. Accessing GitHub resources is done with a per-job token which expires when job completes. The token is granted to trusted parts of the system including the runner, actions and script steps specified by the workflow author as trusted. All OAuth tokens that come from the Token Service that the runner uses to access Actions Service resources are the same. It's just the scope and expiration of the token that may vary. Configuration Configuring a self-hosted runner is covered here in the documentation . Configuration is done with the user being authenticated via a time-limited, GitHub runner registration token. Your credentials are never used for registering the runner with the service. During configuration, an RSA public/private key pair is created, the private key is stored in file on disk. On Windows, the content is protected with DPAPI (machine level encrypted - runner only valid on that machine) and on Linux/OSX with chmod permissions. Using your credentials, the runner is registered with the service by sending the public key to the service which adds that runner to the pool and stores the public key, the Token Service will generate a clientId associated with the public key. Start and Listen After configuring the runner, the runner can be started interactively ( ./run.cmd or ./run.sh ) or as a service. On start, the runner listener process loads the RSA private key (on Windows decrypting with machine key DPAPI), and asks the Token Service for an OAuth token which is signed with the RSA private key. The server then responds with an OAuth token that grants permission to access the message queue (HTTP long poll), allowing the runner to acquire the messages it will eventually run. Run a workflow When a workflow is run, its labels are evaluated, it is matched to a runner and a message is placed in a queue of messages for that runner. The runner then starts listening for jobs via the message queue HTTP long poll. The message is encrypted with the runner's public key, stored during runner configuration. A workflow is queued as a result of a triggered event . Workflows can be scheduled to run at specific UTC times using POSIX cron syntax. An OAuth token is generated, granting limited access to the host in Actions Service associated with the github.com repository/organization. The lifetime of the OAuth token is the lifetime of the run or at most the job timeout (default: 6 hours) , plus 10 additional minutes. Accessing GitHub resources The job message sent to the runner contains the OAuth token to talk back to the Actions Service. The runner listener parent process will spawn a runner worker process for that job and send it the job message over IPC. The token is never persisted. Each action is run as a unique subprocess. The encrypted access token will be provided as an environment variable in each action subprocess. The token is registered with the runner as a secret and scrubbed from the logs as they are written. Authentication in a workflow run to github.com can be accomplished by using the GITHUB_TOKEN ) secret. This token expires after 60 minutes. Please note that this token is different from the OAuth token that the runner uses to talk to the Actions Service. Hosted runner authentication Hosted runner authentication differs from self-hosted authentication in that runners do not undergo a registration process, but instead, the hosted runners get the OAuth token directly by reading the .credentials file. The scope of this particular token is limited for a given workflow job execution, and the token is revoked as soon as the job is finished.","title":"Auth"},{"location":"gh_actions/checks/auth/#runner-authentication-and-authorization","text":"","title":"Runner Authentication and Authorization"},{"location":"gh_actions/checks/auth/#goals","text":"Support runner installs in untrusted domains. The account that configures or runs the runner process is not relevant for accessing GitHub resources. Accessing GitHub resources is done with a per-job token which expires when job completes. The token is granted to trusted parts of the system including the runner, actions and script steps specified by the workflow author as trusted. All OAuth tokens that come from the Token Service that the runner uses to access Actions Service resources are the same. It's just the scope and expiration of the token that may vary.","title":"Goals"},{"location":"gh_actions/checks/auth/#configuration","text":"Configuring a self-hosted runner is covered here in the documentation . Configuration is done with the user being authenticated via a time-limited, GitHub runner registration token. Your credentials are never used for registering the runner with the service. During configuration, an RSA public/private key pair is created, the private key is stored in file on disk. On Windows, the content is protected with DPAPI (machine level encrypted - runner only valid on that machine) and on Linux/OSX with chmod permissions. Using your credentials, the runner is registered with the service by sending the public key to the service which adds that runner to the pool and stores the public key, the Token Service will generate a clientId associated with the public key.","title":"Configuration"},{"location":"gh_actions/checks/auth/#start-and-listen","text":"After configuring the runner, the runner can be started interactively ( ./run.cmd or ./run.sh ) or as a service. On start, the runner listener process loads the RSA private key (on Windows decrypting with machine key DPAPI), and asks the Token Service for an OAuth token which is signed with the RSA private key. The server then responds with an OAuth token that grants permission to access the message queue (HTTP long poll), allowing the runner to acquire the messages it will eventually run.","title":"Start and Listen"},{"location":"gh_actions/checks/auth/#run-a-workflow","text":"When a workflow is run, its labels are evaluated, it is matched to a runner and a message is placed in a queue of messages for that runner. The runner then starts listening for jobs via the message queue HTTP long poll. The message is encrypted with the runner's public key, stored during runner configuration. A workflow is queued as a result of a triggered event . Workflows can be scheduled to run at specific UTC times using POSIX cron syntax. An OAuth token is generated, granting limited access to the host in Actions Service associated with the github.com repository/organization. The lifetime of the OAuth token is the lifetime of the run or at most the job timeout (default: 6 hours) , plus 10 additional minutes.","title":"Run a workflow"},{"location":"gh_actions/checks/auth/#accessing-github-resources","text":"The job message sent to the runner contains the OAuth token to talk back to the Actions Service. The runner listener parent process will spawn a runner worker process for that job and send it the job message over IPC. The token is never persisted. Each action is run as a unique subprocess. The encrypted access token will be provided as an environment variable in each action subprocess. The token is registered with the runner as a secret and scrubbed from the logs as they are written. Authentication in a workflow run to github.com can be accomplished by using the GITHUB_TOKEN ) secret. This token expires after 60 minutes. Please note that this token is different from the OAuth token that the runner uses to talk to the Actions Service.","title":"Accessing GitHub resources"},{"location":"gh_actions/checks/auth/#hosted-runner-authentication","text":"Hosted runner authentication differs from self-hosted authentication in that runners do not undergo a registration process, but instead, the hosted runners get the OAuth token directly by reading the .credentials file. The scope of this particular token is limited for a given workflow job execution, and the token is revoked as soon as the job is finished.","title":"Hosted runner authentication"},{"location":"gh_actions/checks/git/","text":"Git Connection Check What is this check for? Make sure git can access GitHub.com or your GitHub Enterprise Server. What is checked? The test is done by executing # For GitHub.com git ls-remote --exit-code https://github.com/actions/checkout HEAD # For GitHub Enterprise Server git ls-remote --exit-code https://ghes.me/actions/checkout HEAD The test also set environment variable GIT_TRACE=1 and GIT_CURL_VERBOSE=1 before running git ls-remote , this will make git to produce debug log for better debug any potential issues. How to fix the issue? 1. Check global and system git config If you are having issues connecting to the server, check your global and system git config for any unexpected authentication headers. You might be seeing an error like: fatal: unable to access 'https://github.com/actions/checkout/': The requested URL returned error: 400 The following commands can be used to check for unexpected authentication headers: $ git config --global --list | grep extraheader http.extraheader=AUTHORIZATION: unexpected_auth_header $ git config --system --list | grep extraheader The following command can be used to remove the above value: git config --global --unset http.extraheader 2. Check the common network issue Please check the network doc 3. SSL certificate related issue If you are seeing SSL Certificate problem: in the log, it means the git can't connect to the GitHub server due to SSL handshake failure. Please check the SSL cert doc Still not working? Contact GitHub customer service or log an issue at https://github.com/actions/runner if you think it's a runner issue.","title":"Git"},{"location":"gh_actions/checks/git/#git-connection-check","text":"","title":"Git Connection Check"},{"location":"gh_actions/checks/git/#what-is-this-check-for","text":"Make sure git can access GitHub.com or your GitHub Enterprise Server.","title":"What is this check for?"},{"location":"gh_actions/checks/git/#what-is-checked","text":"The test is done by executing # For GitHub.com git ls-remote --exit-code https://github.com/actions/checkout HEAD # For GitHub Enterprise Server git ls-remote --exit-code https://ghes.me/actions/checkout HEAD The test also set environment variable GIT_TRACE=1 and GIT_CURL_VERBOSE=1 before running git ls-remote , this will make git to produce debug log for better debug any potential issues.","title":"What is checked?"},{"location":"gh_actions/checks/git/#how-to-fix-the-issue","text":"","title":"How to fix the issue?"},{"location":"gh_actions/checks/git/#1-check-global-and-system-git-config","text":"If you are having issues connecting to the server, check your global and system git config for any unexpected authentication headers. You might be seeing an error like: fatal: unable to access 'https://github.com/actions/checkout/': The requested URL returned error: 400 The following commands can be used to check for unexpected authentication headers: $ git config --global --list | grep extraheader http.extraheader=AUTHORIZATION: unexpected_auth_header $ git config --system --list | grep extraheader The following command can be used to remove the above value: git config --global --unset http.extraheader","title":"1. Check global and system git config"},{"location":"gh_actions/checks/git/#2-check-the-common-network-issue","text":"Please check the network doc","title":"2. Check the common network issue"},{"location":"gh_actions/checks/git/#3-ssl-certificate-related-issue","text":"If you are seeing SSL Certificate problem: in the log, it means the git can't connect to the GitHub server due to SSL handshake failure. Please check the SSL cert doc","title":"3. SSL certificate related issue"},{"location":"gh_actions/checks/git/#still-not-working","text":"Contact GitHub customer service or log an issue at https://github.com/actions/runner if you think it's a runner issue.","title":"Still not working?"},{"location":"gh_actions/checks/internet/","text":"Internet Connection Check What is this check for? Make sure the runner has access to https://api.github.com The runner needs to access https://api.github.com to download any actions from the marketplace. Even the runner is configured to GitHub Enterprise Server, the runner can still download actions from GitHub.com with GitHub Connect What is checked? DNS lookup for api.github.com using dotnet Ping api.github.com using dotnet Make HTTP GET to https://api.github.com using dotnet, check response headers contains X-GitHub-Request-Id How to fix the issue? 1. Check the common network issue Please check the network doc Still not working? Contact GitHub customer service or log an issue at https://github.com/actions/runner if you think it's a runner issue.","title":"Internet"},{"location":"gh_actions/checks/internet/#internet-connection-check","text":"","title":"Internet Connection Check"},{"location":"gh_actions/checks/internet/#what-is-this-check-for","text":"Make sure the runner has access to https://api.github.com The runner needs to access https://api.github.com to download any actions from the marketplace. Even the runner is configured to GitHub Enterprise Server, the runner can still download actions from GitHub.com with GitHub Connect","title":"What is this check for?"},{"location":"gh_actions/checks/internet/#what-is-checked","text":"DNS lookup for api.github.com using dotnet Ping api.github.com using dotnet Make HTTP GET to https://api.github.com using dotnet, check response headers contains X-GitHub-Request-Id","title":"What is checked?"},{"location":"gh_actions/checks/internet/#how-to-fix-the-issue","text":"","title":"How to fix the issue?"},{"location":"gh_actions/checks/internet/#1-check-the-common-network-issue","text":"Please check the network doc","title":"1. Check the common network issue"},{"location":"gh_actions/checks/internet/#still-not-working","text":"Contact GitHub customer service or log an issue at https://github.com/actions/runner if you think it's a runner issue.","title":"Still not working?"},{"location":"gh_actions/checks/network/","text":"Common Network Related Issues Common things that can cause the runner to not working properly A bug in the runner or the dotnet framework that causes the actions runner to be unable to make Http requests in a certain network environment. A Proxy or Firewall may block certain HTTP method, such as blocking all POST and PUT calls which the runner will use to upload logs. A Proxy or Firewall may only allows requests with certain user-agent to pass through and the actions runner user-agent is not in the allow list. A Proxy try to decrypt and exam HTTPS traffic for security purpose but cause the actions-runner to fail to finish SSL handshake due to the lack of trusting proxy's CA. The SSL handshake may fail if the client and server do not support the same TLS version, or the same cipher suites. A Proxy may try to modify the HTTPS request (like add or change some http headers) and causes the request become incompatible with the Actions Service (ASP.NetCore), Ex: Nginx Firewall rules that block action runner from accessing certain hosts, ex: *.github.com , *.actions.githubusercontent.com , etc Identify and solve these problems The key is to figure out where is the problem, the network environment, or the actions runner? Use a 3rd party tool to make the same requests as the runner did would be a good start point. Use nslookup to check DNS Use ping to check Ping Use traceroute , tracepath , or tracert to check the network route between the runner and the Actions service Use curl -v to check the network stack, good for verifying default certificate/proxy settings. Use Invoke-WebRequest from pwsh ( PowerShell Core ) to check the dotnet network stack, good for verifying bugs in the dotnet framework. If the 3rd party tool is also experiencing the same error as the runner does, then you might want to contact your network administrator for help. Otherwise, contact GitHub customer support or log an issue at https://github.com/actions/runner Troubleshooting: Why can't I configure a runner? If you are having trouble connecting, try these steps: Validate you can reach our endpoints from your web browser. If not, double check your local network connection For hosted Github: https://api.github.com/ https://vstoken.actions.githubusercontent.com/_apis/health https://pipelines.actions.githubusercontent.com/_apis/health For GHES/GHAE https://myGHES.com/_services/vstoken/_apis/health https://myGHES.com/_services/pipelines/_apis/health https://myGHES.com/api/v3 Validate you can reach those endpoints in powershell core The runner runs on .net core, lets validate the local settings for that stack Open up pwsh Run the command using the urls above Invoke-WebRequest {url} If not, get a packet trace using a tool like wireshark and start looking at the TLS handshake. If you see a Client Hello followed by a Server RST: You may need to configure your TLS settings to use the correct version You should support TLS version 1.2 or later You may need to configure your TLS settings to have up to date cipher suites, this may be solved by system updates and patches. Most notably, on windows server 2012 make sure the tls cipher suite update is installed Your firewall, proxy or network configuration may be blocking the connection You will want to reach out to whoever is in charge of your network with these pcap files to further troubleshoot If you see a failure later in the handshake: Try the fix in the SSLCert Fix","title":"Network"},{"location":"gh_actions/checks/network/#common-network-related-issues","text":"","title":"Common Network Related Issues"},{"location":"gh_actions/checks/network/#common-things-that-can-cause-the-runner-to-not-working-properly","text":"A bug in the runner or the dotnet framework that causes the actions runner to be unable to make Http requests in a certain network environment. A Proxy or Firewall may block certain HTTP method, such as blocking all POST and PUT calls which the runner will use to upload logs. A Proxy or Firewall may only allows requests with certain user-agent to pass through and the actions runner user-agent is not in the allow list. A Proxy try to decrypt and exam HTTPS traffic for security purpose but cause the actions-runner to fail to finish SSL handshake due to the lack of trusting proxy's CA. The SSL handshake may fail if the client and server do not support the same TLS version, or the same cipher suites. A Proxy may try to modify the HTTPS request (like add or change some http headers) and causes the request become incompatible with the Actions Service (ASP.NetCore), Ex: Nginx Firewall rules that block action runner from accessing certain hosts, ex: *.github.com , *.actions.githubusercontent.com , etc","title":"Common things that can cause the runner to not working properly"},{"location":"gh_actions/checks/network/#identify-and-solve-these-problems","text":"The key is to figure out where is the problem, the network environment, or the actions runner? Use a 3rd party tool to make the same requests as the runner did would be a good start point. Use nslookup to check DNS Use ping to check Ping Use traceroute , tracepath , or tracert to check the network route between the runner and the Actions service Use curl -v to check the network stack, good for verifying default certificate/proxy settings. Use Invoke-WebRequest from pwsh ( PowerShell Core ) to check the dotnet network stack, good for verifying bugs in the dotnet framework. If the 3rd party tool is also experiencing the same error as the runner does, then you might want to contact your network administrator for help. Otherwise, contact GitHub customer support or log an issue at https://github.com/actions/runner","title":"Identify and solve these problems"},{"location":"gh_actions/checks/network/#troubleshooting-why-cant-i-configure-a-runner","text":"If you are having trouble connecting, try these steps: Validate you can reach our endpoints from your web browser. If not, double check your local network connection For hosted Github: https://api.github.com/ https://vstoken.actions.githubusercontent.com/_apis/health https://pipelines.actions.githubusercontent.com/_apis/health For GHES/GHAE https://myGHES.com/_services/vstoken/_apis/health https://myGHES.com/_services/pipelines/_apis/health https://myGHES.com/api/v3 Validate you can reach those endpoints in powershell core The runner runs on .net core, lets validate the local settings for that stack Open up pwsh Run the command using the urls above Invoke-WebRequest {url} If not, get a packet trace using a tool like wireshark and start looking at the TLS handshake. If you see a Client Hello followed by a Server RST: You may need to configure your TLS settings to use the correct version You should support TLS version 1.2 or later You may need to configure your TLS settings to have up to date cipher suites, this may be solved by system updates and patches. Most notably, on windows server 2012 make sure the tls cipher suite update is installed Your firewall, proxy or network configuration may be blocking the connection You will want to reach out to whoever is in charge of your network with these pcap files to further troubleshoot If you see a failure later in the handshake: Try the fix in the SSLCert Fix","title":"Troubleshooting: Why can't I configure a runner?"},{"location":"gh_actions/checks/nodejs/","text":"Node.js Connection Check What is this check for? Make sure the built-in node.js has access to GitHub.com or GitHub Enterprise Server. The runner carries its own copy of node.js executable under <runner_root>/externals/node16/ . All javascript base Actions will get executed by the built-in node at <runner_root>/externals/node16/ . Not the node from $PATH What is checked? Make HTTPS GET to https://api.github.com or https://myGHES.com/api/v3 using node.js, make sure it gets 200 response code. How to fix the issue? 1. Check the common network issue Please check the network doc 2. SSL certificate related issue If you are seeing Https request failed due to SSL cert issue in the log, it means the node.js can't connect to the GitHub server due to SSL handshake failure. Please check the SSL cert doc Still not working? Contact GitHub customer service or log an issue at https://github.com/actions/runner if you think it's a runner issue.","title":"Nodejs"},{"location":"gh_actions/checks/nodejs/#nodejs-connection-check","text":"","title":"Node.js Connection Check"},{"location":"gh_actions/checks/nodejs/#what-is-this-check-for","text":"Make sure the built-in node.js has access to GitHub.com or GitHub Enterprise Server. The runner carries its own copy of node.js executable under <runner_root>/externals/node16/ . All javascript base Actions will get executed by the built-in node at <runner_root>/externals/node16/ . Not the node from $PATH","title":"What is this check for?"},{"location":"gh_actions/checks/nodejs/#what-is-checked","text":"Make HTTPS GET to https://api.github.com or https://myGHES.com/api/v3 using node.js, make sure it gets 200 response code.","title":"What is checked?"},{"location":"gh_actions/checks/nodejs/#how-to-fix-the-issue","text":"","title":"How to fix the issue?"},{"location":"gh_actions/checks/nodejs/#1-check-the-common-network-issue","text":"Please check the network doc","title":"1. Check the common network issue"},{"location":"gh_actions/checks/nodejs/#2-ssl-certificate-related-issue","text":"If you are seeing Https request failed due to SSL cert issue in the log, it means the node.js can't connect to the GitHub server due to SSL handshake failure. Please check the SSL cert doc","title":"2. SSL certificate related issue"},{"location":"gh_actions/checks/nodejs/#still-not-working","text":"Contact GitHub customer service or log an issue at https://github.com/actions/runner if you think it's a runner issue.","title":"Still not working?"},{"location":"gh_actions/checks/ssl_certs/","text":"SSL Certificate Related Issues You might run into an SSL certificate error when your GitHub Enterprise Server is using a self-signed SSL server certificate or a web proxy within your network is decrypting HTTPS traffic for a security audit. As long as your certificate is generated properly, most of the issues should be fixed after your trust the certificate properly on the runner machine. github repo actions/runner Different OS might have extra requirements on SSL certificate, Ex: macOS requires ExtendedKeyUsage https://support.apple.com/en-us/HT210176 Don't skip SSL cert validation !!! DO NOT SKIP SSL CERT VALIDATION !!! !!! IT IS A BAD SECURITY PRACTICE !!! Download SSL certificate chain Depends on how your SSL server certificate gets configured, you might need to download the whole certificate chain from a machine that has trusted the SSL certificate's CA. Approach 1: Download certificate chain using a browser (Chrome, Firefox, IT), you can google for more example, here is what I found Approach 2: Download certificate chain using OpenSSL, you can google for more example, here is what I found Approach 3: Ask your network administrator or the owner of the CA certificate to send you a copy of it Trust CA certificate for the Runner The actions runner is a dotnet core application which will follow how dotnet load SSL CA certificates on each OS. You can get full details documentation at here In short: - Windows: Load from Windows certificate store. - Linux: Load from OpenSSL CA cert bundle. - macOS: Load from macOS KeyChain. To let the runner trusts your CA certificate, you will need to: 1. Save your SSL certificate chain which includes the root CA and all intermediate CAs into a .pem file. 2. Use OpenSSL to convert .pem file to a proper format for different OS, here is some doc with sample commands 3. Trust CA on different OS: - Windows: https://docs.microsoft.com/en-us/skype-sdk/sdn/articles/installing-the-trusted-root-certificate - macOS: - Linux: Refer to the distribution documentation 1. RedHat: https://www.redhat.com/sysadmin/ca-certificates-cli 2. Ubuntu: http://manpages.ubuntu.com/manpages/focal/man8/update-ca-certificates.8.html 3. Google search: \"trust ca certificate on [linux distribution]\" 4. If all approaches failed, set environment variable SSL_CERT_FILE to the CA bundle .pem file we get. > To verify cert gets installed properly on Linux, you can try use curl -v https://sitewithsslissue.com and pwsh -Command \\\"Invoke-WebRequest -Uri https://sitewithsslissue.com\\\" Trust CA certificate for Git CLI Git uses various CA bundle file depends on your operation system. - Git packaged the CA bundle file within the Git installation on Windows - Git use OpenSSL certificate CA bundle file on Linux and macOS You can check where Git check CA file by running: export GIT_CURL_VERBOSE=1 git ls-remote https://github.com/actions/runner HEAD You should see something like: * Couldn't find host github.com in the .netrc file; using defaults * Trying 140.82.114.4... * TCP_NODELAY set * Connected to github.com (140.82.114.4) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * successfully set certificate verify locations: * CAfile: /etc/ssl/cert.pem CApath: none * SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256 This tells me /etc/ssl/cert.pem is where it read trusted CA certificates. To let Git trusts your CA certificate, you will need to: 1. Save your SSL certificate chain which includes the root CA and all intermediate CAs into a .pem file. 2. Set http.sslCAInfo Git config or GIT_SSL_CAINFO environment variable to the full path of the .pem file Git Doc I would recommend using http.sslCAInfo since it can be scope to certain hosts that need the extra trusted CA. Ex: git config --global http.https://myghes.com/.sslCAInfo /extra/ca/cert.pem This will make Git use the /extra/ca/cert.pem only when communicates with https://myghes.com and keep using the default CA bundle with others. Trust CA certificate for Node.js Node.js has compiled a snapshot of the Mozilla CA store that is fixed at each version of Node.js' release time. To let Node.js trusts your CA certificate, you will need to: 1. Save your SSL certificate chain which includes the root CA and all intermediate CAs into a .pem file. 2. Set environment variable NODE_EXTRA_CA_CERTS which point to the file. ex: export NODE_EXTRA_CA_CERTS=/full/path/to/cacert.pem or set NODE_EXTRA_CA_CERTS=C:\\full\\path\\to\\cacert.pem","title":"SSL Certs"},{"location":"gh_actions/checks/ssl_certs/#ssl-certificate-related-issues","text":"You might run into an SSL certificate error when your GitHub Enterprise Server is using a self-signed SSL server certificate or a web proxy within your network is decrypting HTTPS traffic for a security audit. As long as your certificate is generated properly, most of the issues should be fixed after your trust the certificate properly on the runner machine. github repo actions/runner Different OS might have extra requirements on SSL certificate, Ex: macOS requires ExtendedKeyUsage https://support.apple.com/en-us/HT210176","title":"SSL Certificate Related Issues"},{"location":"gh_actions/checks/ssl_certs/#dont-skip-ssl-cert-validation","text":"!!! DO NOT SKIP SSL CERT VALIDATION !!! !!! IT IS A BAD SECURITY PRACTICE !!!","title":"Don't skip SSL cert validation"},{"location":"gh_actions/checks/ssl_certs/#download-ssl-certificate-chain","text":"Depends on how your SSL server certificate gets configured, you might need to download the whole certificate chain from a machine that has trusted the SSL certificate's CA. Approach 1: Download certificate chain using a browser (Chrome, Firefox, IT), you can google for more example, here is what I found Approach 2: Download certificate chain using OpenSSL, you can google for more example, here is what I found Approach 3: Ask your network administrator or the owner of the CA certificate to send you a copy of it","title":"Download SSL certificate chain"},{"location":"gh_actions/checks/ssl_certs/#trust-ca-certificate-for-the-runner","text":"The actions runner is a dotnet core application which will follow how dotnet load SSL CA certificates on each OS. You can get full details documentation at here In short: - Windows: Load from Windows certificate store. - Linux: Load from OpenSSL CA cert bundle. - macOS: Load from macOS KeyChain. To let the runner trusts your CA certificate, you will need to: 1. Save your SSL certificate chain which includes the root CA and all intermediate CAs into a .pem file. 2. Use OpenSSL to convert .pem file to a proper format for different OS, here is some doc with sample commands 3. Trust CA on different OS: - Windows: https://docs.microsoft.com/en-us/skype-sdk/sdn/articles/installing-the-trusted-root-certificate - macOS: - Linux: Refer to the distribution documentation 1. RedHat: https://www.redhat.com/sysadmin/ca-certificates-cli 2. Ubuntu: http://manpages.ubuntu.com/manpages/focal/man8/update-ca-certificates.8.html 3. Google search: \"trust ca certificate on [linux distribution]\" 4. If all approaches failed, set environment variable SSL_CERT_FILE to the CA bundle .pem file we get. > To verify cert gets installed properly on Linux, you can try use curl -v https://sitewithsslissue.com and pwsh -Command \\\"Invoke-WebRequest -Uri https://sitewithsslissue.com\\\"","title":"Trust CA certificate for the Runner"},{"location":"gh_actions/checks/ssl_certs/#trust-ca-certificate-for-git-cli","text":"Git uses various CA bundle file depends on your operation system. - Git packaged the CA bundle file within the Git installation on Windows - Git use OpenSSL certificate CA bundle file on Linux and macOS You can check where Git check CA file by running: export GIT_CURL_VERBOSE=1 git ls-remote https://github.com/actions/runner HEAD You should see something like: * Couldn't find host github.com in the .netrc file; using defaults * Trying 140.82.114.4... * TCP_NODELAY set * Connected to github.com (140.82.114.4) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * successfully set certificate verify locations: * CAfile: /etc/ssl/cert.pem CApath: none * SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256 This tells me /etc/ssl/cert.pem is where it read trusted CA certificates. To let Git trusts your CA certificate, you will need to: 1. Save your SSL certificate chain which includes the root CA and all intermediate CAs into a .pem file. 2. Set http.sslCAInfo Git config or GIT_SSL_CAINFO environment variable to the full path of the .pem file Git Doc I would recommend using http.sslCAInfo since it can be scope to certain hosts that need the extra trusted CA. Ex: git config --global http.https://myghes.com/.sslCAInfo /extra/ca/cert.pem This will make Git use the /extra/ca/cert.pem only when communicates with https://myghes.com and keep using the default CA bundle with others.","title":"Trust CA certificate for Git CLI"},{"location":"gh_actions/checks/ssl_certs/#trust-ca-certificate-for-nodejs","text":"Node.js has compiled a snapshot of the Mozilla CA store that is fixed at each version of Node.js' release time. To let Node.js trusts your CA certificate, you will need to: 1. Save your SSL certificate chain which includes the root CA and all intermediate CAs into a .pem file. 2. Set environment variable NODE_EXTRA_CA_CERTS which point to the file. ex: export NODE_EXTRA_CA_CERTS=/full/path/to/cacert.pem or set NODE_EXTRA_CA_CERTS=C:\\full\\path\\to\\cacert.pem","title":"Trust CA certificate for Node.js"},{"location":"git/bayer_ghc_post_migration/","text":"Post Migration After migrating a repo from github.platforms.engineering to github.com a few additional steps are required. :warning: Warning: This document is very much a work in progress and subject to changes. Tracking Git Tags Each repo requires tags to track BEAT ID, data classification and application regulations. Tags in github typically require publishing a release. For Bayer, topics are used as tags. No release publish is required. :traffic_light: To tag projects in GitHub, so-called \"Topics\" must be used. Topics can be added in the about section on the right side of the project overview, right below the description field. Tagging Conventions Tagging will be used to manage regulatory compliance. To summarize: Data classification and regulatory tagging is mandatory for all repos. Internal-visibility repos will be pre-tagged bayer-internal and bayer-reg-none private-visibilty repos will be pre-tagged bayer-restricted and bayer-reg-undefined. The tags should be updated with the correct classifications, though in many cases the defaults will be correct. It is recommended but not required that repos be tagged with a BEAT ID Three tag categorires are required. Tag Category Bayer Data Classification bayer-not-classified If you do not have code requiring a classification in the repository bayer-internal Internal bayer-restricted Restricted bayer-secret Secret Regulations Tagging Tag Category Regulations Classification bayer-reg-none If a project is not subject to any regulations, use this tag. bayer-reg-gxp If a project is subject to GxP regulations (GMP, GLP, etc.), use this tag. bayer-reg-cd If a project is subject to controlled data regulations, use this tag. For more information, see here. bayer-reg-ics If a project is subject to ICS, use this tag. BEAT ID Tagging Every application at Bayer should have a BEAT entry. For more information, see go/beat. When an application is registered in BEAT, it is assigned a BEAT ID in a BEAT123456 format. If your repository can be linked to an application, please register it in BEAT and add the BEAT ID as a tag in this format: BEAT123456. Creating a BEAT ID only takes a few minutes. If your repository does not have an applicable BEAT ID, please add the tag BEAT-not-applicable . CI/CD Issues Webhooks and secrets will not migrate and will need to be updated. Last update: {{ git_revision_date_localized }}","title":"Post Migration"},{"location":"git/bayer_ghc_post_migration/#post-migration","text":"After migrating a repo from github.platforms.engineering to github.com a few additional steps are required. :warning: Warning: This document is very much a work in progress and subject to changes.","title":"Post Migration"},{"location":"git/bayer_ghc_post_migration/#tracking-git-tags","text":"Each repo requires tags to track BEAT ID, data classification and application regulations. Tags in github typically require publishing a release. For Bayer, topics are used as tags. No release publish is required. :traffic_light: To tag projects in GitHub, so-called \"Topics\" must be used. Topics can be added in the about section on the right side of the project overview, right below the description field.","title":"Tracking Git Tags"},{"location":"git/bayer_ghc_post_migration/#tagging-conventions","text":"Tagging will be used to manage regulatory compliance. To summarize: Data classification and regulatory tagging is mandatory for all repos. Internal-visibility repos will be pre-tagged bayer-internal and bayer-reg-none private-visibilty repos will be pre-tagged bayer-restricted and bayer-reg-undefined. The tags should be updated with the correct classifications, though in many cases the defaults will be correct. It is recommended but not required that repos be tagged with a BEAT ID Three tag categorires are required. Tag Category Bayer Data Classification bayer-not-classified If you do not have code requiring a classification in the repository bayer-internal Internal bayer-restricted Restricted bayer-secret Secret","title":"Tagging Conventions"},{"location":"git/bayer_ghc_post_migration/#regulations-tagging","text":"Tag Category Regulations Classification bayer-reg-none If a project is not subject to any regulations, use this tag. bayer-reg-gxp If a project is subject to GxP regulations (GMP, GLP, etc.), use this tag. bayer-reg-cd If a project is subject to controlled data regulations, use this tag. For more information, see here. bayer-reg-ics If a project is subject to ICS, use this tag.","title":"Regulations Tagging"},{"location":"git/bayer_ghc_post_migration/#beat-id-tagging","text":"Every application at Bayer should have a BEAT entry. For more information, see go/beat. When an application is registered in BEAT, it is assigned a BEAT ID in a BEAT123456 format. If your repository can be linked to an application, please register it in BEAT and add the BEAT ID as a tag in this format: BEAT123456. Creating a BEAT ID only takes a few minutes. If your repository does not have an applicable BEAT ID, please add the tag BEAT-not-applicable .","title":"BEAT ID Tagging"},{"location":"git/bayer_ghc_post_migration/#cicd-issues","text":"Webhooks and secrets will not migrate and will need to be updated. Last update: {{ git_revision_date_localized }}","title":"CI/CD Issues"},{"location":"git/git-bayer-github-proxy/","text":"Access to GitHub.com Bayer Organization The following links will take you to the documentation on how to get started with GitHub.com & Bayer. Setting up GitHub.com for use with Bayer: https://docs.cloud.bayer.com/devops/github/login/ GitHub.com Conventions: https://docs.cloud.bayer.com/devops/github/conventions/ GitHub Actions: https://docs.cloud.bayer.com/devops/github/actions/# https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions https://docs.cloud.bayer.com/devops/github/actions/cloud/#steps-in-aws-account Setting Proxy Variables to work with GitHub.com The following settings will allow you to set your proxy variables for working with GitHub.com Bayer Cloud Documentation: https://docs.cloud.bayer.com/devops/gitlab/#proxy-settings-for-git-client-to-access-from-mycloudpro-pc Step One: Open Git Bash Set the following proxy variables git config --global http.proxy 'http://your1CWID@10.185.190.100:8080' git config --global https.proxy 'https://your1CWID@10.185.190.100:8080' Set Bayer Proxy for GitHub in Rstudio You will want to open Rstudio and then go to Tools -> Terminal -> New Terminal Then you will want to set the proxies the same way you did above by copying the code and entering it in the terminal now open in Rstudio. You can now type the following command and a list of our settings in the global git config file can be seen. git config -l Once this has been completed you should be able to connect to GitHub.com (GHC) or GitHub Engineering (GHE). When connecting you should see a pop up window similar to the one show below. You will want to utilize a Personal Access Token (PAT) to work with either account.","title":"Git bayer github proxy"},{"location":"git/git-bayer-github-proxy/#access-to-githubcom-bayer-organization","text":"The following links will take you to the documentation on how to get started with GitHub.com & Bayer. Setting up GitHub.com for use with Bayer: https://docs.cloud.bayer.com/devops/github/login/ GitHub.com Conventions: https://docs.cloud.bayer.com/devops/github/conventions/ GitHub Actions: https://docs.cloud.bayer.com/devops/github/actions/# https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions https://docs.cloud.bayer.com/devops/github/actions/cloud/#steps-in-aws-account","title":"Access to GitHub.com Bayer Organization"},{"location":"git/git-bayer-github-proxy/#setting-proxy-variables-to-work-with-githubcom","text":"The following settings will allow you to set your proxy variables for working with GitHub.com Bayer Cloud Documentation: https://docs.cloud.bayer.com/devops/gitlab/#proxy-settings-for-git-client-to-access-from-mycloudpro-pc Step One: Open Git Bash Set the following proxy variables git config --global http.proxy 'http://your1CWID@10.185.190.100:8080' git config --global https.proxy 'https://your1CWID@10.185.190.100:8080' Set Bayer Proxy for GitHub in Rstudio You will want to open Rstudio and then go to Tools -> Terminal -> New Terminal","title":"Setting Proxy Variables to work with GitHub.com"},{"location":"git/git-bayer-github-proxy/#_1","text":"Then you will want to set the proxies the same way you did above by copying the code and entering it in the terminal now open in Rstudio. You can now type the following command and a list of our settings in the global git config file can be seen. git config -l Once this has been completed you should be able to connect to GitHub.com (GHC) or GitHub Engineering (GHE). When connecting you should see a pop up window similar to the one show below. You will want to utilize a Personal Access Token (PAT) to work with either account.","title":""},{"location":"git/git-bayer-github-proxy/#_2","text":"","title":""},{"location":"git/git_branch_v1/","text":"Git Branches Create a new branch and merge into main. git checkout -b <branch> The -b is a convenience flag , to run git branch before running git checkout <branch> git pull git checkout -b mike ## create new branch ## Make some changes to mike branch git add . git commit git push --set-upstream origin mike Remotes Show github repo remotes (URL) git remote -v origin https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git (fetch) origin https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git (push) Change remotes To push repo to a new remote, clone repo and change remote path. git push git@github.com:prfrl/amazon-sagemaker-studio-vpc-networkfirewall.git Delete branch Delete local branch git branch -d <branch> Delete branch in remote git push origin -d <branch> Delete local branches not in remote Delete branches that are in local repo but have been removed from remote. First, check that branches of interest are not in this list, e.g. main/master and important feature branches. $ git fetch -p && git branch -vv | awk '/: gone]/{print $1}' - [deleted] (none) -> origin/dependabot/github_actions/actions/setup-python-3 - [deleted] (none) -> origin/dependabot/github_actions/actions/setup-python-4 - [deleted] (none) -> origin/dependabot/pip/mkdocs-1.3.1 - [deleted] (none) -> origin/dependabot/pip/mkdocs-1.4.0 - [deleted] (none) -> origin/dependabot/pip/mkdocs-1.4.1 - [deleted] (none) -> origin/dependabot/pip/mkdocs-git-revision-date-localized-plugin-1.1.0 - [deleted] (none) -> origin/dependabot/pip/mkdocs-material-8.2.15 - [deleted] (none) -> origin/dependabot/pip/mkdocs-material-8.2.5 - [deleted] (none) -> origin/dependabot/pip/mkdocs-material-8.3.5 If the list looks as expected, delete local branches. git fetch -p && git branch -vv | awk '/: gone]/{print $1}' | xargs git branch -d Works by pruning your tracking branches then deleting the local ones that show they are \"gone\" in git branch -vv To finish, verify all important local branches are intact. git branch -a $ git branch -a * main remotes/origin/HEAD -> origin/main remotes/origin/dependabot/github_actions/actions/checkout-3.1.0 remotes/origin/dependabot/github_actions/actions/setup-python-4.1.0 remotes/origin/dependabot/pip/mkdocs-material-8.5.7 remotes/origin/main Compare branches git diff <my branch_v1> <my branch_v2> Update branch from remote git stash (optional, to save local changes which differs from the remote repository if any) git checkout my_local_branch Checkout branch to work on git pull Pull from remote Additionally you can checkout a new local branch and reset it to the remote branches last commit. git checkout -b \uff1cbranchname\uff1e git reset --hard origin/\uff1cbranchname\uff1e Update branch from main When git status shows \"Your branch is ahead of 'origin/main' by 2 commits\", this measn If your local changes are bad then just remove them locally and reset to the state of remote using git reset git reset git checkout <branch> Optional, You may already be in the branch git pull -s recursive -X theirs Take remote branch changes and replace with their changes if conflict arise. Here if you do git status you will get something like this your branch is ahead of 'origin/master' by 3 commits. git reset --hard origin/<branch> git fetch ## Cheatsheet Push branch to remote `git push origin <branch>` Delete branch `git branch -d <branch>` # replace local changes In case you did something wrong, which for sure never happens ;), you can replace local changes using the command `git checkout -- <filename>` this replaces the changes in your working tree with the last content in HEAD. Changes already added to the index, as well as new files, will be kept. If you instead want to drop all your local changes and commits, fetch the latest history from the server and point your local master branch at it like this ```shell git fetch origin git reset --hard origin/master","title":"Branch V1"},{"location":"git/git_branch_v1/#git-branches","text":"Create a new branch and merge into main. git checkout -b <branch> The -b is a convenience flag , to run git branch before running git checkout <branch> git pull git checkout -b mike ## create new branch ## Make some changes to mike branch git add . git commit git push --set-upstream origin mike","title":"Git Branches"},{"location":"git/git_branch_v1/#remotes","text":"Show github repo remotes (URL) git remote -v origin https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git (fetch) origin https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git (push)","title":"Remotes"},{"location":"git/git_branch_v1/#change-remotes","text":"To push repo to a new remote, clone repo and change remote path. git push git@github.com:prfrl/amazon-sagemaker-studio-vpc-networkfirewall.git","title":"Change remotes"},{"location":"git/git_branch_v1/#delete-branch","text":"Delete local branch git branch -d <branch> Delete branch in remote git push origin -d <branch>","title":"Delete branch"},{"location":"git/git_branch_v1/#delete-local-branches-not-in-remote","text":"Delete branches that are in local repo but have been removed from remote. First, check that branches of interest are not in this list, e.g. main/master and important feature branches. $ git fetch -p && git branch -vv | awk '/: gone]/{print $1}' - [deleted] (none) -> origin/dependabot/github_actions/actions/setup-python-3 - [deleted] (none) -> origin/dependabot/github_actions/actions/setup-python-4 - [deleted] (none) -> origin/dependabot/pip/mkdocs-1.3.1 - [deleted] (none) -> origin/dependabot/pip/mkdocs-1.4.0 - [deleted] (none) -> origin/dependabot/pip/mkdocs-1.4.1 - [deleted] (none) -> origin/dependabot/pip/mkdocs-git-revision-date-localized-plugin-1.1.0 - [deleted] (none) -> origin/dependabot/pip/mkdocs-material-8.2.15 - [deleted] (none) -> origin/dependabot/pip/mkdocs-material-8.2.5 - [deleted] (none) -> origin/dependabot/pip/mkdocs-material-8.3.5 If the list looks as expected, delete local branches. git fetch -p && git branch -vv | awk '/: gone]/{print $1}' | xargs git branch -d Works by pruning your tracking branches then deleting the local ones that show they are \"gone\" in git branch -vv To finish, verify all important local branches are intact. git branch -a $ git branch -a * main remotes/origin/HEAD -> origin/main remotes/origin/dependabot/github_actions/actions/checkout-3.1.0 remotes/origin/dependabot/github_actions/actions/setup-python-4.1.0 remotes/origin/dependabot/pip/mkdocs-material-8.5.7 remotes/origin/main","title":"Delete local branches not in remote"},{"location":"git/git_branch_v1/#compare-branches","text":"git diff <my branch_v1> <my branch_v2>","title":"Compare branches"},{"location":"git/git_branch_v1/#update-branch-from-remote","text":"git stash (optional, to save local changes which differs from the remote repository if any) git checkout my_local_branch Checkout branch to work on git pull Pull from remote Additionally you can checkout a new local branch and reset it to the remote branches last commit. git checkout -b \uff1cbranchname\uff1e git reset --hard origin/\uff1cbranchname\uff1e","title":"Update branch from remote"},{"location":"git/git_branch_v1/#update-branch-from-main","text":"When git status shows \"Your branch is ahead of 'origin/main' by 2 commits\", this measn If your local changes are bad then just remove them locally and reset to the state of remote using git reset","title":"Update branch from main"},{"location":"git/git_branch_v1/#git-reset","text":"git checkout <branch> Optional, You may already be in the branch git pull -s recursive -X theirs Take remote branch changes and replace with their changes if conflict arise. Here if you do git status you will get something like this your branch is ahead of 'origin/master' by 3 commits. git reset --hard origin/<branch> git fetch ## Cheatsheet Push branch to remote `git push origin <branch>` Delete branch `git branch -d <branch>` # replace local changes In case you did something wrong, which for sure never happens ;), you can replace local changes using the command `git checkout -- <filename>` this replaces the changes in your working tree with the last content in HEAD. Changes already added to the index, as well as new files, will be kept. If you instead want to drop all your local changes and commits, fetch the latest history from the server and point your local master branch at it like this ```shell git fetch origin git reset --hard origin/master","title":"git reset"},{"location":"git/git_branching/","text":"Branching Workflow for Continuous Delivery This simple workflow has two guiding principles: master is always production-like and deployable. rebase during feature development, explicit (non fast-forward) merge when done. The n commits from this branch will be rebased and added to base branch Pulling change-sets using rebase rewrites the history of the branch you\u2019re working on and keeps your changes on top. Merge vs Rebase Merge branch to main Create a feature branch and make some file edits. gitGraph commit id: \"1\" commit id: \"2\" branch feature commit id: \"A\" commit id: \"B\" checkout main commit id: \"3\" commit id: \"4\" Next, merge the main branch into the feature branch. gitGraph commit id: \"1\" commit id: \"2\" branch feature commit id: \"A\" commit id: \"B\" checkout main commit id: \"3\" commit id: \"4\" merge feature tag: \"Merge Commit\" This creates a new \u201cmerge commit\u201d in the feature branch that ties together the histories of both branches, giving you a branch structure that looks like this: What is a rebase? Preserving the order of change-sets. Create a feature branch and make some file edits. gitGraph commit id: \"1\" commit id: \"2\" branch feature commit id: \"A\" commit id: \"B\" checkout main commit id: \"3\" commit id: \"4\" Rebase moves feature branch to the tip of the main branch. gitGraph commit id: \"1\" commit id: \"2\" branch feature commit id: \"A\" commit id: \"B\" checkout main commit id: \"3\" commit id: \"4\" merge feature Commit history maintains a linear record. gitGraph commit id: \"1\" commit id: \"2\" commit id: \"3\" commit id: \"4\" commit id: \"A\" type: HIGHLIGHT commit id: \"B\" type: HIGHLIGHT Start by pulling down the latest changes from master This is done easily with the common git commands: git checkout master git fetch origin git merge master Branch off to isolate the feature or bug-fix work in a branch Now create a branch for the feature or bug-fix: git checkout -b PRJ-123-awesome-feature The branch name structure I show here is just the one we use, but you can pick any convention you feel comfortable with. Now you can work on the feature Work on the feature as long as needed. Make sure your commits are meaningful and do not cluster separate changes together. To keep your feature branch fresh and up to date with the latest changes in master, use rebase Every once in a while during the development update the feature branch with the latest changes in master. You can do this with: git fetch origin git rebase origin/master In the (somewhat less common) case where other people are also working on the same shared remote feature branch, also rebase changes coming from it: git rebase origin/PRJ-123-awesome-feature At this point solve any conflicts that come out of the rebase. Resolving conflicts during the rebase allows you to have always clean merges at the end of the feature development. It also keeps your feature branch history clean and focused without spurious noise. When ready for feedback push your branch remotely and create a pull request When it\u2019s time to share your work and solicit feedback you can push your branch remotely with: git push -u origin PRJ-123-awesome-feature (if the branch is already set as 'upstream' and your remote is called 'origin', 'git push' is enough) Now you can create a pull request. After the initial push you can keep pushing updates to the remote branch multiple times throughout. This can happen in response to feedback, or because you\u2019re not done with the development of the feature. Perform a final rebase cleanup after the pull request has been approved After the review is done, it\u2019s good to perform a final cleanup and scrub of the feature branch commit history to remove spurious commits that are not providing relevant information. In some cases \u2013 if your team is experienced and they can handle it \u2013 you can rebase also during development, but I strongly advise against it.: git rebase -i origin/master (At this point if you have rewritten the history of a published branch and provided that no one else will commit to it or use it, you might need to push your changes using the \u2013force flag). When development is complete record an explicit merge When finished with the development of the feature branch and reviewers have reviewed your work, merge using the flag \u2013no-ff. This will preserve the context of the work and will make it easy to revert the whole feature if needed. Here are the commands: git checkout master git pull origin master git merge --no-ff PRJ-123-awesome-feature If you followed the advice above and you have used rebase to keep your feature branch up to date, the actual merge commit will not include any changes; this is cool! The merge commit becomes just a marker that stores the context about the feature branch. Good documentation comparing git rebase vs git merge Fix Conflicts Take remote branch changes and replace with their changes if conflict arise. Here if you do git status you will get something like this your branch is ahead of 'origin/master' by 3 commits. git checkout test git pull git checkout master git pull git merge --no-ff --no-commit test Test merge before commit, avoid a fast-forward commit by --no-ff, If conflict is encountered, we can run git status to check details about the conflicts and try to solve git status Once we solve the conflicts, or if there is no conflict, we commit and push them git commit -m 'merge test branch' git push But this way will lose the changes history logged in test branch, and it would make master branch to be hard for other developers to understand the history of the project. So the best method is we have to use rebase instead of merge (suppose, when in this time, we have solved the branch conflicts). Following is one simple sample, for advanced operations, please refer to http://git-scm.com/book/en/v2/Git-Branching-Rebasing git checkout master git pull git checkout test git pull git rebase -i master git checkout master git merge test Yep, when you have uppers done, all the Test branch's commits will be moved onto the head of Master branch. The major benefit of rebasing is that you get a linear and much cleaner project history. The only thing you need to avoid is: never use rebase on public branch, like master branch. Never do operations like the following: git checkout master git rebase -i test git checkout main git pull origin main Find merge base hash git merge-base origin main # 106f9f893e1ac36e55711fc870f6a30a60a9febc git merge --squash test git commit git push origin master 3 way merge echo $USER branch name dev_${USER} # Create new branch git checkout -b dev main # Edit some files echo \"insert text here\" > scratches/a_file.txt git add <file> git commit -m \"Start a feature\" # Edit some files git add <file> git commit -m \"Finish a feature\" # compare branch to main git request-pull main ./ # Optional # push branch to remote git push -u origin <branch> # Develop the main branch git checkout main # Edit some files git add <file> git commit -m \"Make some super-stable changes to main\" # Merge in the new-feature branch git merge new-feature # To write a commit message and get out of VI, follow these steps: # press i (i for insert) # write your merge message # press esc (escape) # write :wq (write & quit) # then press enter # optional # uncomment to delete local branch # git branch -d dev Note that it\u2019s impossible for Git to perform a fast-forward merge, as there is no way to move main up to new-feature without backtracking.","title":"Branch"},{"location":"git/git_branching/#branching-workflow-for-continuous-delivery","text":"This simple workflow has two guiding principles: master is always production-like and deployable. rebase during feature development, explicit (non fast-forward) merge when done. The n commits from this branch will be rebased and added to base branch Pulling change-sets using rebase rewrites the history of the branch you\u2019re working on and keeps your changes on top.","title":"Branching Workflow for Continuous Delivery"},{"location":"git/git_branching/#merge-vs-rebase","text":"Merge branch to main Create a feature branch and make some file edits. gitGraph commit id: \"1\" commit id: \"2\" branch feature commit id: \"A\" commit id: \"B\" checkout main commit id: \"3\" commit id: \"4\" Next, merge the main branch into the feature branch. gitGraph commit id: \"1\" commit id: \"2\" branch feature commit id: \"A\" commit id: \"B\" checkout main commit id: \"3\" commit id: \"4\" merge feature tag: \"Merge Commit\" This creates a new \u201cmerge commit\u201d in the feature branch that ties together the histories of both branches, giving you a branch structure that looks like this: What is a rebase? Preserving the order of change-sets. Create a feature branch and make some file edits. gitGraph commit id: \"1\" commit id: \"2\" branch feature commit id: \"A\" commit id: \"B\" checkout main commit id: \"3\" commit id: \"4\" Rebase moves feature branch to the tip of the main branch. gitGraph commit id: \"1\" commit id: \"2\" branch feature commit id: \"A\" commit id: \"B\" checkout main commit id: \"3\" commit id: \"4\" merge feature Commit history maintains a linear record. gitGraph commit id: \"1\" commit id: \"2\" commit id: \"3\" commit id: \"4\" commit id: \"A\" type: HIGHLIGHT commit id: \"B\" type: HIGHLIGHT Start by pulling down the latest changes from master This is done easily with the common git commands: git checkout master git fetch origin git merge master Branch off to isolate the feature or bug-fix work in a branch Now create a branch for the feature or bug-fix: git checkout -b PRJ-123-awesome-feature The branch name structure I show here is just the one we use, but you can pick any convention you feel comfortable with. Now you can work on the feature Work on the feature as long as needed. Make sure your commits are meaningful and do not cluster separate changes together. To keep your feature branch fresh and up to date with the latest changes in master, use rebase Every once in a while during the development update the feature branch with the latest changes in master. You can do this with: git fetch origin git rebase origin/master In the (somewhat less common) case where other people are also working on the same shared remote feature branch, also rebase changes coming from it: git rebase origin/PRJ-123-awesome-feature At this point solve any conflicts that come out of the rebase. Resolving conflicts during the rebase allows you to have always clean merges at the end of the feature development. It also keeps your feature branch history clean and focused without spurious noise. When ready for feedback push your branch remotely and create a pull request When it\u2019s time to share your work and solicit feedback you can push your branch remotely with: git push -u origin PRJ-123-awesome-feature (if the branch is already set as 'upstream' and your remote is called 'origin', 'git push' is enough) Now you can create a pull request. After the initial push you can keep pushing updates to the remote branch multiple times throughout. This can happen in response to feedback, or because you\u2019re not done with the development of the feature. Perform a final rebase cleanup after the pull request has been approved After the review is done, it\u2019s good to perform a final cleanup and scrub of the feature branch commit history to remove spurious commits that are not providing relevant information. In some cases \u2013 if your team is experienced and they can handle it \u2013 you can rebase also during development, but I strongly advise against it.: git rebase -i origin/master (At this point if you have rewritten the history of a published branch and provided that no one else will commit to it or use it, you might need to push your changes using the \u2013force flag). When development is complete record an explicit merge When finished with the development of the feature branch and reviewers have reviewed your work, merge using the flag \u2013no-ff. This will preserve the context of the work and will make it easy to revert the whole feature if needed. Here are the commands: git checkout master git pull origin master git merge --no-ff PRJ-123-awesome-feature If you followed the advice above and you have used rebase to keep your feature branch up to date, the actual merge commit will not include any changes; this is cool! The merge commit becomes just a marker that stores the context about the feature branch. Good documentation comparing git rebase vs git merge","title":"Merge vs Rebase"},{"location":"git/git_branching/#fix-conflicts","text":"Take remote branch changes and replace with their changes if conflict arise. Here if you do git status you will get something like this your branch is ahead of 'origin/master' by 3 commits. git checkout test git pull git checkout master git pull git merge --no-ff --no-commit test Test merge before commit, avoid a fast-forward commit by --no-ff, If conflict is encountered, we can run git status to check details about the conflicts and try to solve git status Once we solve the conflicts, or if there is no conflict, we commit and push them git commit -m 'merge test branch' git push But this way will lose the changes history logged in test branch, and it would make master branch to be hard for other developers to understand the history of the project. So the best method is we have to use rebase instead of merge (suppose, when in this time, we have solved the branch conflicts). Following is one simple sample, for advanced operations, please refer to http://git-scm.com/book/en/v2/Git-Branching-Rebasing git checkout master git pull git checkout test git pull git rebase -i master git checkout master git merge test Yep, when you have uppers done, all the Test branch's commits will be moved onto the head of Master branch. The major benefit of rebasing is that you get a linear and much cleaner project history. The only thing you need to avoid is: never use rebase on public branch, like master branch. Never do operations like the following: git checkout master git rebase -i test git checkout main git pull origin main Find merge base hash git merge-base origin main # 106f9f893e1ac36e55711fc870f6a30a60a9febc git merge --squash test git commit git push origin master","title":"Fix Conflicts"},{"location":"git/git_branching/#3-way-merge","text":"echo $USER branch name dev_${USER} # Create new branch git checkout -b dev main # Edit some files echo \"insert text here\" > scratches/a_file.txt git add <file> git commit -m \"Start a feature\" # Edit some files git add <file> git commit -m \"Finish a feature\" # compare branch to main git request-pull main ./ # Optional # push branch to remote git push -u origin <branch> # Develop the main branch git checkout main # Edit some files git add <file> git commit -m \"Make some super-stable changes to main\" # Merge in the new-feature branch git merge new-feature # To write a commit message and get out of VI, follow these steps: # press i (i for insert) # write your merge message # press esc (escape) # write :wq (write & quit) # then press enter # optional # uncomment to delete local branch # git branch -d dev Note that it\u2019s impossible for Git to perform a fast-forward merge, as there is no way to move main up to new-feature without backtracking.","title":"3 way merge"},{"location":"git/git_checkout/","text":"Git Checkout git-checkout 1. Switch branches or 2. restore working tree files If you modify a file but haven't staged the change, then git checkout will reverse the modifications... a quick and easy way to cancel changes to a file. You remain in the same branch. git checkout (as you noted) switches branches. git checkout Selects the current branch git checkout <filename> reverses modifications to unstaged file git branch -d Deletes the obsolete branch git restore takes care of operations that change file","title":"Git Checkout"},{"location":"git/git_checkout/#git-checkout","text":"git-checkout 1. Switch branches or 2. restore working tree files If you modify a file but haven't staged the change, then git checkout will reverse the modifications... a quick and easy way to cancel changes to a file. You remain in the same branch. git checkout (as you noted) switches branches. git checkout Selects the current branch git checkout <filename> reverses modifications to unstaged file git branch -d Deletes the obsolete branch git restore takes care of operations that change file","title":"Git Checkout"},{"location":"git/git_command_list/","text":"Command comparison previous command new command git checkout git switch git checkout N/A (use git status) git checkout -b [ ] git switch -c [ ] git checkout -B [ ] git switch -C [ ] git checkout --orphan git switch --orphan git checkout --orphan N/A (use git switch then git switch --orphan ) git checkout [--detach] git switch --detach git checkout --detach [ ] git switch --detach [ ] git checkout [--] \u2026 git restore [--] \u2026 git checkout --pathspec-from-file= git restore --pathspec-from-file= git checkout [--] \u2026 git restore -s [--] \u2026 git checkout --pathspec-from-file= git restore -s --pathspec-from-file= git checkout -p [ ] [--] [ \u2026] git restore -p [-s ] [--] [ \u2026]","title":"Command comparison"},{"location":"git/git_command_list/#command-comparison","text":"previous command new command git checkout git switch git checkout N/A (use git status) git checkout -b [ ] git switch -c [ ] git checkout -B [ ] git switch -C [ ] git checkout --orphan git switch --orphan git checkout --orphan N/A (use git switch then git switch --orphan ) git checkout [--detach] git switch --detach git checkout --detach [ ] git switch --detach [ ] git checkout [--] \u2026 git restore [--] \u2026 git checkout --pathspec-from-file= git restore --pathspec-from-file= git checkout [--] \u2026 git restore -s [--] \u2026 git checkout --pathspec-from-file= git restore -s --pathspec-from-file= git checkout -p [ ] [--] [ \u2026] git restore -p [-s ] [--] [ \u2026]","title":"Command comparison"},{"location":"git/git_diff/","text":"Show changes before git Pull Preview changes before merging git diff <source_branch> <target_branch> git pull == git fetch && git merge The git fetch updates your so-called \"remote-tracking branches\" - typically these are ones that look like origin/master , github/experiment , etc. that you see with git branch -r . These are like a cache of the state of branches in the remote repository that are updated when you do git fetch (or a successful git push ). So, suppose you've got a remote called origin that refers to your GitHub repository, you would do: ??? \" git diff \" List remote git ls-remote origin -h refs/heads/master will list the current head on the remote -- you can compare it to a previous value or see if you have the SHA in your local repo. git status git status -uno will tell you whether the branch you are tracking is ahead, behind or has diverged. If it says nothing, the local and remote are the same. git reset git pull --rebase origin/main This resets my (local) copy of master (which I assume is screwed up) to the correct point, as represented by (remote) origin/master. git remote git remote update git remote -v get fetch origin ... and then do: git diff master origin/master git log -p HEAD.. origin/main to show each patch git diff HEAD\u2026 origin/main to show a single diff Discard Changes git reset --hard discard changes in staging and working area Sync Remote with Staging git rev-parse --abbrev-ref HEAD Check if on master. I want to check so that I have the master branch checked out. Since thats the branch i want to deploy from. This would return master if on master branch. I could do a git branch but that would return a list of branches with the currently selected marked with a *. So this saves me from string manipulations. Putting together a shell script that checks if you have master branch checked out could look like this: Check for changes on remote (origin) Git repo. Scenario I cloned from a repository and did some commits of my own to my local repository. In the meantime, my colleagues made commits to the remote repository. Now, I want to: Check whether there are any new commits from other people on the remote repository, i.e. origin? Say there were 3 new commits on the remote repository since my last pull, I would like to diff the remote repository's commits, i.e. HEAD~3 with HEAD~2, HEAD~2 with HEAD~1 and HEAD~1 with HEAD. After knowing what changed remotely, I want to get the latest commits from the others. My findings so far For step 2: I know the caret notation HEAD^, HEAD^^, etc. and the tilde notation HEAD~2, HEAD~3, etc. For step 3: That is, I guess, just a git pull. git fetch origin This will update your remote branch to the latest version. For a difference against remote you could use: git diff origin/master And after checking that if you want to accept that changes you could use: git merge origin/master git diff git diff diff --git a/.github/workflows/publish_mkdocs.yml b/.github/workflows/publish_mkdocs.yml ## A old version of file ## B new version of file index 4a377fd..79b6c71 100644 ## Meta data about two files compared @@ -3,18 +3,19 @@ name: \"Publish MKDocs\" ## -3,18 means from A version file, extracting 18 lines starting from line 3","title":"Diff"},{"location":"git/git_diff/#show-changes-before-git-pull","text":"Preview changes before merging git diff <source_branch> <target_branch> git pull == git fetch && git merge The git fetch updates your so-called \"remote-tracking branches\" - typically these are ones that look like origin/master , github/experiment , etc. that you see with git branch -r . These are like a cache of the state of branches in the remote repository that are updated when you do git fetch (or a successful git push ). So, suppose you've got a remote called origin that refers to your GitHub repository, you would do: ??? \" git diff \"","title":"Show changes before git Pull"},{"location":"git/git_diff/#list-remote","text":"git ls-remote origin -h refs/heads/master will list the current head on the remote -- you can compare it to a previous value or see if you have the SHA in your local repo.","title":"List remote"},{"location":"git/git_diff/#git-status","text":"git status -uno will tell you whether the branch you are tracking is ahead, behind or has diverged. If it says nothing, the local and remote are the same.","title":"git status"},{"location":"git/git_diff/#git-reset","text":"git pull --rebase origin/main This resets my (local) copy of master (which I assume is screwed up) to the correct point, as represented by (remote) origin/master.","title":"git reset"},{"location":"git/git_diff/#git-remote","text":"git remote update git remote -v get fetch origin ... and then do: git diff master origin/master git log -p HEAD.. origin/main to show each patch git diff HEAD\u2026 origin/main to show a single diff","title":"git remote"},{"location":"git/git_diff/#discard-changes","text":"git reset --hard discard changes in staging and working area","title":"Discard Changes"},{"location":"git/git_diff/#sync-remote-with-staging","text":"git rev-parse --abbrev-ref HEAD Check if on master. I want to check so that I have the master branch checked out. Since thats the branch i want to deploy from. This would return master if on master branch. I could do a git branch but that would return a list of branches with the currently selected marked with a *. So this saves me from string manipulations. Putting together a shell script that checks if you have master branch checked out could look like this: Check for changes on remote (origin) Git repo. Scenario I cloned from a repository and did some commits of my own to my local repository. In the meantime, my colleagues made commits to the remote repository. Now, I want to: Check whether there are any new commits from other people on the remote repository, i.e. origin? Say there were 3 new commits on the remote repository since my last pull, I would like to diff the remote repository's commits, i.e. HEAD~3 with HEAD~2, HEAD~2 with HEAD~1 and HEAD~1 with HEAD. After knowing what changed remotely, I want to get the latest commits from the others. My findings so far For step 2: I know the caret notation HEAD^, HEAD^^, etc. and the tilde notation HEAD~2, HEAD~3, etc. For step 3: That is, I guess, just a git pull. git fetch origin This will update your remote branch to the latest version. For a difference against remote you could use: git diff origin/master And after checking that if you want to accept that changes you could use: git merge origin/master","title":"Sync Remote with Staging"},{"location":"git/git_diff/#git-diff","text":"git diff diff --git a/.github/workflows/publish_mkdocs.yml b/.github/workflows/publish_mkdocs.yml ## A old version of file ## B new version of file index 4a377fd..79b6c71 100644 ## Meta data about two files compared @@ -3,18 +3,19 @@ name: \"Publish MKDocs\" ## -3,18 means from A version file, extracting 18 lines starting from line 3","title":"git diff"},{"location":"git/git_install_config/","text":"Git Install and configure git on local environment. Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency. GIT Refresher Background discussion and common github commands. No advanced topics, but tutorials should be easier after becoming familiar with common git commands. The official git documentation is excellent (most diagrams in this presentation are from the official documentation) This presentation is available from GitHub.com Why use version control? Easier experimentation - you can always go back to a working version Identification of project versions Exchange of a consistent state of your project Why use git? Widespread use Integrates with many applications Fast and very flexible Distributed State of files in git Files are initially untracked - they will be ignored by git They need to be staged to be handled by git After committing the current state is recorded Every following change can be staged and committed The git lifecycle uses the concept of a remote repository for pushing files from a local environment. Git terminology Repository: Snapshots of the managed files and their version history Commit: A named snapshot of all managed files in the repository Remote: A connected git repository Push: Transmit commits to a remote Pull: Get commits from a remote Merge: Integrate changes Stash: Local cache of changes Clone: create a copy of a remote Branch: a named tracking variant of files What does this have to do with GitHub or GitLab? GitHub or GitLab are remotes with a web interface They offer a lot of additional functionality but in the context of git they are not different from the repository you have on disk Git can be used with different workflows but often GitHub or GitLab are used as central hubs to share a project Install and Config git Install git for your OS Windows scoop install git MacOS brew install git linux apt install git-all AWS prefers to use linux-like docker images??? debian and ubuntu commands used in practice. Setup global configuration git config --global user.name \"elxsj\" git config --global user.email michael.madsen.ext@bayer.com list contents of my git config The ~/.gitconfig file will show git details. Also, the local configuration will be in your repository's .git/config file. To view system, global and local values: git config --list ## My current git config shows these details credential.helper=osxkeychain ## Personal access token user.name=elxsj user.email=93400240+elxsj@users.noreply.github.com init.defaultbranch=master Change the default email shown in the config file: git config --global user.email 'michael.madsen@bayer.com' git credentials SSH is the ideal method to clone and update repos from command line. To debug connectivity issues, a github Personal Access Token is a technically feasible alternative to SSH. If you want to store git credentials (this will store the password unencrypted !) :see_no_evil: Not recommended in production. Use only for testing. git config --global credential.helper store If you want to cache your credentials git config credential.helper 'cache --timeout=<timeout>' SSH keygen While ssh is the prefered method for users to clone and push to their repos, it is still possible to clone via https. ssh-keygen -t ed25519 -C \"michael.madsen.ext@bayer.com\" ## Output ## Generating public/private ed25519 key pair. ## Enter file in which to save the key (/Users/elxsj/.ssh/id_ed25519): Next, add the SSH key to your GitHub account Goto your GitHub Account -> Settings Then look for SSH and GPG keys under Account Settings -> SSH and GPG keys After that click on New SSH Key. Assign some meaningful name to your key Copy the content of the key and paste the key inside your GitHub account. cat /Users/elxsj/.ssh/id_ed25519.pub Proxy configuration US Proxy Settings Berkeley export http_proxy=http://10.86.255.70:8080 export https_proxy=https://10.86.255.70:8080 Configure the Git client to refer to the cacerts that have the imported certificate: git config --system http.sslCAPath /path/to/cacerts From the official git docs but untested with Bayer network. ## This puts password in plain text git config --global http.proxy https://PROXY_USERNAME:PROXY_PASSWORD@PROXY_SERVER:8080 Bayer HTTP/HTTPS proxies Misaligned Bayer proxies interfere with using git. It is technically feasible to temporarily bypass SSL but this deviates from best practices. Do not do this in production! git config --global http.sslVerify false Clone repo Clone repo and bypass SSL Do not do this in production! Useful to check if certificates require updating. git -c http.sslVerify=false clone <repository-name> Git branch default name. If you want to use master instead of main as default branch name. git config --global init.defaultBranch master Update local branch name from main to master . git branch -m main master git fetch origin git branch -u origin/master master git remote set-head origin -a Some aspects to consider setting up a repository Binary files can be handled by git, but large files make some operations in git slow For pure data repositories specialized software like DVC might be a better option Removing changes from the git history is very hard - think twice if you want big files in your repository! Jupyter and RMarkdown notebooks Jupyter and RMarkdown Notebooks embed code with output. They can get very big (file size) They may save many image files Changes on the cell (python) or hook (rmarkdown) outputs can hide changes in the code It can be very hard to merge concurrent changes Clean the output before committing github Stats Gather insights into the usage of different programming languages and their dependencies within our organization. Useful Links UI URL: https://devtools-np.monsanto.net/github-stats UI Repo: https://github.platforms.engineering/APALA4/github-stats-ui API Docs: https://devtools-np.monsanto.net/github-stats-api/v1/docs API Repo: https://github.platforms.engineering/APALA4/github-stats-api Vulnerabilities API: https://ossindex.sonatype.org/rest Github Hooks Many people are familair with github actions and its common to use github actions to perform code formatting or testing. Another way to do this is using git hooks . Authors fuad.abdallah@bayer.com michael.madsen@bayer.com References Git official docs Git visual cheat sheet Pro Git by Scott Chacon and Ben Straub is available to read online for free . A hard copy can be purchased online.","title":"Git"},{"location":"git/git_install_config/#git","text":"Install and configure git on local environment. Git is a free and open source distributed version control system designed to handle everything from small to very large projects with speed and efficiency.","title":"Git"},{"location":"git/git_install_config/#git-refresher","text":"Background discussion and common github commands. No advanced topics, but tutorials should be easier after becoming familiar with common git commands. The official git documentation is excellent (most diagrams in this presentation are from the official documentation) This presentation is available from GitHub.com","title":"GIT Refresher"},{"location":"git/git_install_config/#why-use-version-control","text":"Easier experimentation - you can always go back to a working version Identification of project versions Exchange of a consistent state of your project","title":"Why use version control?"},{"location":"git/git_install_config/#why-use-git","text":"Widespread use Integrates with many applications Fast and very flexible Distributed","title":"Why use git?"},{"location":"git/git_install_config/#state-of-files-in-git","text":"Files are initially untracked - they will be ignored by git They need to be staged to be handled by git After committing the current state is recorded Every following change can be staged and committed The git lifecycle uses the concept of a remote repository for pushing files from a local environment.","title":"State of files in git"},{"location":"git/git_install_config/#git-terminology","text":"Repository: Snapshots of the managed files and their version history Commit: A named snapshot of all managed files in the repository Remote: A connected git repository Push: Transmit commits to a remote Pull: Get commits from a remote Merge: Integrate changes Stash: Local cache of changes Clone: create a copy of a remote Branch: a named tracking variant of files","title":"Git terminology"},{"location":"git/git_install_config/#what-does-this-have-to-do-with-github-or-gitlab","text":"GitHub or GitLab are remotes with a web interface They offer a lot of additional functionality but in the context of git they are not different from the repository you have on disk Git can be used with different workflows but often GitHub or GitLab are used as central hubs to share a project","title":"What does this have to do with GitHub or GitLab?"},{"location":"git/git_install_config/#install-and-config-git","text":"","title":"Install and Config git"},{"location":"git/git_install_config/#install-git-for-your-os","text":"Windows scoop install git MacOS brew install git linux apt install git-all AWS prefers to use linux-like docker images??? debian and ubuntu commands used in practice. Setup global configuration git config --global user.name \"elxsj\" git config --global user.email michael.madsen.ext@bayer.com","title":"Install git for your OS"},{"location":"git/git_install_config/#list-contents-of-my-git-config","text":"The ~/.gitconfig file will show git details. Also, the local configuration will be in your repository's .git/config file. To view system, global and local values: git config --list ## My current git config shows these details credential.helper=osxkeychain ## Personal access token user.name=elxsj user.email=93400240+elxsj@users.noreply.github.com init.defaultbranch=master Change the default email shown in the config file: git config --global user.email 'michael.madsen@bayer.com'","title":"list contents of my git config"},{"location":"git/git_install_config/#git-credentials","text":"SSH is the ideal method to clone and update repos from command line. To debug connectivity issues, a github Personal Access Token is a technically feasible alternative to SSH. If you want to store git credentials (this will store the password unencrypted !) :see_no_evil: Not recommended in production. Use only for testing. git config --global credential.helper store If you want to cache your credentials git config credential.helper 'cache --timeout=<timeout>'","title":"git credentials"},{"location":"git/git_install_config/#ssh-keygen","text":"While ssh is the prefered method for users to clone and push to their repos, it is still possible to clone via https. ssh-keygen -t ed25519 -C \"michael.madsen.ext@bayer.com\" ## Output ## Generating public/private ed25519 key pair. ## Enter file in which to save the key (/Users/elxsj/.ssh/id_ed25519): Next, add the SSH key to your GitHub account Goto your GitHub Account -> Settings Then look for SSH and GPG keys under Account Settings -> SSH and GPG keys After that click on New SSH Key. Assign some meaningful name to your key Copy the content of the key and paste the key inside your GitHub account. cat /Users/elxsj/.ssh/id_ed25519.pub","title":"SSH keygen"},{"location":"git/git_install_config/#proxy-configuration","text":"","title":"Proxy configuration"},{"location":"git/git_install_config/#us-proxy-settings-berkeley","text":"export http_proxy=http://10.86.255.70:8080 export https_proxy=https://10.86.255.70:8080 Configure the Git client to refer to the cacerts that have the imported certificate: git config --system http.sslCAPath /path/to/cacerts From the official git docs but untested with Bayer network. ## This puts password in plain text git config --global http.proxy https://PROXY_USERNAME:PROXY_PASSWORD@PROXY_SERVER:8080","title":"US Proxy Settings Berkeley"},{"location":"git/git_install_config/#bayer-httphttps-proxies","text":"Misaligned Bayer proxies interfere with using git. It is technically feasible to temporarily bypass SSL but this deviates from best practices. Do not do this in production! git config --global http.sslVerify false","title":"Bayer HTTP/HTTPS proxies"},{"location":"git/git_install_config/#clone-repo","text":"Clone repo and bypass SSL Do not do this in production! Useful to check if certificates require updating. git -c http.sslVerify=false clone <repository-name>","title":"Clone repo"},{"location":"git/git_install_config/#git-branch-default-name","text":"If you want to use master instead of main as default branch name. git config --global init.defaultBranch master Update local branch name from main to master . git branch -m main master git fetch origin git branch -u origin/master master git remote set-head origin -a","title":"Git branch default name."},{"location":"git/git_install_config/#some-aspects-to-consider-setting-up-a-repository","text":"Binary files can be handled by git, but large files make some operations in git slow For pure data repositories specialized software like DVC might be a better option Removing changes from the git history is very hard - think twice if you want big files in your repository!","title":"Some aspects to consider setting up a repository"},{"location":"git/git_install_config/#jupyter-and-rmarkdown-notebooks","text":"Jupyter and RMarkdown Notebooks embed code with output. They can get very big (file size) They may save many image files Changes on the cell (python) or hook (rmarkdown) outputs can hide changes in the code It can be very hard to merge concurrent changes Clean the output before committing","title":"Jupyter and RMarkdown notebooks"},{"location":"git/git_install_config/#github-stats","text":"Gather insights into the usage of different programming languages and their dependencies within our organization. Useful Links UI URL: https://devtools-np.monsanto.net/github-stats UI Repo: https://github.platforms.engineering/APALA4/github-stats-ui API Docs: https://devtools-np.monsanto.net/github-stats-api/v1/docs API Repo: https://github.platforms.engineering/APALA4/github-stats-api Vulnerabilities API: https://ossindex.sonatype.org/rest","title":"github Stats"},{"location":"git/git_install_config/#github-hooks","text":"Many people are familair with github actions and its common to use github actions to perform code formatting or testing. Another way to do this is using git hooks .","title":"Github Hooks"},{"location":"git/git_install_config/#authors","text":"fuad.abdallah@bayer.com michael.madsen@bayer.com","title":"Authors"},{"location":"git/git_install_config/#references","text":"Git official docs Git visual cheat sheet Pro Git by Scott Chacon and Ben Straub is available to read online for free . A hard copy can be purchased online.","title":"References"},{"location":"git/git_log/","text":"Git logs in its simplest form, you can study repository history using.. git log This shows the commit message and SHA-1 checksum from each commit. git log commit cd1f2ec305a2c996ab6f3d17199ddc295c0dda52 (HEAD -> main, origin/main, origin/HEAD) Author: memadsen <michael.madsen@bayer.com> Date: Wed Oct 26 12:06:43 2022 -0400 cicd content You can add a lot of parameters to make the log look like what you want. To see only the commits of a certain author: git log --author=bob To see a very compressed log where each commit is one line: git log --pretty=oneline Or maybe you want to see an ASCII art tree of all the branches, decorated with the names of tags and branches: git log --graph --oneline --decorate --all See only which files have changed: git log --name-status These are just a few of the possible parameters you can use. For more, see git log --help","title":"Logs"},{"location":"git/git_log/#git-logs","text":"in its simplest form, you can study repository history using.. git log This shows the commit message and SHA-1 checksum from each commit. git log commit cd1f2ec305a2c996ab6f3d17199ddc295c0dda52 (HEAD -> main, origin/main, origin/HEAD) Author: memadsen <michael.madsen@bayer.com> Date: Wed Oct 26 12:06:43 2022 -0400 cicd content You can add a lot of parameters to make the log look like what you want. To see only the commits of a certain author: git log --author=bob To see a very compressed log where each commit is one line: git log --pretty=oneline Or maybe you want to see an ASCII art tree of all the branches, decorated with the names of tags and branches: git log --graph --oneline --decorate --all See only which files have changed: git log --name-status These are just a few of the possible parameters you can use. For more, see git log --help","title":"Git logs"},{"location":"git/git_merge/","text":"Git Merge merge fast forward The code below creates a new branch, adds two commits to it, then integrates it into the main line with a fast-forward merge. This is a common workflow for short-lived topic branches that are used more as an isolated development than an organizational tool for longer-running features. # Start a new feature git checkout -b new-feature main # or switch to existing feature git switch new-feature # Edit some files git add <file> git commit -m \"Start a feature\" # Edit some files git add <file> git commit -m \"Finish a feature\" # Merge in the new-feature branch git checkout main # Use only one merge # git merge new-feature git merge --no-ff <branch> ## record keeping git branch -d new-feature Update working branch from another branch I've been working on feature1 for a month now and a lot of changes have been pushed to develop . How can I update my current branch feature1 with the latest commits from develop ? git checkout develop git pull git checkout feature/myfeature 3 way merge The next example is very similar, but requires a 3-way merge because main progresses while the feature is in-progress. This is a common scenario for large features or when several developers are working on a project simultaneously. # Start a new feature git checkout -b new-feature main # Edit some files git add <file> git commit -m \"Start a feature\" # Edit some files git add <file> git commit -m \"Finish a feature\" # Develop the main branch git checkout main # Edit some files git add <file> git commit -m \"Make some super-stable changes to main\" # Merge in the new-feature branch git merge new-feature # To write a commit message and get out of VI, follow these steps: # press i (i for insert) # write your merge message # press esc (escape) # write :wq (write & quit) # then press enter # optional # uncomment to delete local branch # git branch -d dev Note that it\u2019s impossible for Git to perform a fast-forward merge, as there is no way to move main up to new-feature without backtracking. For most workflows, new-feature would be a much larger feature that took a long time to develop, which would be why new commits would appear on main in the meantime. If your feature branch was actually as small as the one in the above example, you would probably be better off rebasing it onto main and doing a fast-forward merge. This prevents superfluous merge commits from cluttering up the project history. Resolving conflict If the two branches you're trying to merge both changed the same part of the same file, Git won't be able to figure out which version to use. When such a situation occurs, it stops right before the merge commit so that you can resolve the conflicts manually. The great part of Git's merging process is that it uses the familiar edit/stage/commit workflow to resolve merge conflicts. When you encounter a merge conflict, running the git status command shows you which files need to be resolved. For example, if both branches modified the same section of hello.py, you would see something like the following: On branch main Unmerged paths: (use \"git add/rm ...\" as appropriate to mark resolution) both modified: hello.py How conflicts are presented When Git encounters a conflict during a merge, It will edit the content of the affected files with visual indicators that mark both sides of the conflicted content. These visual markers are: <<<<<<<, =======, and >>>>>>>. Its helpful to search a project for these indicators during a merge to find where conflicts need to be resolved. here is some content not affected by the conflict <<<<<<< main this is conflicted text from main ======= this is conflicted text from feature branch >>>>>>> feature branch; Generally the content before the ======= marker is the receiving branch and the part after is the merging branch. Once you've identified conflicting sections, you can go in and fix up the merge to your liking. When you're ready to finish the merge, all you have to do is run git add on the conflicted file(s) to tell Git they're resolved. Then, you run a normal git commit to generate the merge commit. It\u2019s the exact same process as committing an ordinary snapshot, which means it\u2019s easy for normal developers to manage their own merges. Note that merge conflicts will only occur in the event of a 3-way merge. It\u2019s not possible to have conflicting changes in a fast-forward merge. Example 3 way Commit git init echo one>1.txt git add . git commit -m 'c1' echo two>2.txt git add . git commit -m 'c2' echo three>3.txt git add . git commit -m 'C3' git branch feature git switch feature echo four>4.txt git add . git commit -m 'c4' echo five>5.txt git add . git commit -m 'c5' git switch master echo six>6.txt git add . git commit -m 'c6' git merge feature git log --oneline --all --graph","title":"Git Merge"},{"location":"git/git_merge/#git-merge","text":"","title":"Git Merge"},{"location":"git/git_merge/#merge-fast-forward","text":"The code below creates a new branch, adds two commits to it, then integrates it into the main line with a fast-forward merge. This is a common workflow for short-lived topic branches that are used more as an isolated development than an organizational tool for longer-running features. # Start a new feature git checkout -b new-feature main # or switch to existing feature git switch new-feature # Edit some files git add <file> git commit -m \"Start a feature\" # Edit some files git add <file> git commit -m \"Finish a feature\" # Merge in the new-feature branch git checkout main # Use only one merge # git merge new-feature git merge --no-ff <branch> ## record keeping git branch -d new-feature","title":"merge fast forward"},{"location":"git/git_merge/#update-working-branch-from-another-branch","text":"I've been working on feature1 for a month now and a lot of changes have been pushed to develop . How can I update my current branch feature1 with the latest commits from develop ? git checkout develop git pull git checkout feature/myfeature","title":"Update working branch from another branch"},{"location":"git/git_merge/#3-way-merge","text":"The next example is very similar, but requires a 3-way merge because main progresses while the feature is in-progress. This is a common scenario for large features or when several developers are working on a project simultaneously. # Start a new feature git checkout -b new-feature main # Edit some files git add <file> git commit -m \"Start a feature\" # Edit some files git add <file> git commit -m \"Finish a feature\" # Develop the main branch git checkout main # Edit some files git add <file> git commit -m \"Make some super-stable changes to main\" # Merge in the new-feature branch git merge new-feature # To write a commit message and get out of VI, follow these steps: # press i (i for insert) # write your merge message # press esc (escape) # write :wq (write & quit) # then press enter # optional # uncomment to delete local branch # git branch -d dev Note that it\u2019s impossible for Git to perform a fast-forward merge, as there is no way to move main up to new-feature without backtracking. For most workflows, new-feature would be a much larger feature that took a long time to develop, which would be why new commits would appear on main in the meantime. If your feature branch was actually as small as the one in the above example, you would probably be better off rebasing it onto main and doing a fast-forward merge. This prevents superfluous merge commits from cluttering up the project history.","title":"3 way merge"},{"location":"git/git_merge/#resolving-conflict","text":"If the two branches you're trying to merge both changed the same part of the same file, Git won't be able to figure out which version to use. When such a situation occurs, it stops right before the merge commit so that you can resolve the conflicts manually. The great part of Git's merging process is that it uses the familiar edit/stage/commit workflow to resolve merge conflicts. When you encounter a merge conflict, running the git status command shows you which files need to be resolved. For example, if both branches modified the same section of hello.py, you would see something like the following: On branch main Unmerged paths: (use \"git add/rm ...\" as appropriate to mark resolution) both modified: hello.py How conflicts are presented When Git encounters a conflict during a merge, It will edit the content of the affected files with visual indicators that mark both sides of the conflicted content. These visual markers are: <<<<<<<, =======, and >>>>>>>. Its helpful to search a project for these indicators during a merge to find where conflicts need to be resolved. here is some content not affected by the conflict <<<<<<< main this is conflicted text from main ======= this is conflicted text from feature branch >>>>>>> feature branch; Generally the content before the ======= marker is the receiving branch and the part after is the merging branch. Once you've identified conflicting sections, you can go in and fix up the merge to your liking. When you're ready to finish the merge, all you have to do is run git add on the conflicted file(s) to tell Git they're resolved. Then, you run a normal git commit to generate the merge commit. It\u2019s the exact same process as committing an ordinary snapshot, which means it\u2019s easy for normal developers to manage their own merges. Note that merge conflicts will only occur in the event of a 3-way merge. It\u2019s not possible to have conflicting changes in a fast-forward merge.","title":"Resolving conflict"},{"location":"git/git_merge/#example-3-way-commit","text":"git init echo one>1.txt git add . git commit -m 'c1' echo two>2.txt git add . git commit -m 'c2' echo three>3.txt git add . git commit -m 'C3' git branch feature git switch feature echo four>4.txt git add . git commit -m 'c4' echo five>5.txt git add . git commit -m 'c5' git switch master echo six>6.txt git add . git commit -m 'c6' git merge feature git log --oneline --all --graph","title":"Example 3 way Commit"},{"location":"git/git_pull_stash/","text":"Git stash To overwrite your local files do: git fetch --all git reset --hard <remote>/<branch_name> git fetch --all git reset --hard origin/master Git Pull and save local changes Maintain current local commits It's worth noting that it is possible to maintain current local commits by creating a branch from master before resetting: git checkout master git branch new-branch-to-save-current-commits git fetch --all git reset --hard origin/master After this, all of the old commits will be kept in new-branch-to-save-current-commits. Uncommitted changes Uncommitted changes, however (even staged), will be lost. Make sure to stash and commit anything you need. For that you can run the following: git stash And then to reapply these uncommitted changes: git stash pop","title":"Git stash"},{"location":"git/git_pull_stash/#git-stash","text":"To overwrite your local files do: git fetch --all git reset --hard <remote>/<branch_name> git fetch --all git reset --hard origin/master","title":"Git stash"},{"location":"git/git_pull_stash/#git-pull-and-save-local-changes","text":"Maintain current local commits It's worth noting that it is possible to maintain current local commits by creating a branch from master before resetting: git checkout master git branch new-branch-to-save-current-commits git fetch --all git reset --hard origin/master After this, all of the old commits will be kept in new-branch-to-save-current-commits. Uncommitted changes Uncommitted changes, however (even staged), will be lost. Make sure to stash and commit anything you need. For that you can run the following: git stash And then to reapply these uncommitted changes: git stash pop","title":"Git Pull and save local changes"},{"location":"git/git_rebase/","text":"git rebase I want to base my changes on what everyone has already done. The primary reason for rebasing is to maintain a linear project history. For example, consider a situation where the main branch has progressed since you started working on a feature branch. You want to get the latest updates to the main branch in your feature branch, but you want to keep your branch's history clean so it appears as if you've been working off the latest main branch. This gives the later benefit of a clean merge of your feature branch back into the main branch. Why do we want to maintain a \"clean history\"? The benefits of having a clean history become tangible when performing Git operations to investigate the introduction of a regression. A more real-world scenario would be: A bug is identified in the main branch. A feature that was working successfully is now broken. A developer examines the history of the main branch using git log because of the \"clean history\" the developer is quickly able to reason about the history of the project. The developer can not identify when the bug was introduced using git log so the developer executes a git bisect. Because the git history is clean, git bisect has a refined set of commits to compare when looking for the regression. The developer quickly finds the commit that introduced the bug and is able to act accordingly. Keep feature branch up to date with master and merge to master when done Create a feature branch based off of main and switch to it. git checkout -b feature_branch main git pull --rebase Edit files Commit git commit -a -m \"Adds new feature\" git checkout NewFeatureBranch git merge --no-ff master ## --no-ff keep git history clear git rebase <base>","title":"git rebase"},{"location":"git/git_rebase/#git-rebase","text":"I want to base my changes on what everyone has already done. The primary reason for rebasing is to maintain a linear project history. For example, consider a situation where the main branch has progressed since you started working on a feature branch. You want to get the latest updates to the main branch in your feature branch, but you want to keep your branch's history clean so it appears as if you've been working off the latest main branch. This gives the later benefit of a clean merge of your feature branch back into the main branch. Why do we want to maintain a \"clean history\"? The benefits of having a clean history become tangible when performing Git operations to investigate the introduction of a regression. A more real-world scenario would be: A bug is identified in the main branch. A feature that was working successfully is now broken. A developer examines the history of the main branch using git log because of the \"clean history\" the developer is quickly able to reason about the history of the project. The developer can not identify when the bug was introduced using git log so the developer executes a git bisect. Because the git history is clean, git bisect has a refined set of commits to compare when looking for the regression. The developer quickly finds the commit that introduced the bug and is able to act accordingly.","title":"git rebase"},{"location":"git/git_rebase/#keep-feature-branch-up-to-date-with-master-and-merge-to-master-when-done","text":"Create a feature branch based off of main and switch to it. git checkout -b feature_branch main git pull --rebase Edit files Commit git commit -a -m \"Adds new feature\" git checkout NewFeatureBranch git merge --no-ff master ## --no-ff keep git history clear git rebase <base>","title":"Keep feature branch up to date with master and merge to master when done"},{"location":"git/git_ssh/","text":"Git SSH key Generate a new SSH key for git to securely use repos. This eliminates the need to retype a password for each git action. Generate SSH key Before generating new SSH keys, check for existing SSH keys. To list existing ssh keys, go to the terminal, run command ls -al ~/.ssh , files with extension .pub are your SSH keys. You need to have ssh keys for each account. If you are planning to use two accounts personal and work, there should be two SSH keys, if not, you have to generate them. If you see No such file or directory after running ls -al ~/.ssh command, go ahead and create ~/.ssh directory with command mkdir -p ~/.ssh . Next, generate a new ssh key using ssh-keygen :exclamation: Change the file path or you will write over your existing ssh key $ ssh-keygen -t ed25519 -C michael.madsen@bayer.com Generating public/private ed25519 key pair. Enter file in which to save the key (/Users/elxsj/.ssh/id_ed25519): /Users/elxsj/.ssh/gh_cli Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /Users/elxsj/.ssh/gh_cli. Your public key has been saved in /Users/elxsj/.ssh/gh_cli.pub. The key fingerprint is: SHA256:+F1oyBGO3BNJ9Zo/JqPvMLUymwENS4SAPVwVtQZyYUM michael.madsen@bayer.com Save to default file location Do not use passphrase Add SSH key to SSH Agent Create config file in .ssh directory. For macOS I used touch ~/.ssh/config Host * AddKeysToAgent yes IdentityFile ~/.ssh/id_ed25519 Add SSH key to GHC UI Copy SSH public key to clipboard cat ~/.ssh/id_ed25519.pub Open GitHub in web browser. Settings >> SSH keys >> Add SSH key Next configure SSO to authorize bayer-int to use ssh key. Test SSH connection $ ssh -T git@github.com # ssh to GitHub to test Output should look like this: The authenticity of host 'github.com (140.82.114.4)' can't be established. ECDSA key fingerprint is SHA256:p2QAMXNICxxxxxxxxx #### ------- Enter yes here: ------------ Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added 'github.com,140.82.114.4' (ECDSA) to the list of known hosts. Hi elxsj! You've successfully authenticated, but GitHub does not provide shell access.","title":"SSH key"},{"location":"git/git_ssh/#git-ssh-key","text":"Generate a new SSH key for git to securely use repos. This eliminates the need to retype a password for each git action.","title":"Git SSH key"},{"location":"git/git_ssh/#generate-ssh-key","text":"Before generating new SSH keys, check for existing SSH keys. To list existing ssh keys, go to the terminal, run command ls -al ~/.ssh , files with extension .pub are your SSH keys. You need to have ssh keys for each account. If you are planning to use two accounts personal and work, there should be two SSH keys, if not, you have to generate them. If you see No such file or directory after running ls -al ~/.ssh command, go ahead and create ~/.ssh directory with command mkdir -p ~/.ssh . Next, generate a new ssh key using ssh-keygen :exclamation: Change the file path or you will write over your existing ssh key $ ssh-keygen -t ed25519 -C michael.madsen@bayer.com Generating public/private ed25519 key pair. Enter file in which to save the key (/Users/elxsj/.ssh/id_ed25519): /Users/elxsj/.ssh/gh_cli Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /Users/elxsj/.ssh/gh_cli. Your public key has been saved in /Users/elxsj/.ssh/gh_cli.pub. The key fingerprint is: SHA256:+F1oyBGO3BNJ9Zo/JqPvMLUymwENS4SAPVwVtQZyYUM michael.madsen@bayer.com Save to default file location Do not use passphrase","title":"Generate SSH key"},{"location":"git/git_ssh/#add-ssh-key-to-ssh-agent","text":"Create config file in .ssh directory. For macOS I used touch ~/.ssh/config Host * AddKeysToAgent yes IdentityFile ~/.ssh/id_ed25519","title":"Add SSH key to SSH Agent"},{"location":"git/git_ssh/#add-ssh-key-to-ghc-ui","text":"Copy SSH public key to clipboard cat ~/.ssh/id_ed25519.pub Open GitHub in web browser. Settings >> SSH keys >> Add SSH key Next configure SSO to authorize bayer-int to use ssh key.","title":"Add SSH key to GHC UI"},{"location":"git/git_ssh/#test-ssh-connection","text":"$ ssh -T git@github.com # ssh to GitHub to test Output should look like this: The authenticity of host 'github.com (140.82.114.4)' can't be established. ECDSA key fingerprint is SHA256:p2QAMXNICxxxxxxxxx #### ------- Enter yes here: ------------ Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added 'github.com,140.82.114.4' (ECDSA) to the list of known hosts. Hi elxsj! You've successfully authenticated, but GitHub does not provide shell access.","title":"Test SSH connection"},{"location":"git/git_workflow/","text":"Git Basic Workflow Using typical git workflow. This doc shows git commands I use every day. How does git work internally? Git works like a file system with version history Snapshots are identified by SHA-1 hash sums Versions can also have a name (Tag) add , commit , push and pull are the most frequent commands used. git HEAD HEAD is a special ref that points to the commit you are currently working on - the currently checked out commit in your git working directory. HEAD usually points to the tip/head of the currently active branch, which is represented in the .git/HEAD file as follows: $ cat .git/HEAD ref: refs/heads/main I can switch branches and git HEAD will be updated. $ git switch dev $ cat .git/HEAD ref: refs/heads/dev Set up a local repository In local environment (laptop or cloud directory) cd YOUR_PROJECT_DIRECTORY git init git add --all git commit -m \"initial commit\" If you want to exclude files in you project directory use a .gitignore file file names will be used recursively (also in all subdirectories), start with / to select only files in the project root directory Wildcards can be used to track all files by a pattern. For example to get all python and R files use *.py and *.R select complete directories YOUR_EXCLUDE_FOLDER/ Clone from a remote repository git clone CLONEURL Create new repository ##### Option 1 echo \"# Can-I-Shop-2\" >> README.md git init ## Required for new directory git add . git commit -m \"first commit\" git remote add origin https://github.com/username/projectname.git git push -u origin master ##### Option 2 git remote add origin https://github.com/bayer-int/elxsj_test.git git branch -M master git push -u origin master Reverse git add git reset <filename> Add all files in current path git add . Add all files in project git add -A Amend commit without changing message git commit --amend --no-edit Pushing an amended commit. After pushing to remote, amend commit using th e -f option git push -f origin <my_branch> Putting some changes aside: stash You can't pull changes if you have uncommitted work in your project How can you get important changes if you are \"in the middle of something\"? git stash git pull git stash apply You can have multiple stashes which you can list with git stash list Remove all stash list git stash clear Using .gitignore Reset .gitignore part 1 Abbreviated steps to reset .gitignore to track new changes. First, make changes in .gitignore file. Reset cache git rm -r --cached . Add and push changes to github git add . git commit -m \"Commit message\" Reset .gitignore part 2 After creating a .gitignore file in your repository and setting patterns to match files which you do not want Git to track, Git starts tracking repository files and respecting the patterns set in the .gitignore file after you run the git add command (For example git add . ). The problem is that if we later make some changes to the .gitignore file and then just run the git add command again, the changes made in the .gitignore file will not take effect. Reset .gitignore part 3 For example if you later set in the .gitignore file that you want Git to start tracking a file which you previously set to be ignored, the file will still be untracked if you just run the git add . command. This is because, the git cache needs to be cleared. I usually just do this with the git rm -r --cached . then after I run the git add . command to apply the .gitignore changes. Fetch Fetch all of the remote branches and tags from the existing repository to our local index: git fetch origin branches local But even if all branches and tags have been fetched and exist in a local index, we still won\u2019t have a copy of them that is physically local. And a local copy is required to migrate the repository. We can check for any missing branches that we need to create a local copy of. Let\u2019s list all existing branches (local and remote) to see whether we are missing any copies locally: git branch -a We can easily tell from this output whether we have local copies of all remote branches. The remote ones are prefixed with the remotes/origin/ path, and the local ones are not. So, only our master branch is local, whereas remotes/origin/develop and remotes/origin/release/0.1 are not. That\u2019s OK \u2014 let\u2019s just create local copies: git checkout -b develop origin/develop git checkout -b release/0.1 origin/release/0.1 After creating local copies of everything, we can verify once again whether all branches with the remotes/origin/ prefix have corresponding local copies (shown without the prefix): git branch -a develop master * release/0.1 remotes/origin/develop remotes/origin/master remotes/origin/release/0.1 Now we know for sure that all branches in our repository are stored locally, and we are ready to move the repository to a new host. Switch to another branch git switch <branch name> Create new branch This is a two step process. git checkout -b <branch-name> Create new branch locally git push -u origin <branch-name> Push new branch local to remote After git push to remote, the repo on GitHub.com will show the new branch. Verify the new branch and proceed to add new code using git add > git commit and git push . Merge dev branch into master ## on branch \"dev\" git commit -m \" my message \" git push git checkout master # now on branch master git branch -a git pull ## ensure local master is current with remote git merge dev git push git checkout dev # switch to dev branch RM branches delete local branch git branch -d <branch> delete remote branch git push <remote_name> -d <remote_branch_name> ### Usually looks like this git push origin -d dev Change remote origin Migrate a Git repository OR to merge existing ones. This is useful if the remote needs to be mapped to local files. Change the Git origin remote to a new URL. ## Update the URL of origin remote using SSH git remote set-url origin git@github.com:username/repo.git ## My example git remote set-url origin git@github.com:bayer-int/smol-cls-mlops-scaffold.git # Test URL remote git remote show origin Pull Request The following code creates a new branch, makes an arbitrary change, and pushes it to new_branch: Open the git repo ( from github.com ) and click on the Fork button in the top-right corner. This creates a new copy of the repo we want to update, under your GitHub user account with a URL like: https://github.com/<UserName>/reponame clone the repo git clone <repo_2> Create a new branch git checkout -b new_branch Create a new remote for the upstream repo (github server) git remote add upstream <repo_1> Then git add, git commit and git push as usual. The entire CLI workflow follows this pattern: git clone https://github.platforms.engineering/ELXSJ/MWAA.git git checkout -b dev git remote add upstream https://github.platforms.engineering/science-at-scale/MWAA.git git add . git commit -m \"add ingress to ALB\" git branch -a git push -u origin dev Once you push the changes to your repo, the Compare & pull request button will appear in GitHub. Update local repo to latest remote tag Clone repo. This step was assumed to be done previously but placed here to make the example consistent. git clone https://github.com/mlrun/demos.git :exclamation: Use latest branch and tag from github repo Update current project ## To check out the latest Git tag, first, update ## the repository by fetching the remote tags available. git fetch --tags ## Then, retrieve the latest tag available by using the \u201cgit describe\u201d command. latestTag=$(git describe --tags `git rev-list --tags --max-count=1`) echo $latestTag ## Finally, use the \u201cgit checkout\u201d command to checkout the latest git tag git checkout $latestTag -b latest ## Execute the \u201cgit log\u201d command to make sure that we are actually ## developing starting from the new tag. git log --oneline --graph * 8c98f7c (HEAD -> latest, tag: v1.1.x-rc5, origin/1.1.x) Merge pull request #295 from mlrun/1.1.x-dev |\\ | * ba1c1cb (origin/1.1.x-dev) Merge pull request #294 from aviaIguazio/1.1.x-dev | |\\ | | * e885976 add timeout for pipeline deploy !!! Find file I have edited. git log --pretty --author=$( git config user.email ) --name-only | sort | uniq github Stats Gather insights into the usage of different programming languages and their dependencies within our organization. Useful Links UI URL: https://devtools-np.monsanto.net/github-stats UI Repo: https://github.platforms.engineering/APALA4/github-stats-ui API Docs: https://devtools-np.monsanto.net/github-stats-api/v1/docs API Repo: https://github.platforms.engineering/APALA4/github-stats-api Vulnerabilities API: https://ossindex.sonatype.org/rest Github Hooks Many people are familair with github actions and its common to use github actions to perform code formatting or testing. Another way to do this is using git hooks . Authors fuad.abdallah@bayer.com michael.madsen@bayer.com References Some advanced topics not covered but important to know. Submodules github api You can find more information in the Pro Git book Git official docs Git visual cheat sheet Pro Git by Scott Chacon and Ben Straub is available to read online for free . A hard copy can be purchased online.","title":"Git Workflow"},{"location":"git/git_workflow/#git-basic-workflow","text":"Using typical git workflow. This doc shows git commands I use every day.","title":"Git Basic Workflow"},{"location":"git/git_workflow/#how-does-git-work-internally","text":"Git works like a file system with version history Snapshots are identified by SHA-1 hash sums Versions can also have a name (Tag) add , commit , push and pull are the most frequent commands used.","title":"How does git work internally?"},{"location":"git/git_workflow/#git-head","text":"HEAD is a special ref that points to the commit you are currently working on - the currently checked out commit in your git working directory. HEAD usually points to the tip/head of the currently active branch, which is represented in the .git/HEAD file as follows: $ cat .git/HEAD ref: refs/heads/main I can switch branches and git HEAD will be updated. $ git switch dev $ cat .git/HEAD ref: refs/heads/dev","title":"git HEAD"},{"location":"git/git_workflow/#set-up-a-local-repository","text":"In local environment (laptop or cloud directory) cd YOUR_PROJECT_DIRECTORY git init git add --all git commit -m \"initial commit\" If you want to exclude files in you project directory use a .gitignore file file names will be used recursively (also in all subdirectories), start with / to select only files in the project root directory Wildcards can be used to track all files by a pattern. For example to get all python and R files use *.py and *.R select complete directories YOUR_EXCLUDE_FOLDER/","title":"Set up a local repository"},{"location":"git/git_workflow/#clone-from-a-remote-repository","text":"git clone CLONEURL","title":"Clone from a remote repository"},{"location":"git/git_workflow/#create-new-repository","text":"##### Option 1 echo \"# Can-I-Shop-2\" >> README.md git init ## Required for new directory git add . git commit -m \"first commit\" git remote add origin https://github.com/username/projectname.git git push -u origin master ##### Option 2 git remote add origin https://github.com/bayer-int/elxsj_test.git git branch -M master git push -u origin master Reverse git add git reset <filename> Add all files in current path git add . Add all files in project git add -A Amend commit without changing message git commit --amend --no-edit Pushing an amended commit. After pushing to remote, amend commit using th e -f option git push -f origin <my_branch>","title":"Create new repository"},{"location":"git/git_workflow/#putting-some-changes-aside-stash","text":"You can't pull changes if you have uncommitted work in your project How can you get important changes if you are \"in the middle of something\"? git stash git pull git stash apply You can have multiple stashes which you can list with git stash list Remove all stash list git stash clear","title":"Putting some changes aside: stash"},{"location":"git/git_workflow/#using-gitignore","text":"","title":"Using .gitignore"},{"location":"git/git_workflow/#reset-gitignore-part-1","text":"Abbreviated steps to reset .gitignore to track new changes. First, make changes in .gitignore file. Reset cache git rm -r --cached . Add and push changes to github git add . git commit -m \"Commit message\"","title":"Reset .gitignore part 1"},{"location":"git/git_workflow/#reset-gitignore-part-2","text":"After creating a .gitignore file in your repository and setting patterns to match files which you do not want Git to track, Git starts tracking repository files and respecting the patterns set in the .gitignore file after you run the git add command (For example git add . ). The problem is that if we later make some changes to the .gitignore file and then just run the git add command again, the changes made in the .gitignore file will not take effect.","title":"Reset .gitignore part 2"},{"location":"git/git_workflow/#reset-gitignore-part-3","text":"For example if you later set in the .gitignore file that you want Git to start tracking a file which you previously set to be ignored, the file will still be untracked if you just run the git add . command. This is because, the git cache needs to be cleared. I usually just do this with the git rm -r --cached . then after I run the git add . command to apply the .gitignore changes.","title":"Reset .gitignore part 3"},{"location":"git/git_workflow/#fetch","text":"Fetch all of the remote branches and tags from the existing repository to our local index: git fetch origin","title":"Fetch"},{"location":"git/git_workflow/#branches-local","text":"But even if all branches and tags have been fetched and exist in a local index, we still won\u2019t have a copy of them that is physically local. And a local copy is required to migrate the repository. We can check for any missing branches that we need to create a local copy of. Let\u2019s list all existing branches (local and remote) to see whether we are missing any copies locally: git branch -a We can easily tell from this output whether we have local copies of all remote branches. The remote ones are prefixed with the remotes/origin/ path, and the local ones are not. So, only our master branch is local, whereas remotes/origin/develop and remotes/origin/release/0.1 are not. That\u2019s OK \u2014 let\u2019s just create local copies: git checkout -b develop origin/develop git checkout -b release/0.1 origin/release/0.1 After creating local copies of everything, we can verify once again whether all branches with the remotes/origin/ prefix have corresponding local copies (shown without the prefix): git branch -a develop master * release/0.1 remotes/origin/develop remotes/origin/master remotes/origin/release/0.1 Now we know for sure that all branches in our repository are stored locally, and we are ready to move the repository to a new host.","title":"branches local"},{"location":"git/git_workflow/#switch-to-another-branch","text":"git switch <branch name>","title":"Switch to another branch"},{"location":"git/git_workflow/#create-new-branch","text":"This is a two step process. git checkout -b <branch-name> Create new branch locally git push -u origin <branch-name> Push new branch local to remote After git push to remote, the repo on GitHub.com will show the new branch. Verify the new branch and proceed to add new code using git add > git commit and git push .","title":"Create new branch"},{"location":"git/git_workflow/#merge-dev-branch-into-master","text":"## on branch \"dev\" git commit -m \" my message \" git push git checkout master # now on branch master git branch -a git pull ## ensure local master is current with remote git merge dev git push git checkout dev # switch to dev branch","title":"Merge dev branch into master"},{"location":"git/git_workflow/#rm-branches","text":"delete local branch git branch -d <branch> delete remote branch git push <remote_name> -d <remote_branch_name> ### Usually looks like this git push origin -d dev","title":"RM branches"},{"location":"git/git_workflow/#change-remote-origin","text":"Migrate a Git repository OR to merge existing ones. This is useful if the remote needs to be mapped to local files. Change the Git origin remote to a new URL. ## Update the URL of origin remote using SSH git remote set-url origin git@github.com:username/repo.git ## My example git remote set-url origin git@github.com:bayer-int/smol-cls-mlops-scaffold.git # Test URL remote git remote show origin","title":"Change remote origin"},{"location":"git/git_workflow/#pull-request","text":"The following code creates a new branch, makes an arbitrary change, and pushes it to new_branch: Open the git repo ( from github.com ) and click on the Fork button in the top-right corner. This creates a new copy of the repo we want to update, under your GitHub user account with a URL like: https://github.com/<UserName>/reponame clone the repo git clone <repo_2> Create a new branch git checkout -b new_branch Create a new remote for the upstream repo (github server) git remote add upstream <repo_1> Then git add, git commit and git push as usual. The entire CLI workflow follows this pattern: git clone https://github.platforms.engineering/ELXSJ/MWAA.git git checkout -b dev git remote add upstream https://github.platforms.engineering/science-at-scale/MWAA.git git add . git commit -m \"add ingress to ALB\" git branch -a git push -u origin dev Once you push the changes to your repo, the Compare & pull request button will appear in GitHub.","title":"Pull Request"},{"location":"git/git_workflow/#update-local-repo-to-latest-remote-tag","text":"Clone repo. This step was assumed to be done previously but placed here to make the example consistent. git clone https://github.com/mlrun/demos.git :exclamation: Use latest branch and tag from github repo Update current project ## To check out the latest Git tag, first, update ## the repository by fetching the remote tags available. git fetch --tags ## Then, retrieve the latest tag available by using the \u201cgit describe\u201d command. latestTag=$(git describe --tags `git rev-list --tags --max-count=1`) echo $latestTag ## Finally, use the \u201cgit checkout\u201d command to checkout the latest git tag git checkout $latestTag -b latest ## Execute the \u201cgit log\u201d command to make sure that we are actually ## developing starting from the new tag. git log --oneline --graph * 8c98f7c (HEAD -> latest, tag: v1.1.x-rc5, origin/1.1.x) Merge pull request #295 from mlrun/1.1.x-dev |\\ | * ba1c1cb (origin/1.1.x-dev) Merge pull request #294 from aviaIguazio/1.1.x-dev | |\\ | | * e885976 add timeout for pipeline deploy !!! Find file I have edited. git log --pretty --author=$( git config user.email ) --name-only | sort | uniq","title":"Update local repo to latest remote tag"},{"location":"git/git_workflow/#github-stats","text":"Gather insights into the usage of different programming languages and their dependencies within our organization. Useful Links UI URL: https://devtools-np.monsanto.net/github-stats UI Repo: https://github.platforms.engineering/APALA4/github-stats-ui API Docs: https://devtools-np.monsanto.net/github-stats-api/v1/docs API Repo: https://github.platforms.engineering/APALA4/github-stats-api Vulnerabilities API: https://ossindex.sonatype.org/rest","title":"github Stats"},{"location":"git/git_workflow/#github-hooks","text":"Many people are familair with github actions and its common to use github actions to perform code formatting or testing. Another way to do this is using git hooks .","title":"Github Hooks"},{"location":"git/git_workflow/#authors","text":"fuad.abdallah@bayer.com michael.madsen@bayer.com","title":"Authors"},{"location":"git/git_workflow/#references","text":"Some advanced topics not covered but important to know. Submodules github api You can find more information in the Pro Git book Git official docs Git visual cheat sheet Pro Git by Scott Chacon and Ben Straub is available to read online for free . A hard copy can be purchased online.","title":"References"},{"location":"hosting-and-deployment/enable_github_pages/","text":"Enable Github Pages Github pages requires permissions to be enabled but the process is pretty easy. Create a public repository Navigate to Settings > Pages Configure the branch and build directory. \u2757 github.io requires using the owner name to make the web site visible.","title":"Enable GH Pages"},{"location":"hosting-and-deployment/enable_github_pages/#enable-github-pages","text":"Github pages requires permissions to be enabled but the process is pretty easy. Create a public repository Navigate to Settings > Pages Configure the branch and build directory. \u2757 github.io requires using the owner name to make the web site visible.","title":"Enable Github Pages"},{"location":"hosting-and-deployment/gh-pages-private-repo/","text":"Github Pages Private Source Code Github pages are great, it provides a free static page hosting, but the only caveat is the repository has to be public repository. And, if you want to keep your source private, you will have to opt for premium plans to host pages from private repository. Here is what I have done, github allows unlimited private repositories, so I created a new private repo where I kept my source code and another repo where my site is hosted. Create Personal Token Create a personal access token. Navigate to Settings and create a PAT. Select Developer settings Select Personal access tokens Now generate a new token, with repo permissions. Once you are done copy the generated token, we will need to set this token during our build. Create secret in private repository Go to your private repo and click the settings: Create github action in private repoPermalink This is where the magic begins, we will build a github action in our private repo. You will need to create a file at .github/workflows/ci.yml name: Build & Publish on: push: branches: [ gh_pages ] pull_request: branches: [ gh_pages ] jobs: build: runs-on: ubuntu-latest steps: - name: Checkout local code uses: actions/checkout@v3 with: path: code token: ${{ secrets.GH_PAGES}} ref: gh_pages # - name: Show Directory Files # run : | # cd code # ls -la - name: python uses: actions/setup-python@v4 with: python-version: \"3.10\" - name: Checkout public repo site uses: actions/checkout@v3 with: token: ${{ secrets.GH_PAGES}} repository: np-completed/np-completed.github.io ref: gh_pages path: site - name: Install dependencies run: python3 -m pip install -r code/requirements.txt - name: Build website run: mkdocs build --config-file code/mkdocs.yml - name: Clean Website run: | pushd site git rm -rf . popd - name: Copy website run : | pushd site # cp -rvf ../code/build/* . cp -rvf ../code/site/* . popd ls -la site/ # ls -la code/site/ - name: Deploy and Publish run: | git config --global user.email \"${GITHUB_ACTOR}@users.noreply.github.com\" git config --global user.name \"github-actions\" pushd site git add . git commit -m \"mkdocs build from Action ${GITHUB_SHA}\" git push origin gh_pages popd Each push changes to the private repository triggers the github action. Next, the GH action job will be executed, to build and publish the site to the public repo without exposing your source code.","title":"Private Repo with GH Pages"},{"location":"hosting-and-deployment/gh-pages-private-repo/#github-pages-private-source-code","text":"Github pages are great, it provides a free static page hosting, but the only caveat is the repository has to be public repository. And, if you want to keep your source private, you will have to opt for premium plans to host pages from private repository. Here is what I have done, github allows unlimited private repositories, so I created a new private repo where I kept my source code and another repo where my site is hosted.","title":"Github Pages Private Source Code"},{"location":"hosting-and-deployment/gh-pages-private-repo/#create-personal-token","text":"Create a personal access token. Navigate to Settings and create a PAT. Select Developer settings Select Personal access tokens Now generate a new token, with repo permissions. Once you are done copy the generated token, we will need to set this token during our build.","title":"Create Personal Token"},{"location":"hosting-and-deployment/gh-pages-private-repo/#create-secret-in-private-repository","text":"Go to your private repo and click the settings:","title":"Create secret in private repository"},{"location":"hosting-and-deployment/gh-pages-private-repo/#create-github-action-in-private-repopermalink","text":"This is where the magic begins, we will build a github action in our private repo. You will need to create a file at .github/workflows/ci.yml name: Build & Publish on: push: branches: [ gh_pages ] pull_request: branches: [ gh_pages ] jobs: build: runs-on: ubuntu-latest steps: - name: Checkout local code uses: actions/checkout@v3 with: path: code token: ${{ secrets.GH_PAGES}} ref: gh_pages # - name: Show Directory Files # run : | # cd code # ls -la - name: python uses: actions/setup-python@v4 with: python-version: \"3.10\" - name: Checkout public repo site uses: actions/checkout@v3 with: token: ${{ secrets.GH_PAGES}} repository: np-completed/np-completed.github.io ref: gh_pages path: site - name: Install dependencies run: python3 -m pip install -r code/requirements.txt - name: Build website run: mkdocs build --config-file code/mkdocs.yml - name: Clean Website run: | pushd site git rm -rf . popd - name: Copy website run : | pushd site # cp -rvf ../code/build/* . cp -rvf ../code/site/* . popd ls -la site/ # ls -la code/site/ - name: Deploy and Publish run: | git config --global user.email \"${GITHUB_ACTOR}@users.noreply.github.com\" git config --global user.name \"github-actions\" pushd site git add . git commit -m \"mkdocs build from Action ${GITHUB_SHA}\" git push origin gh_pages popd Each push changes to the private repository triggers the github action. Next, the GH action job will be executed, to build and publish the site to the public repo without exposing your source code.","title":"Create github action in private repoPermalink"},{"location":"hosting-and-deployment/gh-pages/","text":"Host on GitHub Pages Demo site on GitHub Pages (build & deploy with GitHub Actions) Build and deploy with GitHub Actions peaceiris/actions-gh-pages: GitHub Actions for deploying to GitHub Pages with Static Site Generators Go to the repository and read the latest README.md for more details. Build and deploy with mkdocs gh-deploy pipenv pipenv run deploy # OR pipenv shell mkdocs gh-deploy # OR pipenv run mkdocs gh-deploy","title":"Github Pages"},{"location":"hosting-and-deployment/gh-pages/#host-on-github-pages","text":"Demo site on GitHub Pages (build & deploy with GitHub Actions)","title":"Host on GitHub Pages"},{"location":"hosting-and-deployment/gh-pages/#build-and-deploy-with-github-actions","text":"peaceiris/actions-gh-pages: GitHub Actions for deploying to GitHub Pages with Static Site Generators Go to the repository and read the latest README.md for more details.","title":"Build and deploy with GitHub Actions"},{"location":"hosting-and-deployment/gh-pages/#build-and-deploy-with-mkdocs-gh-deploy","text":"","title":"Build and deploy with mkdocs gh-deploy"},{"location":"hosting-and-deployment/gh-pages/#pipenv","text":"pipenv run deploy # OR pipenv shell mkdocs gh-deploy # OR pipenv run mkdocs gh-deploy","title":"pipenv"},{"location":"markdown/content/","text":"Collapsible Content These sections collapse to hide content. A widget expands it to show the content. ??? example \"Library: dataclasses \" The `dataclasses` package helps you to wrap your data in a Python class. This would be as opposed to holding it in a dictionary. This give the data structure features similar to a javascript object. If you have used the Python package you are already familar with a library that is essentially dataclasses package used for data _validation_ called `pydantic`. Dataclasses work in an almost identical way without the data validation part. So here is dataclasses in action. Instead of holding your data in a dictionary, you can can define a class for it and call it with dot notation like below. ```Python from dataclasses import dataclass, field @dataclass class Chemical: common_name: str symbol: str mass: float potassium = Chemical(\"Potassium\",\"K\",39.1) print( potassium.mass * 2 ) ``` **YT Video References:** [v1](https://www.youtube.com/watch?v=vRVVyl9uaZc), [v2](https://www.youtube.com/watch?v=CvQ7e6yUtnw&list=RDCMUCVhQ2NnY5Rskt6UjCUkJ_DA)","title":"Content"},{"location":"markdown/content/#collapsible-content","text":"These sections collapse to hide content. A widget expands it to show the content. ??? example \"Library: dataclasses \" The `dataclasses` package helps you to wrap your data in a Python class. This would be as opposed to holding it in a dictionary. This give the data structure features similar to a javascript object. If you have used the Python package you are already familar with a library that is essentially dataclasses package used for data _validation_ called `pydantic`. Dataclasses work in an almost identical way without the data validation part. So here is dataclasses in action. Instead of holding your data in a dictionary, you can can define a class for it and call it with dot notation like below. ```Python from dataclasses import dataclass, field @dataclass class Chemical: common_name: str symbol: str mass: float potassium = Chemical(\"Potassium\",\"K\",39.1) print( potassium.mass * 2 ) ``` **YT Video References:** [v1](https://www.youtube.com/watch?v=vRVVyl9uaZc), [v2](https://www.youtube.com/watch?v=CvQ7e6yUtnw&list=RDCMUCVhQ2NnY5Rskt6UjCUkJ_DA)","title":"Collapsible Content"},{"location":"markdown/emoji_list/","text":"emoji-cheat-sheet This cheat sheet is automatically generated from GitHub Emoji API and Unicode Full Emoji List . Table of Contents Smileys & Emotion People & Body Animals & Nature Food & Drink Travel & Places Activities Objects Symbols Flags GitHub Custom Emoji Smileys & Emotion Face Smiling Face Affection Face Tongue Face Hand Face Neutral Skeptical Face Sleepy Face Unwell Face Hat Face Glasses Face Concerned Face Negative Face Costume Cat Face Monkey Face Emotion Face Smiling ico shortcode ico shortcode top :grinning: :grinning: :smiley: :smiley: top top :smile: :smile: :grin: :grin: top top :laughing: :laughing: :satisfied: :sweat_smile: :sweat_smile: top top :rofl: :rofl: :joy: :joy: top top :slightly_smiling_face: :slightly_smiling_face: :upside_down_face: :upside_down_face: top top :wink: :wink: :blush: :blush: top top :innocent: :innocent: top Face Affection ico shortcode ico shortcode top :smiling_face_with_three_hearts: :smiling_face_with_three_hearts: :heart_eyes: :heart_eyes: top top :star_struck: :star_struck: :kissing_heart: :kissing_heart: top top :kissing: :kissing: :relaxed: :relaxed: top top :kissing_closed_eyes: :kissing_closed_eyes: :kissing_smiling_eyes: :kissing_smiling_eyes: top top :smiling_face_with_tear: :smiling_face_with_tear: top Face Tongue ico shortcode ico shortcode top :yum: :yum: :stuck_out_tongue: :stuck_out_tongue: top top :stuck_out_tongue_winking_eye: :stuck_out_tongue_winking_eye: :zany_face: :zany_face: top top :stuck_out_tongue_closed_eyes: :stuck_out_tongue_closed_eyes: :money_mouth_face: :money_mouth_face: top Face Hand ico shortcode ico shortcode top :hugs: :hugs: :hand_over_mouth: :hand_over_mouth: top top :shushing_face: :shushing_face: :thinking: :thinking: top Face Neutral Skeptical ico shortcode ico shortcode top :zipper_mouth_face: :zipper_mouth_face: :raised_eyebrow: :raised_eyebrow: top top :neutral_face: :neutral_face: :expressionless: :expressionless: top top :no_mouth: :no_mouth: :face_in_clouds: :face_in_clouds: top top :smirk: :smirk: :unamused: :unamused: top top :roll_eyes: :roll_eyes: :grimacing: :grimacing: top top :face_exhaling: :face_exhaling: :lying_face: :lying_face: top Face Sleepy ico shortcode ico shortcode top :relieved: :relieved: :pensive: :pensive: top top :sleepy: :sleepy: :drooling_face: :drooling_face: top top :sleeping: :sleeping: top Face Unwell ico shortcode ico shortcode top :mask: :mask: :face_with_thermometer: :face_with_thermometer: top top :face_with_head_bandage: :face_with_head_bandage: :nauseated_face: :nauseated_face: top top :vomiting_face: :vomiting_face: :sneezing_face: :sneezing_face: top top :hot_face: :hot_face: :cold_face: :cold_face: top top :woozy_face: :woozy_face: :dizzy_face: :dizzy_face: top top :face_with_spiral_eyes: :face_with_spiral_eyes: :exploding_head: :exploding_head: top Face Hat ico shortcode ico shortcode top :cowboy_hat_face: :cowboy_hat_face: :partying_face: :partying_face: top top :disguised_face: :disguised_face: top Face Glasses ico shortcode ico shortcode top :sunglasses: :sunglasses: :nerd_face: :nerd_face: top top :monocle_face: :monocle_face: top Face Concerned ico shortcode ico shortcode top :confused: :confused: :worried: :worried: top top :slightly_frowning_face: :slightly_frowning_face: :frowning_face: :frowning_face: top top :open_mouth: :open_mouth: :hushed: :hushed: top top :astonished: :astonished: :flushed: :flushed: top top :pleading_face: :pleading_face: :frowning: :frowning: top top :anguished: :anguished: :fearful: :fearful: top top :cold_sweat: :cold_sweat: :disappointed_relieved: :disappointed_relieved: top top :cry: :cry: :sob: :sob: top top :scream: :scream: :confounded: :confounded: top top :persevere: :persevere: :disappointed: :disappointed: top top :sweat: :sweat: :weary: :weary: top top :tired_face: :tired_face: :yawning_face: :yawning_face: top Face Negative ico shortcode ico shortcode top :triumph: :triumph: :pout: :pout: :rage: top top :angry: :angry: :cursing_face: :cursing_face: top top :smiling_imp: :smiling_imp: :imp: :imp: top top :skull: :skull: :skull_and_crossbones: :skull_and_crossbones: top Face Costume ico shortcode ico shortcode top :hankey: :hankey: :poop: :shit: :clown_face: :clown_face: top top :japanese_ogre: :japanese_ogre: :japanese_goblin: :japanese_goblin: top top :ghost: :ghost: :alien: :alien: top top :space_invader: :space_invader: :robot: :robot: top Cat Face ico shortcode ico shortcode top :smiley_cat: :smiley_cat: :smile_cat: :smile_cat: top top :joy_cat: :joy_cat: :heart_eyes_cat: :heart_eyes_cat: top top :smirk_cat: :smirk_cat: :kissing_cat: :kissing_cat: top top :scream_cat: :scream_cat: :crying_cat_face: :crying_cat_face: top top :pouting_cat: :pouting_cat: top Monkey Face ico shortcode ico shortcode top :see_no_evil: :see_no_evil: :hear_no_evil: :hear_no_evil: top top :speak_no_evil: :speak_no_evil: top Emotion ico shortcode ico shortcode top :kiss: :kiss: :love_letter: :love_letter: top top :cupid: :cupid: :gift_heart: :gift_heart: top top :sparkling_heart: :sparkling_heart: :heartpulse: :heartpulse: top top :heartbeat: :heartbeat: :revolving_hearts: :revolving_hearts: top top :two_hearts: :two_hearts: :heart_decoration: :heart_decoration: top top :heavy_heart_exclamation: :heavy_heart_exclamation: :broken_heart: :broken_heart: top top :heart_on_fire: :heart_on_fire: :mending_heart: :mending_heart: top top :heart: :heart: :orange_heart: :orange_heart: top top :yellow_heart: :yellow_heart: :green_heart: :green_heart: top top :blue_heart: :blue_heart: :purple_heart: :purple_heart: top top :brown_heart: :brown_heart: :black_heart: :black_heart: top top :white_heart: :white_heart: :100: :100: top top :anger: :anger: :boom: :boom: :collision: top top :dizzy: :dizzy: :sweat_drops: :sweat_drops: top top :dash: :dash: :hole: :hole: top top :bomb: :bomb: :speech_balloon: :speech_balloon: top top :eye_speech_bubble: :eye_speech_bubble: :left_speech_bubble: :left_speech_bubble: top top :right_anger_bubble: :right_anger_bubble: :thought_balloon: :thought_balloon: top top :zzz: :zzz: top People & Body Hand Fingers Open Hand Fingers Partial Hand Single Finger Hand Fingers Closed Hands Hand Prop Body Parts Person Person Gesture Person Role Person Fantasy Person Activity Person Sport Person Resting Family Person Symbol Hand Fingers Open ico shortcode ico shortcode top :wave: :wave: :raised_back_of_hand: :raised_back_of_hand: top top :raised_hand_with_fingers_splayed: :raised_hand_with_fingers_splayed: :hand: :hand: :raised_hand: top top :vulcan_salute: :vulcan_salute: top Hand Fingers Partial ico shortcode ico shortcode top :ok_hand: :ok_hand: :pinched_fingers: :pinched_fingers: top top :pinching_hand: :pinching_hand: :v: :v: top top :crossed_fingers: :crossed_fingers: :love_you_gesture: :love_you_gesture: top top :metal: :metal: :call_me_hand: :call_me_hand: top Hand Single Finger ico shortcode ico shortcode top :point_left: :point_left: :point_right: :point_right: top top :point_up_2: :point_up_2: :fu: :fu: :middle_finger: top top :point_down: :point_down: :point_up: :point_up: top Hand Fingers Closed ico shortcode ico shortcode top :+1: :+1: :thumbsup: :-1: :-1: :thumbsdown: top top :fist: :fist: :fist_raised: :facepunch: :facepunch: :fist_oncoming: :punch: top top :fist_left: :fist_left: :fist_right: :fist_right: top Hands ico shortcode ico shortcode top :clap: :clap: :raised_hands: :raised_hands: top top :open_hands: :open_hands: :palms_up_together: :palms_up_together: top top :handshake: :handshake: :pray: :pray: top Hand Prop ico shortcode ico shortcode top :writing_hand: :writing_hand: :nail_care: :nail_care: top top :selfie: :selfie: top Body Parts ico shortcode ico shortcode top :muscle: :muscle: :mechanical_arm: :mechanical_arm: top top :mechanical_leg: :mechanical_leg: :leg: :leg: top top :foot: :foot: :ear: :ear: top top :ear_with_hearing_aid: :ear_with_hearing_aid: :nose: :nose: top top :brain: :brain: :anatomical_heart: :anatomical_heart: top top :lungs: :lungs: :tooth: :tooth: top top :bone: :bone: :eyes: :eyes: top top :eye: :eye: :tongue: :tongue: top top :lips: :lips: top Person ico shortcode ico shortcode top :baby: :baby: :child: :child: top top :boy: :boy: :girl: :girl: top top :adult: :adult: :blond_haired_person: :blond_haired_person: top top :man: :man: :bearded_person: :bearded_person: top top :man_beard: :man_beard: :woman_beard: :woman_beard: top top :red_haired_man: :red_haired_man: :curly_haired_man: :curly_haired_man: top top :white_haired_man: :white_haired_man: :bald_man: :bald_man: top top :woman: :woman: :red_haired_woman: :red_haired_woman: top top :person_red_hair: :person_red_hair: :curly_haired_woman: :curly_haired_woman: top top :person_curly_hair: :person_curly_hair: :white_haired_woman: :white_haired_woman: top top :person_white_hair: :person_white_hair: :bald_woman: :bald_woman: top top :person_bald: :person_bald: :blond_haired_woman: :blond_haired_woman: :blonde_woman: top top :blond_haired_man: :blond_haired_man: :older_adult: :older_adult: top top :older_man: :older_man: :older_woman: :older_woman: top Person Gesture ico shortcode ico shortcode top :frowning_person: :frowning_person: :frowning_man: :frowning_man: top top :frowning_woman: :frowning_woman: :pouting_face: :pouting_face: top top :pouting_man: :pouting_man: :pouting_woman: :pouting_woman: top top :no_good: :no_good: :ng_man: :ng_man: :no_good_man: top top :ng_woman: :ng_woman: :no_good_woman: :ok_person: :ok_person: top top :ok_man: :ok_man: :ok_woman: :ok_woman: top top :information_desk_person: :information_desk_person: :tipping_hand_person: :sassy_man: :sassy_man: :tipping_hand_man: top top :sassy_woman: :sassy_woman: :tipping_hand_woman: :raising_hand: :raising_hand: top top :raising_hand_man: :raising_hand_man: :raising_hand_woman: :raising_hand_woman: top top :deaf_person: :deaf_person: :deaf_man: :deaf_man: top top :deaf_woman: :deaf_woman: :bow: :bow: top top :bowing_man: :bowing_man: :bowing_woman: :bowing_woman: top top :facepalm: :facepalm: :man_facepalming: :man_facepalming: top top :woman_facepalming: :woman_facepalming: :shrug: :shrug: top top :man_shrugging: :man_shrugging: :woman_shrugging: :woman_shrugging: top Person Role ico shortcode ico shortcode top :health_worker: :health_worker: :man_health_worker: :man_health_worker: top top :woman_health_worker: :woman_health_worker: :student: :student: top top :man_student: :man_student: :woman_student: :woman_student: top top :teacher: :teacher: :man_teacher: :man_teacher: top top :woman_teacher: :woman_teacher: :judge: :judge: top top :man_judge: :man_judge: :woman_judge: :woman_judge: top top :farmer: :farmer: :man_farmer: :man_farmer: top top :woman_farmer: :woman_farmer: :cook: :cook: top top :man_cook: :man_cook: :woman_cook: :woman_cook: top top :mechanic: :mechanic: :man_mechanic: :man_mechanic: top top :woman_mechanic: :woman_mechanic: :factory_worker: :factory_worker: top top :man_factory_worker: :man_factory_worker: :woman_factory_worker: :woman_factory_worker: top top :office_worker: :office_worker: :man_office_worker: :man_office_worker: top top :woman_office_worker: :woman_office_worker: :scientist: :scientist: top top :man_scientist: :man_scientist: :woman_scientist: :woman_scientist: top top :technologist: :technologist: :man_technologist: :man_technologist: top top :woman_technologist: :woman_technologist: :singer: :singer: top top :man_singer: :man_singer: :woman_singer: :woman_singer: top top :artist: :artist: :man_artist: :man_artist: top top :woman_artist: :woman_artist: :pilot: :pilot: top top :man_pilot: :man_pilot: :woman_pilot: :woman_pilot: top top :astronaut: :astronaut: :man_astronaut: :man_astronaut: top top :woman_astronaut: :woman_astronaut: :firefighter: :firefighter: top top :man_firefighter: :man_firefighter: :woman_firefighter: :woman_firefighter: top top :cop: :cop: :police_officer: :policeman: :policeman: top top :policewoman: :policewoman: :detective: :detective: top top :male_detective: :male_detective: :female_detective: :female_detective: top top :guard: :guard: :guardsman: :guardsman: top top :guardswoman: :guardswoman: :ninja: :ninja: top top :construction_worker: :construction_worker: :construction_worker_man: :construction_worker_man: top top :construction_worker_woman: :construction_worker_woman: :prince: :prince: top top :princess: :princess: :person_with_turban: :person_with_turban: top top :man_with_turban: :man_with_turban: :woman_with_turban: :woman_with_turban: top top :man_with_gua_pi_mao: :man_with_gua_pi_mao: :woman_with_headscarf: :woman_with_headscarf: top top :person_in_tuxedo: :person_in_tuxedo: :man_in_tuxedo: :man_in_tuxedo: top top :woman_in_tuxedo: :woman_in_tuxedo: :person_with_veil: :person_with_veil: top top :man_with_veil: :man_with_veil: :bride_with_veil: :bride_with_veil: :woman_with_veil: top top :pregnant_woman: :pregnant_woman: :breast_feeding: :breast_feeding: top top :woman_feeding_baby: :woman_feeding_baby: :man_feeding_baby: :man_feeding_baby: top top :person_feeding_baby: :person_feeding_baby: top Person Fantasy ico shortcode ico shortcode top :angel: :angel: :santa: :santa: top top :mrs_claus: :mrs_claus: :mx_claus: :mx_claus: top top :superhero: :superhero: :superhero_man: :superhero_man: top top :superhero_woman: :superhero_woman: :supervillain: :supervillain: top top :supervillain_man: :supervillain_man: :supervillain_woman: :supervillain_woman: top top :mage: :mage: :mage_man: :mage_man: top top :mage_woman: :mage_woman: :fairy: :fairy: top top :fairy_man: :fairy_man: :fairy_woman: :fairy_woman: top top :vampire: :vampire: :vampire_man: :vampire_man: top top :vampire_woman: :vampire_woman: :merperson: :merperson: top top :merman: :merman: :mermaid: :mermaid: top top :elf: :elf: :elf_man: :elf_man: top top :elf_woman: :elf_woman: :genie: :genie: top top :genie_man: :genie_man: :genie_woman: :genie_woman: top top :zombie: :zombie: :zombie_man: :zombie_man: top top :zombie_woman: :zombie_woman: top Person Activity ico shortcode ico shortcode top :massage: :massage: :massage_man: :massage_man: top top :massage_woman: :massage_woman: :haircut: :haircut: top top :haircut_man: :haircut_man: :haircut_woman: :haircut_woman: top top :walking: :walking: :walking_man: :walking_man: top top :walking_woman: :walking_woman: :standing_person: :standing_person: top top :standing_man: :standing_man: :standing_woman: :standing_woman: top top :kneeling_person: :kneeling_person: :kneeling_man: :kneeling_man: top top :kneeling_woman: :kneeling_woman: :person_with_probing_cane: :person_with_probing_cane: top top :man_with_probing_cane: :man_with_probing_cane: :woman_with_probing_cane: :woman_with_probing_cane: top top :person_in_motorized_wheelchair: :person_in_motorized_wheelchair: :man_in_motorized_wheelchair: :man_in_motorized_wheelchair: top top :woman_in_motorized_wheelchair: :woman_in_motorized_wheelchair: :person_in_manual_wheelchair: :person_in_manual_wheelchair: top top :man_in_manual_wheelchair: :man_in_manual_wheelchair: :woman_in_manual_wheelchair: :woman_in_manual_wheelchair: top top :runner: :runner: :running: :running_man: :running_man: top top :running_woman: :running_woman: :dancer: :dancer: :woman_dancing: top top :man_dancing: :man_dancing: :business_suit_levitating: :business_suit_levitating: top top :dancers: :dancers: :dancing_men: :dancing_men: top top :dancing_women: :dancing_women: :sauna_person: :sauna_person: top top :sauna_man: :sauna_man: :sauna_woman: :sauna_woman: top top :climbing: :climbing: :climbing_man: :climbing_man: top top :climbing_woman: :climbing_woman: top Person Sport ico shortcode ico shortcode top :person_fencing: :person_fencing: :horse_racing: :horse_racing: top top :skier: :skier: :snowboarder: :snowboarder: top top :golfing: :golfing: :golfing_man: :golfing_man: top top :golfing_woman: :golfing_woman: :surfer: :surfer: top top :surfing_man: :surfing_man: :surfing_woman: :surfing_woman: top top :rowboat: :rowboat: :rowing_man: :rowing_man: top top :rowing_woman: :rowing_woman: :swimmer: :swimmer: top top :swimming_man: :swimming_man: :swimming_woman: :swimming_woman: top top :bouncing_ball_person: :bouncing_ball_person: :basketball_man: :basketball_man: :bouncing_ball_man: top top :basketball_woman: :basketball_woman: :bouncing_ball_woman: :weight_lifting: :weight_lifting: top top :weight_lifting_man: :weight_lifting_man: :weight_lifting_woman: :weight_lifting_woman: top top :bicyclist: :bicyclist: :biking_man: :biking_man: top top :biking_woman: :biking_woman: :mountain_bicyclist: :mountain_bicyclist: top top :mountain_biking_man: :mountain_biking_man: :mountain_biking_woman: :mountain_biking_woman: top top :cartwheeling: :cartwheeling: :man_cartwheeling: :man_cartwheeling: top top :woman_cartwheeling: :woman_cartwheeling: :wrestling: :wrestling: top top :men_wrestling: :men_wrestling: :women_wrestling: :women_wrestling: top top :water_polo: :water_polo: :man_playing_water_polo: :man_playing_water_polo: top top :woman_playing_water_polo: :woman_playing_water_polo: :handball_person: :handball_person: top top :man_playing_handball: :man_playing_handball: :woman_playing_handball: :woman_playing_handball: top top :juggling_person: :juggling_person: :man_juggling: :man_juggling: top top :woman_juggling: :woman_juggling: top Person Resting ico shortcode ico shortcode top :lotus_position: :lotus_position: :lotus_position_man: :lotus_position_man: top top :lotus_position_woman: :lotus_position_woman: :bath: :bath: top top :sleeping_bed: :sleeping_bed: top Family ico shortcode ico shortcode top :people_holding_hands: :people_holding_hands: :two_women_holding_hands: :two_women_holding_hands: top top :couple: :couple: :two_men_holding_hands: :two_men_holding_hands: top top :couplekiss: :couplekiss: :couplekiss_man_woman: :couplekiss_man_woman: top top :couplekiss_man_man: :couplekiss_man_man: :couplekiss_woman_woman: :couplekiss_woman_woman: top top :couple_with_heart: :couple_with_heart: :couple_with_heart_woman_man: :couple_with_heart_woman_man: top top :couple_with_heart_man_man: :couple_with_heart_man_man: :couple_with_heart_woman_woman: :couple_with_heart_woman_woman: top top :family: :family: :family_man_woman_boy: :family_man_woman_boy: top top :family_man_woman_girl: :family_man_woman_girl: :family_man_woman_girl_boy: :family_man_woman_girl_boy: top top :family_man_woman_boy_boy: :family_man_woman_boy_boy: :family_man_woman_girl_girl: :family_man_woman_girl_girl: top top :family_man_man_boy: :family_man_man_boy: :family_man_man_girl: :family_man_man_girl: top top :family_man_man_girl_boy: :family_man_man_girl_boy: :family_man_man_boy_boy: :family_man_man_boy_boy: top top :family_man_man_girl_girl: :family_man_man_girl_girl: :family_woman_woman_boy: :family_woman_woman_boy: top top :family_woman_woman_girl: :family_woman_woman_girl: :family_woman_woman_girl_boy: :family_woman_woman_girl_boy: top top :family_woman_woman_boy_boy: :family_woman_woman_boy_boy: :family_woman_woman_girl_girl: :family_woman_woman_girl_girl: top top :family_man_boy: :family_man_boy: :family_man_boy_boy: :family_man_boy_boy: top top :family_man_girl: :family_man_girl: :family_man_girl_boy: :family_man_girl_boy: top top :family_man_girl_girl: :family_man_girl_girl: :family_woman_boy: :family_woman_boy: top top :family_woman_boy_boy: :family_woman_boy_boy: :family_woman_girl: :family_woman_girl: top top :family_woman_girl_boy: :family_woman_girl_boy: :family_woman_girl_girl: :family_woman_girl_girl: top Person Symbol ico shortcode ico shortcode top :speaking_head: :speaking_head: :bust_in_silhouette: :bust_in_silhouette: top top :busts_in_silhouette: :busts_in_silhouette: :people_hugging: :people_hugging: top top :footprints: :footprints: top Animals & Nature Animal Mammal Animal Bird Animal Amphibian Animal Reptile Animal Marine Animal Bug Plant Flower Plant Other Animal Mammal ico shortcode ico shortcode top :monkey_face: :monkey_face: :monkey: :monkey: top top :gorilla: :gorilla: :orangutan: :orangutan: top top :dog: :dog: :dog2: :dog2: top top :guide_dog: :guide_dog: :service_dog: :service_dog: top top :poodle: :poodle: :wolf: :wolf: top top :fox_face: :fox_face: :raccoon: :raccoon: top top :cat: :cat: :cat2: :cat2: top top :black_cat: :black_cat: :lion: :lion: top top :tiger: :tiger: :tiger2: :tiger2: top top :leopard: :leopard: :horse: :horse: top top :racehorse: :racehorse: :unicorn: :unicorn: top top :zebra: :zebra: :deer: :deer: top top :bison: :bison: :cow: :cow: top top :ox: :ox: :water_buffalo: :water_buffalo: top top :cow2: :cow2: :pig: :pig: top top :pig2: :pig2: :boar: :boar: top top :pig_nose: :pig_nose: :ram: :ram: top top :sheep: :sheep: :goat: :goat: top top :dromedary_camel: :dromedary_camel: :camel: :camel: top top :llama: :llama: :giraffe: :giraffe: top top :elephant: :elephant: :mammoth: :mammoth: top top :rhinoceros: :rhinoceros: :hippopotamus: :hippopotamus: top top :mouse: :mouse: :mouse2: :mouse2: top top :rat: :rat: :hamster: :hamster: top top :rabbit: :rabbit: :rabbit2: :rabbit2: top top :chipmunk: :chipmunk: :beaver: :beaver: top top :hedgehog: :hedgehog: :bat: :bat: top top :bear: :bear: :polar_bear: :polar_bear: top top :koala: :koala: :panda_face: :panda_face: top top :sloth: :sloth: :otter: :otter: top top :skunk: :skunk: :kangaroo: :kangaroo: top top :badger: :badger: :feet: :feet: :paw_prints: top Animal Bird ico shortcode ico shortcode top :turkey: :turkey: :chicken: :chicken: top top :rooster: :rooster: :hatching_chick: :hatching_chick: top top :baby_chick: :baby_chick: :hatched_chick: :hatched_chick: top top :bird: :bird: :penguin: :penguin: top top :dove: :dove: :eagle: :eagle: top top :duck: :duck: :swan: :swan: top top :owl: :owl: :dodo: :dodo: top top :feather: :feather: :flamingo: :flamingo: top top :peacock: :peacock: :parrot: :parrot: top Animal Amphibian ico shortcode top :frog: :frog: top Animal Reptile ico shortcode ico shortcode top :crocodile: :crocodile: :turtle: :turtle: top top :lizard: :lizard: :snake: :snake: top top :dragon_face: :dragon_face: :dragon: :dragon: top top :sauropod: :sauropod: :t-rex: :t-rex: top Animal Marine ico shortcode ico shortcode top :whale: :whale: :whale2: :whale2: top top :dolphin: :dolphin: :flipper: :seal: :seal: top top :fish: :fish: :tropical_fish: :tropical_fish: top top :blowfish: :blowfish: :shark: :shark: top top :octopus: :octopus: :shell: :shell: top Animal Bug ico shortcode ico shortcode top :snail: :snail: :butterfly: :butterfly: top top :bug: :bug: :ant: :ant: top top :bee: :bee: :honeybee: :beetle: :beetle: top top :lady_beetle: :lady_beetle: :cricket: :cricket: top top :cockroach: :cockroach: :spider: :spider: top top :spider_web: :spider_web: :scorpion: :scorpion: top top :mosquito: :mosquito: :fly: :fly: top top :worm: :worm: :microbe: :microbe: top Plant Flower ico shortcode ico shortcode top :bouquet: :bouquet: :cherry_blossom: :cherry_blossom: top top :white_flower: :white_flower: :rosette: :rosette: top top :rose: :rose: :wilted_flower: :wilted_flower: top top :hibiscus: :hibiscus: :sunflower: :sunflower: top top :blossom: :blossom: :tulip: :tulip: top Plant Other ico shortcode ico shortcode top :seedling: :seedling: :potted_plant: :potted_plant: top top :evergreen_tree: :evergreen_tree: :deciduous_tree: :deciduous_tree: top top :palm_tree: :palm_tree: :cactus: :cactus: top top :ear_of_rice: :ear_of_rice: :herb: :herb: top top :shamrock: :shamrock: :four_leaf_clover: :four_leaf_clover: top top :maple_leaf: :maple_leaf: :fallen_leaf: :fallen_leaf: top top :leaves: :leaves: top Food & Drink Food Fruit Food Vegetable Food Prepared Food Asian Food Marine Food Sweet Drink Dishware Food Fruit ico shortcode ico shortcode top :grapes: :grapes: :melon: :melon: top top :watermelon: :watermelon: :mandarin: :mandarin: :orange: :tangerine: top top :lemon: :lemon: :banana: :banana: top top :pineapple: :pineapple: :mango: :mango: top top :apple: :apple: :green_apple: :green_apple: top top :pear: :pear: :peach: :peach: top top :cherries: :cherries: :strawberry: :strawberry: top top :blueberries: :blueberries: :kiwi_fruit: :kiwi_fruit: top top :tomato: :tomato: :olive: :olive: top top :coconut: :coconut: top Food Vegetable ico shortcode ico shortcode top :avocado: :avocado: :eggplant: :eggplant: top top :potato: :potato: :carrot: :carrot: top top :corn: :corn: :hot_pepper: :hot_pepper: top top :bell_pepper: :bell_pepper: :cucumber: :cucumber: top top :leafy_green: :leafy_green: :broccoli: :broccoli: top top :garlic: :garlic: :onion: :onion: top top :mushroom: :mushroom: :peanuts: :peanuts: top top :chestnut: :chestnut: top Food Prepared ico shortcode ico shortcode top :bread: :bread: :croissant: :croissant: top top :baguette_bread: :baguette_bread: :flatbread: :flatbread: top top :pretzel: :pretzel: :bagel: :bagel: top top :pancakes: :pancakes: :waffle: :waffle: top top :cheese: :cheese: :meat_on_bone: :meat_on_bone: top top :poultry_leg: :poultry_leg: :cut_of_meat: :cut_of_meat: top top :bacon: :bacon: :hamburger: :hamburger: top top :fries: :fries: :pizza: :pizza: top top :hotdog: :hotdog: :sandwich: :sandwich: top top :taco: :taco: :burrito: :burrito: top top :tamale: :tamale: :stuffed_flatbread: :stuffed_flatbread: top top :falafel: :falafel: :egg: :egg: top top :fried_egg: :fried_egg: :shallow_pan_of_food: :shallow_pan_of_food: top top :stew: :stew: :fondue: :fondue: top top :bowl_with_spoon: :bowl_with_spoon: :green_salad: :green_salad: top top :popcorn: :popcorn: :butter: :butter: top top :salt: :salt: :canned_food: :canned_food: top Food Asian ico shortcode ico shortcode top :bento: :bento: :rice_cracker: :rice_cracker: top top :rice_ball: :rice_ball: :rice: :rice: top top :curry: :curry: :ramen: :ramen: top top :spaghetti: :spaghetti: :sweet_potato: :sweet_potato: top top :oden: :oden: :sushi: :sushi: top top :fried_shrimp: :fried_shrimp: :fish_cake: :fish_cake: top top :moon_cake: :moon_cake: :dango: :dango: top top :dumpling: :dumpling: :fortune_cookie: :fortune_cookie: top top :takeout_box: :takeout_box: top Food Marine ico shortcode ico shortcode top :crab: :crab: :lobster: :lobster: top top :shrimp: :shrimp: :squid: :squid: top top :oyster: :oyster: top Food Sweet ico shortcode ico shortcode top :icecream: :icecream: :shaved_ice: :shaved_ice: top top :ice_cream: :ice_cream: :doughnut: :doughnut: top top :cookie: :cookie: :birthday: :birthday: top top :cake: :cake: :cupcake: :cupcake: top top :pie: :pie: :chocolate_bar: :chocolate_bar: top top :candy: :candy: :lollipop: :lollipop: top top :custard: :custard: :honey_pot: :honey_pot: top Drink ico shortcode ico shortcode top :baby_bottle: :baby_bottle: :milk_glass: :milk_glass: top top :coffee: :coffee: :teapot: :teapot: top top :tea: :tea: :sake: :sake: top top :champagne: :champagne: :wine_glass: :wine_glass: top top :cocktail: :cocktail: :tropical_drink: :tropical_drink: top top :beer: :beer: :beers: :beers: top top :clinking_glasses: :clinking_glasses: :tumbler_glass: :tumbler_glass: top top :cup_with_straw: :cup_with_straw: :bubble_tea: :bubble_tea: top top :beverage_box: :beverage_box: :mate: :mate: top top :ice_cube: :ice_cube: top Dishware ico shortcode ico shortcode top :chopsticks: :chopsticks: :plate_with_cutlery: :plate_with_cutlery: top top :fork_and_knife: :fork_and_knife: :spoon: :spoon: top top :hocho: :hocho: :knife: :amphora: :amphora: top Travel & Places Place Map Place Geographic Place Building Place Religious Place Other Transport Ground Transport Water Transport Air Hotel Time Sky & Weather Place Map ico shortcode ico shortcode top :earth_africa: :earth_africa: :earth_americas: :earth_americas: top top :earth_asia: :earth_asia: :globe_with_meridians: :globe_with_meridians: top top :world_map: :world_map: :japan: :japan: top top :compass: :compass: top Place Geographic ico shortcode ico shortcode top :mountain_snow: :mountain_snow: :mountain: :mountain: top top :volcano: :volcano: :mount_fuji: :mount_fuji: top top :camping: :camping: :beach_umbrella: :beach_umbrella: top top :desert: :desert: :desert_island: :desert_island: top top :national_park: :national_park: top Place Building ico shortcode ico shortcode top :stadium: :stadium: :classical_building: :classical_building: top top :building_construction: :building_construction: :bricks: :bricks: top top :rock: :rock: :wood: :wood: top top :hut: :hut: :houses: :houses: top top :derelict_house: :derelict_house: :house: :house: top top :house_with_garden: :house_with_garden: :office: :office: top top :post_office: :post_office: :european_post_office: :european_post_office: top top :hospital: :hospital: :bank: :bank: top top :hotel: :hotel: :love_hotel: :love_hotel: top top :convenience_store: :convenience_store: :school: :school: top top :department_store: :department_store: :factory: :factory: top top :japanese_castle: :japanese_castle: :european_castle: :european_castle: top top :wedding: :wedding: :tokyo_tower: :tokyo_tower: top top :statue_of_liberty: :statue_of_liberty: top Place Religious ico shortcode ico shortcode top :church: :church: :mosque: :mosque: top top :hindu_temple: :hindu_temple: :synagogue: :synagogue: top top :shinto_shrine: :shinto_shrine: :kaaba: :kaaba: top Place Other ico shortcode ico shortcode top :fountain: :fountain: :tent: :tent: top top :foggy: :foggy: :night_with_stars: :night_with_stars: top top :cityscape: :cityscape: :sunrise_over_mountains: :sunrise_over_mountains: top top :sunrise: :sunrise: :city_sunset: :city_sunset: top top :city_sunrise: :city_sunrise: :bridge_at_night: :bridge_at_night: top top :hotsprings: :hotsprings: :carousel_horse: :carousel_horse: top top :ferris_wheel: :ferris_wheel: :roller_coaster: :roller_coaster: top top :barber: :barber: :circus_tent: :circus_tent: top Transport Ground ico shortcode ico shortcode top :steam_locomotive: :steam_locomotive: :railway_car: :railway_car: top top :bullettrain_side: :bullettrain_side: :bullettrain_front: :bullettrain_front: top top :train2: :train2: :metro: :metro: top top :light_rail: :light_rail: :station: :station: top top :tram: :tram: :monorail: :monorail: top top :mountain_railway: :mountain_railway: :train: :train: top top :bus: :bus: :oncoming_bus: :oncoming_bus: top top :trolleybus: :trolleybus: :minibus: :minibus: top top :ambulance: :ambulance: :fire_engine: :fire_engine: top top :police_car: :police_car: :oncoming_police_car: :oncoming_police_car: top top :taxi: :taxi: :oncoming_taxi: :oncoming_taxi: top top :car: :car: :red_car: :oncoming_automobile: :oncoming_automobile: top top :blue_car: :blue_car: :pickup_truck: :pickup_truck: top top :truck: :truck: :articulated_lorry: :articulated_lorry: top top :tractor: :tractor: :racing_car: :racing_car: top top :motorcycle: :motorcycle: :motor_scooter: :motor_scooter: top top :manual_wheelchair: :manual_wheelchair: :motorized_wheelchair: :motorized_wheelchair: top top :auto_rickshaw: :auto_rickshaw: :bike: :bike: top top :kick_scooter: :kick_scooter: :skateboard: :skateboard: top top :roller_skate: :roller_skate: :busstop: :busstop: top top :motorway: :motorway: :railway_track: :railway_track: top top :oil_drum: :oil_drum: :fuelpump: :fuelpump: top top :rotating_light: :rotating_light: :traffic_light: :traffic_light: top top :vertical_traffic_light: :vertical_traffic_light: :stop_sign: :stop_sign: top top :construction: :construction: top Transport Water ico shortcode ico shortcode top :anchor: :anchor: :boat: :boat: :sailboat: top top :canoe: :canoe: :speedboat: :speedboat: top top :passenger_ship: :passenger_ship: :ferry: :ferry: top top :motor_boat: :motor_boat: :ship: :ship: top Transport Air ico shortcode ico shortcode top :airplane: :airplane: :small_airplane: :small_airplane: top top :flight_departure: :flight_departure: :flight_arrival: :flight_arrival: top top :parachute: :parachute: :seat: :seat: top top :helicopter: :helicopter: :suspension_railway: :suspension_railway: top top :mountain_cableway: :mountain_cableway: :aerial_tramway: :aerial_tramway: top top :artificial_satellite: :artificial_satellite: :rocket: :rocket: top top :flying_saucer: :flying_saucer: top Hotel ico shortcode ico shortcode top :bellhop_bell: :bellhop_bell: :luggage: :luggage: top Time ico shortcode ico shortcode top :hourglass: :hourglass: :hourglass_flowing_sand: :hourglass_flowing_sand: top top :watch: :watch: :alarm_clock: :alarm_clock: top top :stopwatch: :stopwatch: :timer_clock: :timer_clock: top top :mantelpiece_clock: :mantelpiece_clock: :clock12: :clock12: top top :clock1230: :clock1230: :clock1: :clock1: top top :clock130: :clock130: :clock2: :clock2: top top :clock230: :clock230: :clock3: :clock3: top top :clock330: :clock330: :clock4: :clock4: top top :clock430: :clock430: :clock5: :clock5: top top :clock530: :clock530: :clock6: :clock6: top top :clock630: :clock630: :clock7: :clock7: top top :clock730: :clock730: :clock8: :clock8: top top :clock830: :clock830: :clock9: :clock9: top top :clock930: :clock930: :clock10: :clock10: top top :clock1030: :clock1030: :clock11: :clock11: top top :clock1130: :clock1130: top Sky & Weather ico shortcode ico shortcode top :new_moon: :new_moon: :waxing_crescent_moon: :waxing_crescent_moon: top top :first_quarter_moon: :first_quarter_moon: :moon: :moon: :waxing_gibbous_moon: top top :full_moon: :full_moon: :waning_gibbous_moon: :waning_gibbous_moon: top top :last_quarter_moon: :last_quarter_moon: :waning_crescent_moon: :waning_crescent_moon: top top :crescent_moon: :crescent_moon: :new_moon_with_face: :new_moon_with_face: top top :first_quarter_moon_with_face: :first_quarter_moon_with_face: :last_quarter_moon_with_face: :last_quarter_moon_with_face: top top :thermometer: :thermometer: :sunny: :sunny: top top :full_moon_with_face: :full_moon_with_face: :sun_with_face: :sun_with_face: top top :ringed_planet: :ringed_planet: :star: :star: top top :star2: :star2: :stars: :stars: top top :milky_way: :milky_way: :cloud: :cloud: top top :partly_sunny: :partly_sunny: :cloud_with_lightning_and_rain: :cloud_with_lightning_and_rain: top top :sun_behind_small_cloud: :sun_behind_small_cloud: :sun_behind_large_cloud: :sun_behind_large_cloud: top top :sun_behind_rain_cloud: :sun_behind_rain_cloud: :cloud_with_rain: :cloud_with_rain: top top :cloud_with_snow: :cloud_with_snow: :cloud_with_lightning: :cloud_with_lightning: top top :tornado: :tornado: :fog: :fog: top top :wind_face: :wind_face: :cyclone: :cyclone: top top :rainbow: :rainbow: :closed_umbrella: :closed_umbrella: top top :open_umbrella: :open_umbrella: :umbrella: :umbrella: top top :parasol_on_ground: :parasol_on_ground: :zap: :zap: top top :snowflake: :snowflake: :snowman_with_snow: :snowman_with_snow: top top :snowman: :snowman: :comet: :comet: top top :fire: :fire: :droplet: :droplet: top top :ocean: :ocean: top Activities Event Award Medal Sport Game Arts & Crafts Event ico shortcode ico shortcode top :jack_o_lantern: :jack_o_lantern: :christmas_tree: :christmas_tree: top top :fireworks: :fireworks: :sparkler: :sparkler: top top :firecracker: :firecracker: :sparkles: :sparkles: top top :balloon: :balloon: :tada: :tada: top top :confetti_ball: :confetti_ball: :tanabata_tree: :tanabata_tree: top top :bamboo: :bamboo: :dolls: :dolls: top top :flags: :flags: :wind_chime: :wind_chime: top top :rice_scene: :rice_scene: :red_envelope: :red_envelope: top top :ribbon: :ribbon: :gift: :gift: top top :reminder_ribbon: :reminder_ribbon: :tickets: :tickets: top top :ticket: :ticket: top Award Medal ico shortcode ico shortcode top :medal_military: :medal_military: :trophy: :trophy: top top :medal_sports: :medal_sports: :1st_place_medal: :1st_place_medal: top top :2nd_place_medal: :2nd_place_medal: :3rd_place_medal: :3rd_place_medal: top Sport ico shortcode ico shortcode top :soccer: :soccer: :baseball: :baseball: top top :softball: :softball: :basketball: :basketball: top top :volleyball: :volleyball: :football: :football: top top :rugby_football: :rugby_football: :tennis: :tennis: top top :flying_disc: :flying_disc: :bowling: :bowling: top top :cricket_game: :cricket_game: :field_hockey: :field_hockey: top top :ice_hockey: :ice_hockey: :lacrosse: :lacrosse: top top :ping_pong: :ping_pong: :badminton: :badminton: top top :boxing_glove: :boxing_glove: :martial_arts_uniform: :martial_arts_uniform: top top :goal_net: :goal_net: :golf: :golf: top top :ice_skate: :ice_skate: :fishing_pole_and_fish: :fishing_pole_and_fish: top top :diving_mask: :diving_mask: :running_shirt_with_sash: :running_shirt_with_sash: top top :ski: :ski: :sled: :sled: top top :curling_stone: :curling_stone: top Game ico shortcode ico shortcode top :dart: :dart: :yo_yo: :yo_yo: top top :kite: :kite: :8ball: :8ball: top top :crystal_ball: :crystal_ball: :magic_wand: :magic_wand: top top :nazar_amulet: :nazar_amulet: :video_game: :video_game: top top :joystick: :joystick: :slot_machine: :slot_machine: top top :game_die: :game_die: :jigsaw: :jigsaw: top top :teddy_bear: :teddy_bear: :pinata: :pinata: top top :nesting_dolls: :nesting_dolls: :spades: :spades: top top :hearts: :hearts: :diamonds: :diamonds: top top :clubs: :clubs: :chess_pawn: :chess_pawn: top top :black_joker: :black_joker: :mahjong: :mahjong: top top :flower_playing_cards: :flower_playing_cards: top Arts & Crafts ico shortcode ico shortcode top :performing_arts: :performing_arts: :framed_picture: :framed_picture: top top :art: :art: :thread: :thread: top top :sewing_needle: :sewing_needle: :yarn: :yarn: top top :knot: :knot: top Objects Clothing Sound Music Musical Instrument Phone Computer Light & Video Book Paper Money Mail Writing Office Lock Tool Science Medical Household Other Object Clothing ico shortcode ico shortcode top :eyeglasses: :eyeglasses: :dark_sunglasses: :dark_sunglasses: top top :goggles: :goggles: :lab_coat: :lab_coat: top top :safety_vest: :safety_vest: :necktie: :necktie: top top :shirt: :shirt: :tshirt: :jeans: :jeans: top top :scarf: :scarf: :gloves: :gloves: top top :coat: :coat: :socks: :socks: top top :dress: :dress: :kimono: :kimono: top top :sari: :sari: :one_piece_swimsuit: :one_piece_swimsuit: top top :swim_brief: :swim_brief: :shorts: :shorts: top top :bikini: :bikini: :womans_clothes: :womans_clothes: top top :purse: :purse: :handbag: :handbag: top top :pouch: :pouch: :shopping: :shopping: top top :school_satchel: :school_satchel: :thong_sandal: :thong_sandal: top top :mans_shoe: :mans_shoe: :shoe: :athletic_shoe: :athletic_shoe: top top :hiking_boot: :hiking_boot: :flat_shoe: :flat_shoe: top top :high_heel: :high_heel: :sandal: :sandal: top top :ballet_shoes: :ballet_shoes: :boot: :boot: top top :crown: :crown: :womans_hat: :womans_hat: top top :tophat: :tophat: :mortar_board: :mortar_board: top top :billed_cap: :billed_cap: :military_helmet: :military_helmet: top top :rescue_worker_helmet: :rescue_worker_helmet: :prayer_beads: :prayer_beads: top top :lipstick: :lipstick: :ring: :ring: top top :gem: :gem: top Sound ico shortcode ico shortcode top :mute: :mute: :speaker: :speaker: top top :sound: :sound: :loud_sound: :loud_sound: top top :loudspeaker: :loudspeaker: :mega: :mega: top top :postal_horn: :postal_horn: :bell: :bell: top top :no_bell: :no_bell: top Music ico shortcode ico shortcode top :musical_score: :musical_score: :musical_note: :musical_note: top top :notes: :notes: :studio_microphone: :studio_microphone: top top :level_slider: :level_slider: :control_knobs: :control_knobs: top top :microphone: :microphone: :headphones: :headphones: top top :radio: :radio: top Musical Instrument ico shortcode ico shortcode top :saxophone: :saxophone: :accordion: :accordion: top top :guitar: :guitar: :musical_keyboard: :musical_keyboard: top top :trumpet: :trumpet: :violin: :violin: top top :banjo: :banjo: :drum: :drum: top top :long_drum: :long_drum: top Phone ico shortcode ico shortcode top :iphone: :iphone: :calling: :calling: top top :phone: :phone: :telephone: :telephone_receiver: :telephone_receiver: top top :pager: :pager: :fax: :fax: top Computer ico shortcode ico shortcode top :battery: :battery: :electric_plug: :electric_plug: top top :computer: :computer: :desktop_computer: :desktop_computer: top top :printer: :printer: :keyboard: :keyboard: top top :computer_mouse: :computer_mouse: :trackball: :trackball: top top :minidisc: :minidisc: :floppy_disk: :floppy_disk: top top :cd: :cd: :dvd: :dvd: top top :abacus: :abacus: top Light & Video ico shortcode ico shortcode top :movie_camera: :movie_camera: :film_strip: :film_strip: top top :film_projector: :film_projector: :clapper: :clapper: top top :tv: :tv: :camera: :camera: top top :camera_flash: :camera_flash: :video_camera: :video_camera: top top :vhs: :vhs: :mag: :mag: top top :mag_right: :mag_right: :candle: :candle: top top :bulb: :bulb: :flashlight: :flashlight: top top :izakaya_lantern: :izakaya_lantern: :lantern: :diya_lamp: :diya_lamp: top Book Paper ico shortcode ico shortcode top :notebook_with_decorative_cover: :notebook_with_decorative_cover: :closed_book: :closed_book: top top :book: :book: :open_book: :green_book: :green_book: top top :blue_book: :blue_book: :orange_book: :orange_book: top top :books: :books: :notebook: :notebook: top top :ledger: :ledger: :page_with_curl: :page_with_curl: top top :scroll: :scroll: :page_facing_up: :page_facing_up: top top :newspaper: :newspaper: :newspaper_roll: :newspaper_roll: top top :bookmark_tabs: :bookmark_tabs: :bookmark: :bookmark: top top :label: :label: top Money ico shortcode ico shortcode top :moneybag: :moneybag: :coin: :coin: top top :yen: :yen: :dollar: :dollar: top top :euro: :euro: :pound: :pound: top top :money_with_wings: :money_with_wings: :credit_card: :credit_card: top top :receipt: :receipt: :chart: :chart: top Mail ico shortcode ico shortcode top :envelope: :envelope: :e-mail: :e-mail: :email: top top :incoming_envelope: :incoming_envelope: :envelope_with_arrow: :envelope_with_arrow: top top :outbox_tray: :outbox_tray: :inbox_tray: :inbox_tray: top top :package: :package: :mailbox: :mailbox: top top :mailbox_closed: :mailbox_closed: :mailbox_with_mail: :mailbox_with_mail: top top :mailbox_with_no_mail: :mailbox_with_no_mail: :postbox: :postbox: top top :ballot_box: :ballot_box: top Writing ico shortcode ico shortcode top :pencil2: :pencil2: :black_nib: :black_nib: top top :fountain_pen: :fountain_pen: :pen: :pen: top top :paintbrush: :paintbrush: :crayon: :crayon: top top :memo: :memo: :pencil: top Office ico shortcode ico shortcode top :briefcase: :briefcase: :file_folder: :file_folder: top top :open_file_folder: :open_file_folder: :card_index_dividers: :card_index_dividers: top top :date: :date: :calendar: :calendar: top top :spiral_notepad: :spiral_notepad: :spiral_calendar: :spiral_calendar: top top :card_index: :card_index: :chart_with_upwards_trend: :chart_with_upwards_trend: top top :chart_with_downwards_trend: :chart_with_downwards_trend: :bar_chart: :bar_chart: top top :clipboard: :clipboard: :pushpin: :pushpin: top top :round_pushpin: :round_pushpin: :paperclip: :paperclip: top top :paperclips: :paperclips: :straight_ruler: :straight_ruler: top top :triangular_ruler: :triangular_ruler: :scissors: :scissors: top top :card_file_box: :card_file_box: :file_cabinet: :file_cabinet: top top :wastebasket: :wastebasket: top Lock ico shortcode ico shortcode top :lock: :lock: :unlock: :unlock: top top :lock_with_ink_pen: :lock_with_ink_pen: :closed_lock_with_key: :closed_lock_with_key: top top :key: :key: :old_key: :old_key: top Tool ico shortcode ico shortcode top :hammer: :hammer: :axe: :axe: top top :pick: :pick: :hammer_and_pick: :hammer_and_pick: top top :hammer_and_wrench: :hammer_and_wrench: :dagger: :dagger: top top :crossed_swords: :crossed_swords: :gun: :gun: top top :boomerang: :boomerang: :bow_and_arrow: :bow_and_arrow: top top :shield: :shield: :carpentry_saw: :carpentry_saw: top top :wrench: :wrench: :screwdriver: :screwdriver: top top :nut_and_bolt: :nut_and_bolt: :gear: :gear: top top :clamp: :clamp: :balance_scale: :balance_scale: top top :probing_cane: :probing_cane: :link: :link: top top :chains: :chains: :hook: :hook: top top :toolbox: :toolbox: :magnet: :magnet: top top :ladder: :ladder: top Science ico shortcode ico shortcode top :alembic: :alembic: :test_tube: :test_tube: top top :petri_dish: :petri_dish: :dna: :dna: top top :microscope: :microscope: :telescope: :telescope: top top :satellite: :satellite: top Medical ico shortcode ico shortcode top :syringe: :syringe: :drop_of_blood: :drop_of_blood: top top :pill: :pill: :adhesive_bandage: :adhesive_bandage: top top :stethoscope: :stethoscope: top Household ico shortcode ico shortcode top :door: :door: :elevator: :elevator: top top :mirror: :mirror: :window: :window: top top :bed: :bed: :couch_and_lamp: :couch_and_lamp: top top :chair: :chair: :toilet: :toilet: top top :plunger: :plunger: :shower: :shower: top top :bathtub: :bathtub: :mouse_trap: :mouse_trap: top top :razor: :razor: :lotion_bottle: :lotion_bottle: top top :safety_pin: :safety_pin: :broom: :broom: top top :basket: :basket: :roll_of_paper: :roll_of_paper: top top :bucket: :bucket: :soap: :soap: top top :toothbrush: :toothbrush: :sponge: :sponge: top top :fire_extinguisher: :fire_extinguisher: :shopping_cart: :shopping_cart: top Other Object ico shortcode ico shortcode top :smoking: :smoking: :coffin: :coffin: top top :headstone: :headstone: :funeral_urn: :funeral_urn: top top :moyai: :moyai: :placard: :placard: top Symbols Transport Sign Warning Arrow Religion Zodiac Av Symbol Gender Math Punctuation Currency Other Symbol Keycap Alphanum Geometric Transport Sign ico shortcode ico shortcode top :atm: :atm: :put_litter_in_its_place: :put_litter_in_its_place: top top :potable_water: :potable_water: :wheelchair: :wheelchair: top top :mens: :mens: :womens: :womens: top top :restroom: :restroom: :baby_symbol: :baby_symbol: top top :wc: :wc: :passport_control: :passport_control: top top :customs: :customs: :baggage_claim: :baggage_claim: top top :left_luggage: :left_luggage: top Warning ico shortcode ico shortcode top :warning: :warning: :children_crossing: :children_crossing: top top :no_entry: :no_entry: :no_entry_sign: :no_entry_sign: top top :no_bicycles: :no_bicycles: :no_smoking: :no_smoking: top top :do_not_litter: :do_not_litter: :non-potable_water: :non-potable_water: top top :no_pedestrians: :no_pedestrians: :no_mobile_phones: :no_mobile_phones: top top :underage: :underage: :radioactive: :radioactive: top top :biohazard: :biohazard: top Arrow ico shortcode ico shortcode top :arrow_up: :arrow_up: :arrow_upper_right: :arrow_upper_right: top top :arrow_right: :arrow_right: :arrow_lower_right: :arrow_lower_right: top top :arrow_down: :arrow_down: :arrow_lower_left: :arrow_lower_left: top top :arrow_left: :arrow_left: :arrow_upper_left: :arrow_upper_left: top top :arrow_up_down: :arrow_up_down: :left_right_arrow: :left_right_arrow: top top :leftwards_arrow_with_hook: :leftwards_arrow_with_hook: :arrow_right_hook: :arrow_right_hook: top top :arrow_heading_up: :arrow_heading_up: :arrow_heading_down: :arrow_heading_down: top top :arrows_clockwise: :arrows_clockwise: :arrows_counterclockwise: :arrows_counterclockwise: top top :back: :back: :end: :end: top top :on: :on: :soon: :soon: top top :top: :top: top Religion ico shortcode ico shortcode top :place_of_worship: :place_of_worship: :atom_symbol: :atom_symbol: top top :om: :om: :star_of_david: :star_of_david: top top :wheel_of_dharma: :wheel_of_dharma: :yin_yang: :yin_yang: top top :latin_cross: :latin_cross: :orthodox_cross: :orthodox_cross: top top :star_and_crescent: :star_and_crescent: :peace_symbol: :peace_symbol: top top :menorah: :menorah: :six_pointed_star: :six_pointed_star: top Zodiac ico shortcode ico shortcode top :aries: :aries: :taurus: :taurus: top top :gemini: :gemini: :cancer: :cancer: top top :leo: :leo: :virgo: :virgo: top top :libra: :libra: :scorpius: :scorpius: top top :sagittarius: :sagittarius: :capricorn: :capricorn: top top :aquarius: :aquarius: :pisces: :pisces: top top :ophiuchus: :ophiuchus: top Av Symbol ico shortcode ico shortcode top :twisted_rightwards_arrows: :twisted_rightwards_arrows: :repeat: :repeat: top top :repeat_one: :repeat_one: :arrow_forward: :arrow_forward: top top :fast_forward: :fast_forward: :next_track_button: :next_track_button: top top :play_or_pause_button: :play_or_pause_button: :arrow_backward: :arrow_backward: top top :rewind: :rewind: :previous_track_button: :previous_track_button: top top :arrow_up_small: :arrow_up_small: :arrow_double_up: :arrow_double_up: top top :arrow_down_small: :arrow_down_small: :arrow_double_down: :arrow_double_down: top top :pause_button: :pause_button: :stop_button: :stop_button: top top :record_button: :record_button: :eject_button: :eject_button: top top :cinema: :cinema: :low_brightness: :low_brightness: top top :high_brightness: :high_brightness: :signal_strength: :signal_strength: top top :vibration_mode: :vibration_mode: :mobile_phone_off: :mobile_phone_off: top Gender ico shortcode ico shortcode top :female_sign: :female_sign: :male_sign: :male_sign: top top :transgender_symbol: :transgender_symbol: top Math ico shortcode ico shortcode top :heavy_multiplication_x: :heavy_multiplication_x: :heavy_plus_sign: :heavy_plus_sign: top top :heavy_minus_sign: :heavy_minus_sign: :heavy_division_sign: :heavy_division_sign: top top :infinity: :infinity: top Punctuation ico shortcode ico shortcode top :bangbang: :bangbang: :interrobang: :interrobang: top top :question: :question: :grey_question: :grey_question: top top :grey_exclamation: :grey_exclamation: :exclamation: :exclamation: :heavy_exclamation_mark: top top :wavy_dash: :wavy_dash: top Currency ico shortcode ico shortcode top :currency_exchange: :currency_exchange: :heavy_dollar_sign: :heavy_dollar_sign: top Other Symbol ico shortcode ico shortcode top :medical_symbol: :medical_symbol: :recycle: :recycle: top top :fleur_de_lis: :fleur_de_lis: :trident: :trident: top top :name_badge: :name_badge: :beginner: :beginner: top top :o: :o: :white_check_mark: :white_check_mark: top top :ballot_box_with_check: :ballot_box_with_check: :heavy_check_mark: :heavy_check_mark: top top :x: :x: :negative_squared_cross_mark: :negative_squared_cross_mark: top top :curly_loop: :curly_loop: :loop: :loop: top top :part_alternation_mark: :part_alternation_mark: :eight_spoked_asterisk: :eight_spoked_asterisk: top top :eight_pointed_black_star: :eight_pointed_black_star: :sparkle: :sparkle: top top :copyright: :copyright: :registered: :registered: top top :tm: :tm: top Keycap ico shortcode ico shortcode top :hash: :hash: :asterisk: :asterisk: top top :zero: :zero: :one: :one: top top :two: :two: :three: :three: top top :four: :four: :five: :five: top top :six: :six: :seven: :seven: top top :eight: :eight: :nine: :nine: top top :keycap_ten: :keycap_ten: top Alphanum ico shortcode ico shortcode top :capital_abcd: :capital_abcd: :abcd: :abcd: top top :1234: :1234: :symbols: :symbols: top top :abc: :abc: :a: :a: top top :ab: :ab: :b: :b: top top :cl: :cl: :cool: :cool: top top :free: :free: :information_source: :information_source: top top :id: :id: :m: :m: top top :new: :new: :ng: :ng: top top :o2: :o2: :ok: :ok: top top :parking: :parking: :sos: :sos: top top :up: :up: :vs: :vs: top top :koko: :koko: :sa: :sa: top top :u6708: :u6708: :u6709: :u6709: top top :u6307: :u6307: :ideograph_advantage: :ideograph_advantage: top top :u5272: :u5272: :u7121: :u7121: top top :u7981: :u7981: :accept: :accept: top top :u7533: :u7533: :u5408: :u5408: top top :u7a7a: :u7a7a: :congratulations: :congratulations: top top :secret: :secret: :u55b6: :u55b6: top top :u6e80: :u6e80: top Geometric ico shortcode ico shortcode top :red_circle: :red_circle: :orange_circle: :orange_circle: top top :yellow_circle: :yellow_circle: :green_circle: :green_circle: top top :large_blue_circle: :large_blue_circle: :purple_circle: :purple_circle: top top :brown_circle: :brown_circle: :black_circle: :black_circle: top top :white_circle: :white_circle: :red_square: :red_square: top top :orange_square: :orange_square: :yellow_square: :yellow_square: top top :green_square: :green_square: :blue_square: :blue_square: top top :purple_square: :purple_square: :brown_square: :brown_square: top top :black_large_square: :black_large_square: :white_large_square: :white_large_square: top top :black_medium_square: :black_medium_square: :white_medium_square: :white_medium_square: top top :black_medium_small_square: :black_medium_small_square: :white_medium_small_square: :white_medium_small_square: top top :black_small_square: :black_small_square: :white_small_square: :white_small_square: top top :large_orange_diamond: :large_orange_diamond: :large_blue_diamond: :large_blue_diamond: top top :small_orange_diamond: :small_orange_diamond: :small_blue_diamond: :small_blue_diamond: top top :small_red_triangle: :small_red_triangle: :small_red_triangle_down: :small_red_triangle_down: top top :diamond_shape_with_a_dot_inside: :diamond_shape_with_a_dot_inside: :radio_button: :radio_button: top top :white_square_button: :white_square_button: :black_square_button: :black_square_button: top Flags Flag Country Flag Subdivision Flag Flag ico shortcode ico shortcode top :checkered_flag: :checkered_flag: :triangular_flag_on_post: :triangular_flag_on_post: top top :crossed_flags: :crossed_flags: :black_flag: :black_flag: top top :white_flag: :white_flag: :rainbow_flag: :rainbow_flag: top top :transgender_flag: :transgender_flag: :pirate_flag: :pirate_flag: top Country Flag ico shortcode ico shortcode top :ascension_island: :ascension_island: :andorra: :andorra: top top :united_arab_emirates: :united_arab_emirates: :afghanistan: :afghanistan: top top :antigua_barbuda: :antigua_barbuda: :anguilla: :anguilla: top top :albania: :albania: :armenia: :armenia: top top :angola: :angola: :antarctica: :antarctica: top top :argentina: :argentina: :american_samoa: :american_samoa: top top :austria: :austria: :australia: :australia: top top :aruba: :aruba: :aland_islands: :aland_islands: top top :azerbaijan: :azerbaijan: :bosnia_herzegovina: :bosnia_herzegovina: top top :barbados: :barbados: :bangladesh: :bangladesh: top top :belgium: :belgium: :burkina_faso: :burkina_faso: top top :bulgaria: :bulgaria: :bahrain: :bahrain: top top :burundi: :burundi: :benin: :benin: top top :st_barthelemy: :st_barthelemy: :bermuda: :bermuda: top top :brunei: :brunei: :bolivia: :bolivia: top top :caribbean_netherlands: :caribbean_netherlands: :brazil: :brazil: top top :bahamas: :bahamas: :bhutan: :bhutan: top top :bouvet_island: :bouvet_island: :botswana: :botswana: top top :belarus: :belarus: :belize: :belize: top top :canada: :canada: :cocos_islands: :cocos_islands: top top :congo_kinshasa: :congo_kinshasa: :central_african_republic: :central_african_republic: top top :congo_brazzaville: :congo_brazzaville: :switzerland: :switzerland: top top :cote_divoire: :cote_divoire: :cook_islands: :cook_islands: top top :chile: :chile: :cameroon: :cameroon: top top :cn: :cn: :colombia: :colombia: top top :clipperton_island: :clipperton_island: :costa_rica: :costa_rica: top top :cuba: :cuba: :cape_verde: :cape_verde: top top :curacao: :curacao: :christmas_island: :christmas_island: top top :cyprus: :cyprus: :czech_republic: :czech_republic: top top :de: :de: :diego_garcia: :diego_garcia: top top :djibouti: :djibouti: :denmark: :denmark: top top :dominica: :dominica: :dominican_republic: :dominican_republic: top top :algeria: :algeria: :ceuta_melilla: :ceuta_melilla: top top :ecuador: :ecuador: :estonia: :estonia: top top :egypt: :egypt: :western_sahara: :western_sahara: top top :eritrea: :eritrea: :es: :es: top top :ethiopia: :ethiopia: :eu: :eu: :european_union: top top :finland: :finland: :fiji: :fiji: top top :falkland_islands: :falkland_islands: :micronesia: :micronesia: top top :faroe_islands: :faroe_islands: :fr: :fr: top top :gabon: :gabon: :gb: :gb: :uk: top top :grenada: :grenada: :georgia: :georgia: top top :french_guiana: :french_guiana: :guernsey: :guernsey: top top :ghana: :ghana: :gibraltar: :gibraltar: top top :greenland: :greenland: :gambia: :gambia: top top :guinea: :guinea: :guadeloupe: :guadeloupe: top top :equatorial_guinea: :equatorial_guinea: :greece: :greece: top top :south_georgia_south_sandwich_islands: :south_georgia_south_sandwich_islands: :guatemala: :guatemala: top top :guam: :guam: :guinea_bissau: :guinea_bissau: top top :guyana: :guyana: :hong_kong: :hong_kong: top top :heard_mcdonald_islands: :heard_mcdonald_islands: :honduras: :honduras: top top :croatia: :croatia: :haiti: :haiti: top top :hungary: :hungary: :canary_islands: :canary_islands: top top :indonesia: :indonesia: :ireland: :ireland: top top :israel: :israel: :isle_of_man: :isle_of_man: top top :india: :india: :british_indian_ocean_territory: :british_indian_ocean_territory: top top :iraq: :iraq: :iran: :iran: top top :iceland: :iceland: :it: :it: top top :jersey: :jersey: :jamaica: :jamaica: top top :jordan: :jordan: :jp: :jp: top top :kenya: :kenya: :kyrgyzstan: :kyrgyzstan: top top :cambodia: :cambodia: :kiribati: :kiribati: top top :comoros: :comoros: :st_kitts_nevis: :st_kitts_nevis: top top :north_korea: :north_korea: :kr: :kr: top top :kuwait: :kuwait: :cayman_islands: :cayman_islands: top top :kazakhstan: :kazakhstan: :laos: :laos: top top :lebanon: :lebanon: :st_lucia: :st_lucia: top top :liechtenstein: :liechtenstein: :sri_lanka: :sri_lanka: top top :liberia: :liberia: :lesotho: :lesotho: top top :lithuania: :lithuania: :luxembourg: :luxembourg: top top :latvia: :latvia: :libya: :libya: top top :morocco: :morocco: :monaco: :monaco: top top :moldova: :moldova: :montenegro: :montenegro: top top :st_martin: :st_martin: :madagascar: :madagascar: top top :marshall_islands: :marshall_islands: :macedonia: :macedonia: top top :mali: :mali: :myanmar: :myanmar: top top :mongolia: :mongolia: :macau: :macau: top top :northern_mariana_islands: :northern_mariana_islands: :martinique: :martinique: top top :mauritania: :mauritania: :montserrat: :montserrat: top top :malta: :malta: :mauritius: :mauritius: top top :maldives: :maldives: :malawi: :malawi: top top :mexico: :mexico: :malaysia: :malaysia: top top :mozambique: :mozambique: :namibia: :namibia: top top :new_caledonia: :new_caledonia: :niger: :niger: top top :norfolk_island: :norfolk_island: :nigeria: :nigeria: top top :nicaragua: :nicaragua: :netherlands: :netherlands: top top :norway: :norway: :nepal: :nepal: top top :nauru: :nauru: :niue: :niue: top top :new_zealand: :new_zealand: :oman: :oman: top top :panama: :panama: :peru: :peru: top top :french_polynesia: :french_polynesia: :papua_new_guinea: :papua_new_guinea: top top :philippines: :philippines: :pakistan: :pakistan: top top :poland: :poland: :st_pierre_miquelon: :st_pierre_miquelon: top top :pitcairn_islands: :pitcairn_islands: :puerto_rico: :puerto_rico: top top :palestinian_territories: :palestinian_territories: :portugal: :portugal: top top :palau: :palau: :paraguay: :paraguay: top top :qatar: :qatar: :reunion: :reunion: top top :romania: :romania: :serbia: :serbia: top top :ru: :ru: :rwanda: :rwanda: top top :saudi_arabia: :saudi_arabia: :solomon_islands: :solomon_islands: top top :seychelles: :seychelles: :sudan: :sudan: top top :sweden: :sweden: :singapore: :singapore: top top :st_helena: :st_helena: :slovenia: :slovenia: top top :svalbard_jan_mayen: :svalbard_jan_mayen: :slovakia: :slovakia: top top :sierra_leone: :sierra_leone: :san_marino: :san_marino: top top :senegal: :senegal: :somalia: :somalia: top top :suriname: :suriname: :south_sudan: :south_sudan: top top :sao_tome_principe: :sao_tome_principe: :el_salvador: :el_salvador: top top :sint_maarten: :sint_maarten: :syria: :syria: top top :swaziland: :swaziland: :tristan_da_cunha: :tristan_da_cunha: top top :turks_caicos_islands: :turks_caicos_islands: :chad: :chad: top top :french_southern_territories: :french_southern_territories: :togo: :togo: top top :thailand: :thailand: :tajikistan: :tajikistan: top top :tokelau: :tokelau: :timor_leste: :timor_leste: top top :turkmenistan: :turkmenistan: :tunisia: :tunisia: top top :tonga: :tonga: :tr: :tr: top top :trinidad_tobago: :trinidad_tobago: :tuvalu: :tuvalu: top top :taiwan: :taiwan: :tanzania: :tanzania: top top :ukraine: :ukraine: :uganda: :uganda: top top :us_outlying_islands: :us_outlying_islands: :united_nations: :united_nations: top top :us: :us: :uruguay: :uruguay: top top :uzbekistan: :uzbekistan: :vatican_city: :vatican_city: top top :st_vincent_grenadines: :st_vincent_grenadines: :venezuela: :venezuela: top top :british_virgin_islands: :british_virgin_islands: :us_virgin_islands: :us_virgin_islands: top top :vietnam: :vietnam: :vanuatu: :vanuatu: top top :wallis_futuna: :wallis_futuna: :samoa: :samoa: top top :kosovo: :kosovo: :yemen: :yemen: top top :mayotte: :mayotte: :south_africa: :south_africa: top top :zambia: :zambia: :zimbabwe: :zimbabwe: top Subdivision Flag ico shortcode ico shortcode top :england: :england: :scotland: :scotland: top top :wales: :wales: top GitHub Custom Emoji ico shortcode ico shortcode top :atom: :atom: :basecamp: :basecamp: top top :basecampy: :basecampy: :bowtie: :bowtie: top top :electron: :electron: :feelsgood: :feelsgood: top top :finnadie: :finnadie: :goberserk: :goberserk: top top :godmode: :godmode: :hurtrealbad: :hurtrealbad: top top :neckbeard: :neckbeard: :octocat: :octocat: top top :rage1: :rage1: :rage2: :rage2: top top :rage3: :rage3: :rage4: :rage4: top top :shipit: :shipit: :suspect: :suspect: top top :trollface: :trollface: top","title":"markdown emoji list"},{"location":"markdown/emoji_list/#emoji-cheat-sheet","text":"This cheat sheet is automatically generated from GitHub Emoji API and Unicode Full Emoji List .","title":"emoji-cheat-sheet"},{"location":"markdown/emoji_list/#table-of-contents","text":"Smileys & Emotion People & Body Animals & Nature Food & Drink Travel & Places Activities Objects Symbols Flags GitHub Custom Emoji","title":"Table of Contents"},{"location":"markdown/emoji_list/#smileys-emotion","text":"Face Smiling Face Affection Face Tongue Face Hand Face Neutral Skeptical Face Sleepy Face Unwell Face Hat Face Glasses Face Concerned Face Negative Face Costume Cat Face Monkey Face Emotion","title":"Smileys &amp; Emotion"},{"location":"markdown/emoji_list/#face-smiling","text":"ico shortcode ico shortcode top :grinning: :grinning: :smiley: :smiley: top top :smile: :smile: :grin: :grin: top top :laughing: :laughing: :satisfied: :sweat_smile: :sweat_smile: top top :rofl: :rofl: :joy: :joy: top top :slightly_smiling_face: :slightly_smiling_face: :upside_down_face: :upside_down_face: top top :wink: :wink: :blush: :blush: top top :innocent: :innocent: top","title":"Face Smiling"},{"location":"markdown/emoji_list/#face-affection","text":"ico shortcode ico shortcode top :smiling_face_with_three_hearts: :smiling_face_with_three_hearts: :heart_eyes: :heart_eyes: top top :star_struck: :star_struck: :kissing_heart: :kissing_heart: top top :kissing: :kissing: :relaxed: :relaxed: top top :kissing_closed_eyes: :kissing_closed_eyes: :kissing_smiling_eyes: :kissing_smiling_eyes: top top :smiling_face_with_tear: :smiling_face_with_tear: top","title":"Face Affection"},{"location":"markdown/emoji_list/#face-tongue","text":"ico shortcode ico shortcode top :yum: :yum: :stuck_out_tongue: :stuck_out_tongue: top top :stuck_out_tongue_winking_eye: :stuck_out_tongue_winking_eye: :zany_face: :zany_face: top top :stuck_out_tongue_closed_eyes: :stuck_out_tongue_closed_eyes: :money_mouth_face: :money_mouth_face: top","title":"Face Tongue"},{"location":"markdown/emoji_list/#face-hand","text":"ico shortcode ico shortcode top :hugs: :hugs: :hand_over_mouth: :hand_over_mouth: top top :shushing_face: :shushing_face: :thinking: :thinking: top","title":"Face Hand"},{"location":"markdown/emoji_list/#face-neutral-skeptical","text":"ico shortcode ico shortcode top :zipper_mouth_face: :zipper_mouth_face: :raised_eyebrow: :raised_eyebrow: top top :neutral_face: :neutral_face: :expressionless: :expressionless: top top :no_mouth: :no_mouth: :face_in_clouds: :face_in_clouds: top top :smirk: :smirk: :unamused: :unamused: top top :roll_eyes: :roll_eyes: :grimacing: :grimacing: top top :face_exhaling: :face_exhaling: :lying_face: :lying_face: top","title":"Face Neutral Skeptical"},{"location":"markdown/emoji_list/#face-sleepy","text":"ico shortcode ico shortcode top :relieved: :relieved: :pensive: :pensive: top top :sleepy: :sleepy: :drooling_face: :drooling_face: top top :sleeping: :sleeping: top","title":"Face Sleepy"},{"location":"markdown/emoji_list/#face-unwell","text":"ico shortcode ico shortcode top :mask: :mask: :face_with_thermometer: :face_with_thermometer: top top :face_with_head_bandage: :face_with_head_bandage: :nauseated_face: :nauseated_face: top top :vomiting_face: :vomiting_face: :sneezing_face: :sneezing_face: top top :hot_face: :hot_face: :cold_face: :cold_face: top top :woozy_face: :woozy_face: :dizzy_face: :dizzy_face: top top :face_with_spiral_eyes: :face_with_spiral_eyes: :exploding_head: :exploding_head: top","title":"Face Unwell"},{"location":"markdown/emoji_list/#face-hat","text":"ico shortcode ico shortcode top :cowboy_hat_face: :cowboy_hat_face: :partying_face: :partying_face: top top :disguised_face: :disguised_face: top","title":"Face Hat"},{"location":"markdown/emoji_list/#face-glasses","text":"ico shortcode ico shortcode top :sunglasses: :sunglasses: :nerd_face: :nerd_face: top top :monocle_face: :monocle_face: top","title":"Face Glasses"},{"location":"markdown/emoji_list/#face-concerned","text":"ico shortcode ico shortcode top :confused: :confused: :worried: :worried: top top :slightly_frowning_face: :slightly_frowning_face: :frowning_face: :frowning_face: top top :open_mouth: :open_mouth: :hushed: :hushed: top top :astonished: :astonished: :flushed: :flushed: top top :pleading_face: :pleading_face: :frowning: :frowning: top top :anguished: :anguished: :fearful: :fearful: top top :cold_sweat: :cold_sweat: :disappointed_relieved: :disappointed_relieved: top top :cry: :cry: :sob: :sob: top top :scream: :scream: :confounded: :confounded: top top :persevere: :persevere: :disappointed: :disappointed: top top :sweat: :sweat: :weary: :weary: top top :tired_face: :tired_face: :yawning_face: :yawning_face: top","title":"Face Concerned"},{"location":"markdown/emoji_list/#face-negative","text":"ico shortcode ico shortcode top :triumph: :triumph: :pout: :pout: :rage: top top :angry: :angry: :cursing_face: :cursing_face: top top :smiling_imp: :smiling_imp: :imp: :imp: top top :skull: :skull: :skull_and_crossbones: :skull_and_crossbones: top","title":"Face Negative"},{"location":"markdown/emoji_list/#face-costume","text":"ico shortcode ico shortcode top :hankey: :hankey: :poop: :shit: :clown_face: :clown_face: top top :japanese_ogre: :japanese_ogre: :japanese_goblin: :japanese_goblin: top top :ghost: :ghost: :alien: :alien: top top :space_invader: :space_invader: :robot: :robot: top","title":"Face Costume"},{"location":"markdown/emoji_list/#cat-face","text":"ico shortcode ico shortcode top :smiley_cat: :smiley_cat: :smile_cat: :smile_cat: top top :joy_cat: :joy_cat: :heart_eyes_cat: :heart_eyes_cat: top top :smirk_cat: :smirk_cat: :kissing_cat: :kissing_cat: top top :scream_cat: :scream_cat: :crying_cat_face: :crying_cat_face: top top :pouting_cat: :pouting_cat: top","title":"Cat Face"},{"location":"markdown/emoji_list/#monkey-face","text":"ico shortcode ico shortcode top :see_no_evil: :see_no_evil: :hear_no_evil: :hear_no_evil: top top :speak_no_evil: :speak_no_evil: top","title":"Monkey Face"},{"location":"markdown/emoji_list/#emotion","text":"ico shortcode ico shortcode top :kiss: :kiss: :love_letter: :love_letter: top top :cupid: :cupid: :gift_heart: :gift_heart: top top :sparkling_heart: :sparkling_heart: :heartpulse: :heartpulse: top top :heartbeat: :heartbeat: :revolving_hearts: :revolving_hearts: top top :two_hearts: :two_hearts: :heart_decoration: :heart_decoration: top top :heavy_heart_exclamation: :heavy_heart_exclamation: :broken_heart: :broken_heart: top top :heart_on_fire: :heart_on_fire: :mending_heart: :mending_heart: top top :heart: :heart: :orange_heart: :orange_heart: top top :yellow_heart: :yellow_heart: :green_heart: :green_heart: top top :blue_heart: :blue_heart: :purple_heart: :purple_heart: top top :brown_heart: :brown_heart: :black_heart: :black_heart: top top :white_heart: :white_heart: :100: :100: top top :anger: :anger: :boom: :boom: :collision: top top :dizzy: :dizzy: :sweat_drops: :sweat_drops: top top :dash: :dash: :hole: :hole: top top :bomb: :bomb: :speech_balloon: :speech_balloon: top top :eye_speech_bubble: :eye_speech_bubble: :left_speech_bubble: :left_speech_bubble: top top :right_anger_bubble: :right_anger_bubble: :thought_balloon: :thought_balloon: top top :zzz: :zzz: top","title":"Emotion"},{"location":"markdown/emoji_list/#people-body","text":"Hand Fingers Open Hand Fingers Partial Hand Single Finger Hand Fingers Closed Hands Hand Prop Body Parts Person Person Gesture Person Role Person Fantasy Person Activity Person Sport Person Resting Family Person Symbol","title":"People &amp; Body"},{"location":"markdown/emoji_list/#hand-fingers-open","text":"ico shortcode ico shortcode top :wave: :wave: :raised_back_of_hand: :raised_back_of_hand: top top :raised_hand_with_fingers_splayed: :raised_hand_with_fingers_splayed: :hand: :hand: :raised_hand: top top :vulcan_salute: :vulcan_salute: top","title":"Hand Fingers Open"},{"location":"markdown/emoji_list/#hand-fingers-partial","text":"ico shortcode ico shortcode top :ok_hand: :ok_hand: :pinched_fingers: :pinched_fingers: top top :pinching_hand: :pinching_hand: :v: :v: top top :crossed_fingers: :crossed_fingers: :love_you_gesture: :love_you_gesture: top top :metal: :metal: :call_me_hand: :call_me_hand: top","title":"Hand Fingers Partial"},{"location":"markdown/emoji_list/#hand-single-finger","text":"ico shortcode ico shortcode top :point_left: :point_left: :point_right: :point_right: top top :point_up_2: :point_up_2: :fu: :fu: :middle_finger: top top :point_down: :point_down: :point_up: :point_up: top","title":"Hand Single Finger"},{"location":"markdown/emoji_list/#hand-fingers-closed","text":"ico shortcode ico shortcode top :+1: :+1: :thumbsup: :-1: :-1: :thumbsdown: top top :fist: :fist: :fist_raised: :facepunch: :facepunch: :fist_oncoming: :punch: top top :fist_left: :fist_left: :fist_right: :fist_right: top","title":"Hand Fingers Closed"},{"location":"markdown/emoji_list/#hands","text":"ico shortcode ico shortcode top :clap: :clap: :raised_hands: :raised_hands: top top :open_hands: :open_hands: :palms_up_together: :palms_up_together: top top :handshake: :handshake: :pray: :pray: top","title":"Hands"},{"location":"markdown/emoji_list/#hand-prop","text":"ico shortcode ico shortcode top :writing_hand: :writing_hand: :nail_care: :nail_care: top top :selfie: :selfie: top","title":"Hand Prop"},{"location":"markdown/emoji_list/#body-parts","text":"ico shortcode ico shortcode top :muscle: :muscle: :mechanical_arm: :mechanical_arm: top top :mechanical_leg: :mechanical_leg: :leg: :leg: top top :foot: :foot: :ear: :ear: top top :ear_with_hearing_aid: :ear_with_hearing_aid: :nose: :nose: top top :brain: :brain: :anatomical_heart: :anatomical_heart: top top :lungs: :lungs: :tooth: :tooth: top top :bone: :bone: :eyes: :eyes: top top :eye: :eye: :tongue: :tongue: top top :lips: :lips: top","title":"Body Parts"},{"location":"markdown/emoji_list/#person","text":"ico shortcode ico shortcode top :baby: :baby: :child: :child: top top :boy: :boy: :girl: :girl: top top :adult: :adult: :blond_haired_person: :blond_haired_person: top top :man: :man: :bearded_person: :bearded_person: top top :man_beard: :man_beard: :woman_beard: :woman_beard: top top :red_haired_man: :red_haired_man: :curly_haired_man: :curly_haired_man: top top :white_haired_man: :white_haired_man: :bald_man: :bald_man: top top :woman: :woman: :red_haired_woman: :red_haired_woman: top top :person_red_hair: :person_red_hair: :curly_haired_woman: :curly_haired_woman: top top :person_curly_hair: :person_curly_hair: :white_haired_woman: :white_haired_woman: top top :person_white_hair: :person_white_hair: :bald_woman: :bald_woman: top top :person_bald: :person_bald: :blond_haired_woman: :blond_haired_woman: :blonde_woman: top top :blond_haired_man: :blond_haired_man: :older_adult: :older_adult: top top :older_man: :older_man: :older_woman: :older_woman: top","title":"Person"},{"location":"markdown/emoji_list/#person-gesture","text":"ico shortcode ico shortcode top :frowning_person: :frowning_person: :frowning_man: :frowning_man: top top :frowning_woman: :frowning_woman: :pouting_face: :pouting_face: top top :pouting_man: :pouting_man: :pouting_woman: :pouting_woman: top top :no_good: :no_good: :ng_man: :ng_man: :no_good_man: top top :ng_woman: :ng_woman: :no_good_woman: :ok_person: :ok_person: top top :ok_man: :ok_man: :ok_woman: :ok_woman: top top :information_desk_person: :information_desk_person: :tipping_hand_person: :sassy_man: :sassy_man: :tipping_hand_man: top top :sassy_woman: :sassy_woman: :tipping_hand_woman: :raising_hand: :raising_hand: top top :raising_hand_man: :raising_hand_man: :raising_hand_woman: :raising_hand_woman: top top :deaf_person: :deaf_person: :deaf_man: :deaf_man: top top :deaf_woman: :deaf_woman: :bow: :bow: top top :bowing_man: :bowing_man: :bowing_woman: :bowing_woman: top top :facepalm: :facepalm: :man_facepalming: :man_facepalming: top top :woman_facepalming: :woman_facepalming: :shrug: :shrug: top top :man_shrugging: :man_shrugging: :woman_shrugging: :woman_shrugging: top","title":"Person Gesture"},{"location":"markdown/emoji_list/#person-role","text":"ico shortcode ico shortcode top :health_worker: :health_worker: :man_health_worker: :man_health_worker: top top :woman_health_worker: :woman_health_worker: :student: :student: top top :man_student: :man_student: :woman_student: :woman_student: top top :teacher: :teacher: :man_teacher: :man_teacher: top top :woman_teacher: :woman_teacher: :judge: :judge: top top :man_judge: :man_judge: :woman_judge: :woman_judge: top top :farmer: :farmer: :man_farmer: :man_farmer: top top :woman_farmer: :woman_farmer: :cook: :cook: top top :man_cook: :man_cook: :woman_cook: :woman_cook: top top :mechanic: :mechanic: :man_mechanic: :man_mechanic: top top :woman_mechanic: :woman_mechanic: :factory_worker: :factory_worker: top top :man_factory_worker: :man_factory_worker: :woman_factory_worker: :woman_factory_worker: top top :office_worker: :office_worker: :man_office_worker: :man_office_worker: top top :woman_office_worker: :woman_office_worker: :scientist: :scientist: top top :man_scientist: :man_scientist: :woman_scientist: :woman_scientist: top top :technologist: :technologist: :man_technologist: :man_technologist: top top :woman_technologist: :woman_technologist: :singer: :singer: top top :man_singer: :man_singer: :woman_singer: :woman_singer: top top :artist: :artist: :man_artist: :man_artist: top top :woman_artist: :woman_artist: :pilot: :pilot: top top :man_pilot: :man_pilot: :woman_pilot: :woman_pilot: top top :astronaut: :astronaut: :man_astronaut: :man_astronaut: top top :woman_astronaut: :woman_astronaut: :firefighter: :firefighter: top top :man_firefighter: :man_firefighter: :woman_firefighter: :woman_firefighter: top top :cop: :cop: :police_officer: :policeman: :policeman: top top :policewoman: :policewoman: :detective: :detective: top top :male_detective: :male_detective: :female_detective: :female_detective: top top :guard: :guard: :guardsman: :guardsman: top top :guardswoman: :guardswoman: :ninja: :ninja: top top :construction_worker: :construction_worker: :construction_worker_man: :construction_worker_man: top top :construction_worker_woman: :construction_worker_woman: :prince: :prince: top top :princess: :princess: :person_with_turban: :person_with_turban: top top :man_with_turban: :man_with_turban: :woman_with_turban: :woman_with_turban: top top :man_with_gua_pi_mao: :man_with_gua_pi_mao: :woman_with_headscarf: :woman_with_headscarf: top top :person_in_tuxedo: :person_in_tuxedo: :man_in_tuxedo: :man_in_tuxedo: top top :woman_in_tuxedo: :woman_in_tuxedo: :person_with_veil: :person_with_veil: top top :man_with_veil: :man_with_veil: :bride_with_veil: :bride_with_veil: :woman_with_veil: top top :pregnant_woman: :pregnant_woman: :breast_feeding: :breast_feeding: top top :woman_feeding_baby: :woman_feeding_baby: :man_feeding_baby: :man_feeding_baby: top top :person_feeding_baby: :person_feeding_baby: top","title":"Person Role"},{"location":"markdown/emoji_list/#person-fantasy","text":"ico shortcode ico shortcode top :angel: :angel: :santa: :santa: top top :mrs_claus: :mrs_claus: :mx_claus: :mx_claus: top top :superhero: :superhero: :superhero_man: :superhero_man: top top :superhero_woman: :superhero_woman: :supervillain: :supervillain: top top :supervillain_man: :supervillain_man: :supervillain_woman: :supervillain_woman: top top :mage: :mage: :mage_man: :mage_man: top top :mage_woman: :mage_woman: :fairy: :fairy: top top :fairy_man: :fairy_man: :fairy_woman: :fairy_woman: top top :vampire: :vampire: :vampire_man: :vampire_man: top top :vampire_woman: :vampire_woman: :merperson: :merperson: top top :merman: :merman: :mermaid: :mermaid: top top :elf: :elf: :elf_man: :elf_man: top top :elf_woman: :elf_woman: :genie: :genie: top top :genie_man: :genie_man: :genie_woman: :genie_woman: top top :zombie: :zombie: :zombie_man: :zombie_man: top top :zombie_woman: :zombie_woman: top","title":"Person Fantasy"},{"location":"markdown/emoji_list/#person-activity","text":"ico shortcode ico shortcode top :massage: :massage: :massage_man: :massage_man: top top :massage_woman: :massage_woman: :haircut: :haircut: top top :haircut_man: :haircut_man: :haircut_woman: :haircut_woman: top top :walking: :walking: :walking_man: :walking_man: top top :walking_woman: :walking_woman: :standing_person: :standing_person: top top :standing_man: :standing_man: :standing_woman: :standing_woman: top top :kneeling_person: :kneeling_person: :kneeling_man: :kneeling_man: top top :kneeling_woman: :kneeling_woman: :person_with_probing_cane: :person_with_probing_cane: top top :man_with_probing_cane: :man_with_probing_cane: :woman_with_probing_cane: :woman_with_probing_cane: top top :person_in_motorized_wheelchair: :person_in_motorized_wheelchair: :man_in_motorized_wheelchair: :man_in_motorized_wheelchair: top top :woman_in_motorized_wheelchair: :woman_in_motorized_wheelchair: :person_in_manual_wheelchair: :person_in_manual_wheelchair: top top :man_in_manual_wheelchair: :man_in_manual_wheelchair: :woman_in_manual_wheelchair: :woman_in_manual_wheelchair: top top :runner: :runner: :running: :running_man: :running_man: top top :running_woman: :running_woman: :dancer: :dancer: :woman_dancing: top top :man_dancing: :man_dancing: :business_suit_levitating: :business_suit_levitating: top top :dancers: :dancers: :dancing_men: :dancing_men: top top :dancing_women: :dancing_women: :sauna_person: :sauna_person: top top :sauna_man: :sauna_man: :sauna_woman: :sauna_woman: top top :climbing: :climbing: :climbing_man: :climbing_man: top top :climbing_woman: :climbing_woman: top","title":"Person Activity"},{"location":"markdown/emoji_list/#person-sport","text":"ico shortcode ico shortcode top :person_fencing: :person_fencing: :horse_racing: :horse_racing: top top :skier: :skier: :snowboarder: :snowboarder: top top :golfing: :golfing: :golfing_man: :golfing_man: top top :golfing_woman: :golfing_woman: :surfer: :surfer: top top :surfing_man: :surfing_man: :surfing_woman: :surfing_woman: top top :rowboat: :rowboat: :rowing_man: :rowing_man: top top :rowing_woman: :rowing_woman: :swimmer: :swimmer: top top :swimming_man: :swimming_man: :swimming_woman: :swimming_woman: top top :bouncing_ball_person: :bouncing_ball_person: :basketball_man: :basketball_man: :bouncing_ball_man: top top :basketball_woman: :basketball_woman: :bouncing_ball_woman: :weight_lifting: :weight_lifting: top top :weight_lifting_man: :weight_lifting_man: :weight_lifting_woman: :weight_lifting_woman: top top :bicyclist: :bicyclist: :biking_man: :biking_man: top top :biking_woman: :biking_woman: :mountain_bicyclist: :mountain_bicyclist: top top :mountain_biking_man: :mountain_biking_man: :mountain_biking_woman: :mountain_biking_woman: top top :cartwheeling: :cartwheeling: :man_cartwheeling: :man_cartwheeling: top top :woman_cartwheeling: :woman_cartwheeling: :wrestling: :wrestling: top top :men_wrestling: :men_wrestling: :women_wrestling: :women_wrestling: top top :water_polo: :water_polo: :man_playing_water_polo: :man_playing_water_polo: top top :woman_playing_water_polo: :woman_playing_water_polo: :handball_person: :handball_person: top top :man_playing_handball: :man_playing_handball: :woman_playing_handball: :woman_playing_handball: top top :juggling_person: :juggling_person: :man_juggling: :man_juggling: top top :woman_juggling: :woman_juggling: top","title":"Person Sport"},{"location":"markdown/emoji_list/#person-resting","text":"ico shortcode ico shortcode top :lotus_position: :lotus_position: :lotus_position_man: :lotus_position_man: top top :lotus_position_woman: :lotus_position_woman: :bath: :bath: top top :sleeping_bed: :sleeping_bed: top","title":"Person Resting"},{"location":"markdown/emoji_list/#family","text":"ico shortcode ico shortcode top :people_holding_hands: :people_holding_hands: :two_women_holding_hands: :two_women_holding_hands: top top :couple: :couple: :two_men_holding_hands: :two_men_holding_hands: top top :couplekiss: :couplekiss: :couplekiss_man_woman: :couplekiss_man_woman: top top :couplekiss_man_man: :couplekiss_man_man: :couplekiss_woman_woman: :couplekiss_woman_woman: top top :couple_with_heart: :couple_with_heart: :couple_with_heart_woman_man: :couple_with_heart_woman_man: top top :couple_with_heart_man_man: :couple_with_heart_man_man: :couple_with_heart_woman_woman: :couple_with_heart_woman_woman: top top :family: :family: :family_man_woman_boy: :family_man_woman_boy: top top :family_man_woman_girl: :family_man_woman_girl: :family_man_woman_girl_boy: :family_man_woman_girl_boy: top top :family_man_woman_boy_boy: :family_man_woman_boy_boy: :family_man_woman_girl_girl: :family_man_woman_girl_girl: top top :family_man_man_boy: :family_man_man_boy: :family_man_man_girl: :family_man_man_girl: top top :family_man_man_girl_boy: :family_man_man_girl_boy: :family_man_man_boy_boy: :family_man_man_boy_boy: top top :family_man_man_girl_girl: :family_man_man_girl_girl: :family_woman_woman_boy: :family_woman_woman_boy: top top :family_woman_woman_girl: :family_woman_woman_girl: :family_woman_woman_girl_boy: :family_woman_woman_girl_boy: top top :family_woman_woman_boy_boy: :family_woman_woman_boy_boy: :family_woman_woman_girl_girl: :family_woman_woman_girl_girl: top top :family_man_boy: :family_man_boy: :family_man_boy_boy: :family_man_boy_boy: top top :family_man_girl: :family_man_girl: :family_man_girl_boy: :family_man_girl_boy: top top :family_man_girl_girl: :family_man_girl_girl: :family_woman_boy: :family_woman_boy: top top :family_woman_boy_boy: :family_woman_boy_boy: :family_woman_girl: :family_woman_girl: top top :family_woman_girl_boy: :family_woman_girl_boy: :family_woman_girl_girl: :family_woman_girl_girl: top","title":"Family"},{"location":"markdown/emoji_list/#person-symbol","text":"ico shortcode ico shortcode top :speaking_head: :speaking_head: :bust_in_silhouette: :bust_in_silhouette: top top :busts_in_silhouette: :busts_in_silhouette: :people_hugging: :people_hugging: top top :footprints: :footprints: top","title":"Person Symbol"},{"location":"markdown/emoji_list/#animals-nature","text":"Animal Mammal Animal Bird Animal Amphibian Animal Reptile Animal Marine Animal Bug Plant Flower Plant Other","title":"Animals &amp; Nature"},{"location":"markdown/emoji_list/#animal-mammal","text":"ico shortcode ico shortcode top :monkey_face: :monkey_face: :monkey: :monkey: top top :gorilla: :gorilla: :orangutan: :orangutan: top top :dog: :dog: :dog2: :dog2: top top :guide_dog: :guide_dog: :service_dog: :service_dog: top top :poodle: :poodle: :wolf: :wolf: top top :fox_face: :fox_face: :raccoon: :raccoon: top top :cat: :cat: :cat2: :cat2: top top :black_cat: :black_cat: :lion: :lion: top top :tiger: :tiger: :tiger2: :tiger2: top top :leopard: :leopard: :horse: :horse: top top :racehorse: :racehorse: :unicorn: :unicorn: top top :zebra: :zebra: :deer: :deer: top top :bison: :bison: :cow: :cow: top top :ox: :ox: :water_buffalo: :water_buffalo: top top :cow2: :cow2: :pig: :pig: top top :pig2: :pig2: :boar: :boar: top top :pig_nose: :pig_nose: :ram: :ram: top top :sheep: :sheep: :goat: :goat: top top :dromedary_camel: :dromedary_camel: :camel: :camel: top top :llama: :llama: :giraffe: :giraffe: top top :elephant: :elephant: :mammoth: :mammoth: top top :rhinoceros: :rhinoceros: :hippopotamus: :hippopotamus: top top :mouse: :mouse: :mouse2: :mouse2: top top :rat: :rat: :hamster: :hamster: top top :rabbit: :rabbit: :rabbit2: :rabbit2: top top :chipmunk: :chipmunk: :beaver: :beaver: top top :hedgehog: :hedgehog: :bat: :bat: top top :bear: :bear: :polar_bear: :polar_bear: top top :koala: :koala: :panda_face: :panda_face: top top :sloth: :sloth: :otter: :otter: top top :skunk: :skunk: :kangaroo: :kangaroo: top top :badger: :badger: :feet: :feet: :paw_prints: top","title":"Animal Mammal"},{"location":"markdown/emoji_list/#animal-bird","text":"ico shortcode ico shortcode top :turkey: :turkey: :chicken: :chicken: top top :rooster: :rooster: :hatching_chick: :hatching_chick: top top :baby_chick: :baby_chick: :hatched_chick: :hatched_chick: top top :bird: :bird: :penguin: :penguin: top top :dove: :dove: :eagle: :eagle: top top :duck: :duck: :swan: :swan: top top :owl: :owl: :dodo: :dodo: top top :feather: :feather: :flamingo: :flamingo: top top :peacock: :peacock: :parrot: :parrot: top","title":"Animal Bird"},{"location":"markdown/emoji_list/#animal-amphibian","text":"ico shortcode top :frog: :frog: top","title":"Animal Amphibian"},{"location":"markdown/emoji_list/#animal-reptile","text":"ico shortcode ico shortcode top :crocodile: :crocodile: :turtle: :turtle: top top :lizard: :lizard: :snake: :snake: top top :dragon_face: :dragon_face: :dragon: :dragon: top top :sauropod: :sauropod: :t-rex: :t-rex: top","title":"Animal Reptile"},{"location":"markdown/emoji_list/#animal-marine","text":"ico shortcode ico shortcode top :whale: :whale: :whale2: :whale2: top top :dolphin: :dolphin: :flipper: :seal: :seal: top top :fish: :fish: :tropical_fish: :tropical_fish: top top :blowfish: :blowfish: :shark: :shark: top top :octopus: :octopus: :shell: :shell: top","title":"Animal Marine"},{"location":"markdown/emoji_list/#animal-bug","text":"ico shortcode ico shortcode top :snail: :snail: :butterfly: :butterfly: top top :bug: :bug: :ant: :ant: top top :bee: :bee: :honeybee: :beetle: :beetle: top top :lady_beetle: :lady_beetle: :cricket: :cricket: top top :cockroach: :cockroach: :spider: :spider: top top :spider_web: :spider_web: :scorpion: :scorpion: top top :mosquito: :mosquito: :fly: :fly: top top :worm: :worm: :microbe: :microbe: top","title":"Animal Bug"},{"location":"markdown/emoji_list/#plant-flower","text":"ico shortcode ico shortcode top :bouquet: :bouquet: :cherry_blossom: :cherry_blossom: top top :white_flower: :white_flower: :rosette: :rosette: top top :rose: :rose: :wilted_flower: :wilted_flower: top top :hibiscus: :hibiscus: :sunflower: :sunflower: top top :blossom: :blossom: :tulip: :tulip: top","title":"Plant Flower"},{"location":"markdown/emoji_list/#plant-other","text":"ico shortcode ico shortcode top :seedling: :seedling: :potted_plant: :potted_plant: top top :evergreen_tree: :evergreen_tree: :deciduous_tree: :deciduous_tree: top top :palm_tree: :palm_tree: :cactus: :cactus: top top :ear_of_rice: :ear_of_rice: :herb: :herb: top top :shamrock: :shamrock: :four_leaf_clover: :four_leaf_clover: top top :maple_leaf: :maple_leaf: :fallen_leaf: :fallen_leaf: top top :leaves: :leaves: top","title":"Plant Other"},{"location":"markdown/emoji_list/#food-drink","text":"Food Fruit Food Vegetable Food Prepared Food Asian Food Marine Food Sweet Drink Dishware","title":"Food &amp; Drink"},{"location":"markdown/emoji_list/#food-fruit","text":"ico shortcode ico shortcode top :grapes: :grapes: :melon: :melon: top top :watermelon: :watermelon: :mandarin: :mandarin: :orange: :tangerine: top top :lemon: :lemon: :banana: :banana: top top :pineapple: :pineapple: :mango: :mango: top top :apple: :apple: :green_apple: :green_apple: top top :pear: :pear: :peach: :peach: top top :cherries: :cherries: :strawberry: :strawberry: top top :blueberries: :blueberries: :kiwi_fruit: :kiwi_fruit: top top :tomato: :tomato: :olive: :olive: top top :coconut: :coconut: top","title":"Food Fruit"},{"location":"markdown/emoji_list/#food-vegetable","text":"ico shortcode ico shortcode top :avocado: :avocado: :eggplant: :eggplant: top top :potato: :potato: :carrot: :carrot: top top :corn: :corn: :hot_pepper: :hot_pepper: top top :bell_pepper: :bell_pepper: :cucumber: :cucumber: top top :leafy_green: :leafy_green: :broccoli: :broccoli: top top :garlic: :garlic: :onion: :onion: top top :mushroom: :mushroom: :peanuts: :peanuts: top top :chestnut: :chestnut: top","title":"Food Vegetable"},{"location":"markdown/emoji_list/#food-prepared","text":"ico shortcode ico shortcode top :bread: :bread: :croissant: :croissant: top top :baguette_bread: :baguette_bread: :flatbread: :flatbread: top top :pretzel: :pretzel: :bagel: :bagel: top top :pancakes: :pancakes: :waffle: :waffle: top top :cheese: :cheese: :meat_on_bone: :meat_on_bone: top top :poultry_leg: :poultry_leg: :cut_of_meat: :cut_of_meat: top top :bacon: :bacon: :hamburger: :hamburger: top top :fries: :fries: :pizza: :pizza: top top :hotdog: :hotdog: :sandwich: :sandwich: top top :taco: :taco: :burrito: :burrito: top top :tamale: :tamale: :stuffed_flatbread: :stuffed_flatbread: top top :falafel: :falafel: :egg: :egg: top top :fried_egg: :fried_egg: :shallow_pan_of_food: :shallow_pan_of_food: top top :stew: :stew: :fondue: :fondue: top top :bowl_with_spoon: :bowl_with_spoon: :green_salad: :green_salad: top top :popcorn: :popcorn: :butter: :butter: top top :salt: :salt: :canned_food: :canned_food: top","title":"Food Prepared"},{"location":"markdown/emoji_list/#food-asian","text":"ico shortcode ico shortcode top :bento: :bento: :rice_cracker: :rice_cracker: top top :rice_ball: :rice_ball: :rice: :rice: top top :curry: :curry: :ramen: :ramen: top top :spaghetti: :spaghetti: :sweet_potato: :sweet_potato: top top :oden: :oden: :sushi: :sushi: top top :fried_shrimp: :fried_shrimp: :fish_cake: :fish_cake: top top :moon_cake: :moon_cake: :dango: :dango: top top :dumpling: :dumpling: :fortune_cookie: :fortune_cookie: top top :takeout_box: :takeout_box: top","title":"Food Asian"},{"location":"markdown/emoji_list/#food-marine","text":"ico shortcode ico shortcode top :crab: :crab: :lobster: :lobster: top top :shrimp: :shrimp: :squid: :squid: top top :oyster: :oyster: top","title":"Food Marine"},{"location":"markdown/emoji_list/#food-sweet","text":"ico shortcode ico shortcode top :icecream: :icecream: :shaved_ice: :shaved_ice: top top :ice_cream: :ice_cream: :doughnut: :doughnut: top top :cookie: :cookie: :birthday: :birthday: top top :cake: :cake: :cupcake: :cupcake: top top :pie: :pie: :chocolate_bar: :chocolate_bar: top top :candy: :candy: :lollipop: :lollipop: top top :custard: :custard: :honey_pot: :honey_pot: top","title":"Food Sweet"},{"location":"markdown/emoji_list/#drink","text":"ico shortcode ico shortcode top :baby_bottle: :baby_bottle: :milk_glass: :milk_glass: top top :coffee: :coffee: :teapot: :teapot: top top :tea: :tea: :sake: :sake: top top :champagne: :champagne: :wine_glass: :wine_glass: top top :cocktail: :cocktail: :tropical_drink: :tropical_drink: top top :beer: :beer: :beers: :beers: top top :clinking_glasses: :clinking_glasses: :tumbler_glass: :tumbler_glass: top top :cup_with_straw: :cup_with_straw: :bubble_tea: :bubble_tea: top top :beverage_box: :beverage_box: :mate: :mate: top top :ice_cube: :ice_cube: top","title":"Drink"},{"location":"markdown/emoji_list/#dishware","text":"ico shortcode ico shortcode top :chopsticks: :chopsticks: :plate_with_cutlery: :plate_with_cutlery: top top :fork_and_knife: :fork_and_knife: :spoon: :spoon: top top :hocho: :hocho: :knife: :amphora: :amphora: top","title":"Dishware"},{"location":"markdown/emoji_list/#travel-places","text":"Place Map Place Geographic Place Building Place Religious Place Other Transport Ground Transport Water Transport Air Hotel Time Sky & Weather","title":"Travel &amp; Places"},{"location":"markdown/emoji_list/#place-map","text":"ico shortcode ico shortcode top :earth_africa: :earth_africa: :earth_americas: :earth_americas: top top :earth_asia: :earth_asia: :globe_with_meridians: :globe_with_meridians: top top :world_map: :world_map: :japan: :japan: top top :compass: :compass: top","title":"Place Map"},{"location":"markdown/emoji_list/#place-geographic","text":"ico shortcode ico shortcode top :mountain_snow: :mountain_snow: :mountain: :mountain: top top :volcano: :volcano: :mount_fuji: :mount_fuji: top top :camping: :camping: :beach_umbrella: :beach_umbrella: top top :desert: :desert: :desert_island: :desert_island: top top :national_park: :national_park: top","title":"Place Geographic"},{"location":"markdown/emoji_list/#place-building","text":"ico shortcode ico shortcode top :stadium: :stadium: :classical_building: :classical_building: top top :building_construction: :building_construction: :bricks: :bricks: top top :rock: :rock: :wood: :wood: top top :hut: :hut: :houses: :houses: top top :derelict_house: :derelict_house: :house: :house: top top :house_with_garden: :house_with_garden: :office: :office: top top :post_office: :post_office: :european_post_office: :european_post_office: top top :hospital: :hospital: :bank: :bank: top top :hotel: :hotel: :love_hotel: :love_hotel: top top :convenience_store: :convenience_store: :school: :school: top top :department_store: :department_store: :factory: :factory: top top :japanese_castle: :japanese_castle: :european_castle: :european_castle: top top :wedding: :wedding: :tokyo_tower: :tokyo_tower: top top :statue_of_liberty: :statue_of_liberty: top","title":"Place Building"},{"location":"markdown/emoji_list/#place-religious","text":"ico shortcode ico shortcode top :church: :church: :mosque: :mosque: top top :hindu_temple: :hindu_temple: :synagogue: :synagogue: top top :shinto_shrine: :shinto_shrine: :kaaba: :kaaba: top","title":"Place Religious"},{"location":"markdown/emoji_list/#place-other","text":"ico shortcode ico shortcode top :fountain: :fountain: :tent: :tent: top top :foggy: :foggy: :night_with_stars: :night_with_stars: top top :cityscape: :cityscape: :sunrise_over_mountains: :sunrise_over_mountains: top top :sunrise: :sunrise: :city_sunset: :city_sunset: top top :city_sunrise: :city_sunrise: :bridge_at_night: :bridge_at_night: top top :hotsprings: :hotsprings: :carousel_horse: :carousel_horse: top top :ferris_wheel: :ferris_wheel: :roller_coaster: :roller_coaster: top top :barber: :barber: :circus_tent: :circus_tent: top","title":"Place Other"},{"location":"markdown/emoji_list/#transport-ground","text":"ico shortcode ico shortcode top :steam_locomotive: :steam_locomotive: :railway_car: :railway_car: top top :bullettrain_side: :bullettrain_side: :bullettrain_front: :bullettrain_front: top top :train2: :train2: :metro: :metro: top top :light_rail: :light_rail: :station: :station: top top :tram: :tram: :monorail: :monorail: top top :mountain_railway: :mountain_railway: :train: :train: top top :bus: :bus: :oncoming_bus: :oncoming_bus: top top :trolleybus: :trolleybus: :minibus: :minibus: top top :ambulance: :ambulance: :fire_engine: :fire_engine: top top :police_car: :police_car: :oncoming_police_car: :oncoming_police_car: top top :taxi: :taxi: :oncoming_taxi: :oncoming_taxi: top top :car: :car: :red_car: :oncoming_automobile: :oncoming_automobile: top top :blue_car: :blue_car: :pickup_truck: :pickup_truck: top top :truck: :truck: :articulated_lorry: :articulated_lorry: top top :tractor: :tractor: :racing_car: :racing_car: top top :motorcycle: :motorcycle: :motor_scooter: :motor_scooter: top top :manual_wheelchair: :manual_wheelchair: :motorized_wheelchair: :motorized_wheelchair: top top :auto_rickshaw: :auto_rickshaw: :bike: :bike: top top :kick_scooter: :kick_scooter: :skateboard: :skateboard: top top :roller_skate: :roller_skate: :busstop: :busstop: top top :motorway: :motorway: :railway_track: :railway_track: top top :oil_drum: :oil_drum: :fuelpump: :fuelpump: top top :rotating_light: :rotating_light: :traffic_light: :traffic_light: top top :vertical_traffic_light: :vertical_traffic_light: :stop_sign: :stop_sign: top top :construction: :construction: top","title":"Transport Ground"},{"location":"markdown/emoji_list/#transport-water","text":"ico shortcode ico shortcode top :anchor: :anchor: :boat: :boat: :sailboat: top top :canoe: :canoe: :speedboat: :speedboat: top top :passenger_ship: :passenger_ship: :ferry: :ferry: top top :motor_boat: :motor_boat: :ship: :ship: top","title":"Transport Water"},{"location":"markdown/emoji_list/#transport-air","text":"ico shortcode ico shortcode top :airplane: :airplane: :small_airplane: :small_airplane: top top :flight_departure: :flight_departure: :flight_arrival: :flight_arrival: top top :parachute: :parachute: :seat: :seat: top top :helicopter: :helicopter: :suspension_railway: :suspension_railway: top top :mountain_cableway: :mountain_cableway: :aerial_tramway: :aerial_tramway: top top :artificial_satellite: :artificial_satellite: :rocket: :rocket: top top :flying_saucer: :flying_saucer: top","title":"Transport Air"},{"location":"markdown/emoji_list/#hotel","text":"ico shortcode ico shortcode top :bellhop_bell: :bellhop_bell: :luggage: :luggage: top","title":"Hotel"},{"location":"markdown/emoji_list/#time","text":"ico shortcode ico shortcode top :hourglass: :hourglass: :hourglass_flowing_sand: :hourglass_flowing_sand: top top :watch: :watch: :alarm_clock: :alarm_clock: top top :stopwatch: :stopwatch: :timer_clock: :timer_clock: top top :mantelpiece_clock: :mantelpiece_clock: :clock12: :clock12: top top :clock1230: :clock1230: :clock1: :clock1: top top :clock130: :clock130: :clock2: :clock2: top top :clock230: :clock230: :clock3: :clock3: top top :clock330: :clock330: :clock4: :clock4: top top :clock430: :clock430: :clock5: :clock5: top top :clock530: :clock530: :clock6: :clock6: top top :clock630: :clock630: :clock7: :clock7: top top :clock730: :clock730: :clock8: :clock8: top top :clock830: :clock830: :clock9: :clock9: top top :clock930: :clock930: :clock10: :clock10: top top :clock1030: :clock1030: :clock11: :clock11: top top :clock1130: :clock1130: top","title":"Time"},{"location":"markdown/emoji_list/#sky-weather","text":"ico shortcode ico shortcode top :new_moon: :new_moon: :waxing_crescent_moon: :waxing_crescent_moon: top top :first_quarter_moon: :first_quarter_moon: :moon: :moon: :waxing_gibbous_moon: top top :full_moon: :full_moon: :waning_gibbous_moon: :waning_gibbous_moon: top top :last_quarter_moon: :last_quarter_moon: :waning_crescent_moon: :waning_crescent_moon: top top :crescent_moon: :crescent_moon: :new_moon_with_face: :new_moon_with_face: top top :first_quarter_moon_with_face: :first_quarter_moon_with_face: :last_quarter_moon_with_face: :last_quarter_moon_with_face: top top :thermometer: :thermometer: :sunny: :sunny: top top :full_moon_with_face: :full_moon_with_face: :sun_with_face: :sun_with_face: top top :ringed_planet: :ringed_planet: :star: :star: top top :star2: :star2: :stars: :stars: top top :milky_way: :milky_way: :cloud: :cloud: top top :partly_sunny: :partly_sunny: :cloud_with_lightning_and_rain: :cloud_with_lightning_and_rain: top top :sun_behind_small_cloud: :sun_behind_small_cloud: :sun_behind_large_cloud: :sun_behind_large_cloud: top top :sun_behind_rain_cloud: :sun_behind_rain_cloud: :cloud_with_rain: :cloud_with_rain: top top :cloud_with_snow: :cloud_with_snow: :cloud_with_lightning: :cloud_with_lightning: top top :tornado: :tornado: :fog: :fog: top top :wind_face: :wind_face: :cyclone: :cyclone: top top :rainbow: :rainbow: :closed_umbrella: :closed_umbrella: top top :open_umbrella: :open_umbrella: :umbrella: :umbrella: top top :parasol_on_ground: :parasol_on_ground: :zap: :zap: top top :snowflake: :snowflake: :snowman_with_snow: :snowman_with_snow: top top :snowman: :snowman: :comet: :comet: top top :fire: :fire: :droplet: :droplet: top top :ocean: :ocean: top","title":"Sky &amp; Weather"},{"location":"markdown/emoji_list/#activities","text":"Event Award Medal Sport Game Arts & Crafts","title":"Activities"},{"location":"markdown/emoji_list/#event","text":"ico shortcode ico shortcode top :jack_o_lantern: :jack_o_lantern: :christmas_tree: :christmas_tree: top top :fireworks: :fireworks: :sparkler: :sparkler: top top :firecracker: :firecracker: :sparkles: :sparkles: top top :balloon: :balloon: :tada: :tada: top top :confetti_ball: :confetti_ball: :tanabata_tree: :tanabata_tree: top top :bamboo: :bamboo: :dolls: :dolls: top top :flags: :flags: :wind_chime: :wind_chime: top top :rice_scene: :rice_scene: :red_envelope: :red_envelope: top top :ribbon: :ribbon: :gift: :gift: top top :reminder_ribbon: :reminder_ribbon: :tickets: :tickets: top top :ticket: :ticket: top","title":"Event"},{"location":"markdown/emoji_list/#award-medal","text":"ico shortcode ico shortcode top :medal_military: :medal_military: :trophy: :trophy: top top :medal_sports: :medal_sports: :1st_place_medal: :1st_place_medal: top top :2nd_place_medal: :2nd_place_medal: :3rd_place_medal: :3rd_place_medal: top","title":"Award Medal"},{"location":"markdown/emoji_list/#sport","text":"ico shortcode ico shortcode top :soccer: :soccer: :baseball: :baseball: top top :softball: :softball: :basketball: :basketball: top top :volleyball: :volleyball: :football: :football: top top :rugby_football: :rugby_football: :tennis: :tennis: top top :flying_disc: :flying_disc: :bowling: :bowling: top top :cricket_game: :cricket_game: :field_hockey: :field_hockey: top top :ice_hockey: :ice_hockey: :lacrosse: :lacrosse: top top :ping_pong: :ping_pong: :badminton: :badminton: top top :boxing_glove: :boxing_glove: :martial_arts_uniform: :martial_arts_uniform: top top :goal_net: :goal_net: :golf: :golf: top top :ice_skate: :ice_skate: :fishing_pole_and_fish: :fishing_pole_and_fish: top top :diving_mask: :diving_mask: :running_shirt_with_sash: :running_shirt_with_sash: top top :ski: :ski: :sled: :sled: top top :curling_stone: :curling_stone: top","title":"Sport"},{"location":"markdown/emoji_list/#game","text":"ico shortcode ico shortcode top :dart: :dart: :yo_yo: :yo_yo: top top :kite: :kite: :8ball: :8ball: top top :crystal_ball: :crystal_ball: :magic_wand: :magic_wand: top top :nazar_amulet: :nazar_amulet: :video_game: :video_game: top top :joystick: :joystick: :slot_machine: :slot_machine: top top :game_die: :game_die: :jigsaw: :jigsaw: top top :teddy_bear: :teddy_bear: :pinata: :pinata: top top :nesting_dolls: :nesting_dolls: :spades: :spades: top top :hearts: :hearts: :diamonds: :diamonds: top top :clubs: :clubs: :chess_pawn: :chess_pawn: top top :black_joker: :black_joker: :mahjong: :mahjong: top top :flower_playing_cards: :flower_playing_cards: top","title":"Game"},{"location":"markdown/emoji_list/#arts-crafts","text":"ico shortcode ico shortcode top :performing_arts: :performing_arts: :framed_picture: :framed_picture: top top :art: :art: :thread: :thread: top top :sewing_needle: :sewing_needle: :yarn: :yarn: top top :knot: :knot: top","title":"Arts &amp; Crafts"},{"location":"markdown/emoji_list/#objects","text":"Clothing Sound Music Musical Instrument Phone Computer Light & Video Book Paper Money Mail Writing Office Lock Tool Science Medical Household Other Object","title":"Objects"},{"location":"markdown/emoji_list/#clothing","text":"ico shortcode ico shortcode top :eyeglasses: :eyeglasses: :dark_sunglasses: :dark_sunglasses: top top :goggles: :goggles: :lab_coat: :lab_coat: top top :safety_vest: :safety_vest: :necktie: :necktie: top top :shirt: :shirt: :tshirt: :jeans: :jeans: top top :scarf: :scarf: :gloves: :gloves: top top :coat: :coat: :socks: :socks: top top :dress: :dress: :kimono: :kimono: top top :sari: :sari: :one_piece_swimsuit: :one_piece_swimsuit: top top :swim_brief: :swim_brief: :shorts: :shorts: top top :bikini: :bikini: :womans_clothes: :womans_clothes: top top :purse: :purse: :handbag: :handbag: top top :pouch: :pouch: :shopping: :shopping: top top :school_satchel: :school_satchel: :thong_sandal: :thong_sandal: top top :mans_shoe: :mans_shoe: :shoe: :athletic_shoe: :athletic_shoe: top top :hiking_boot: :hiking_boot: :flat_shoe: :flat_shoe: top top :high_heel: :high_heel: :sandal: :sandal: top top :ballet_shoes: :ballet_shoes: :boot: :boot: top top :crown: :crown: :womans_hat: :womans_hat: top top :tophat: :tophat: :mortar_board: :mortar_board: top top :billed_cap: :billed_cap: :military_helmet: :military_helmet: top top :rescue_worker_helmet: :rescue_worker_helmet: :prayer_beads: :prayer_beads: top top :lipstick: :lipstick: :ring: :ring: top top :gem: :gem: top","title":"Clothing"},{"location":"markdown/emoji_list/#sound","text":"ico shortcode ico shortcode top :mute: :mute: :speaker: :speaker: top top :sound: :sound: :loud_sound: :loud_sound: top top :loudspeaker: :loudspeaker: :mega: :mega: top top :postal_horn: :postal_horn: :bell: :bell: top top :no_bell: :no_bell: top","title":"Sound"},{"location":"markdown/emoji_list/#music","text":"ico shortcode ico shortcode top :musical_score: :musical_score: :musical_note: :musical_note: top top :notes: :notes: :studio_microphone: :studio_microphone: top top :level_slider: :level_slider: :control_knobs: :control_knobs: top top :microphone: :microphone: :headphones: :headphones: top top :radio: :radio: top","title":"Music"},{"location":"markdown/emoji_list/#musical-instrument","text":"ico shortcode ico shortcode top :saxophone: :saxophone: :accordion: :accordion: top top :guitar: :guitar: :musical_keyboard: :musical_keyboard: top top :trumpet: :trumpet: :violin: :violin: top top :banjo: :banjo: :drum: :drum: top top :long_drum: :long_drum: top","title":"Musical Instrument"},{"location":"markdown/emoji_list/#phone","text":"ico shortcode ico shortcode top :iphone: :iphone: :calling: :calling: top top :phone: :phone: :telephone: :telephone_receiver: :telephone_receiver: top top :pager: :pager: :fax: :fax: top","title":"Phone"},{"location":"markdown/emoji_list/#computer","text":"ico shortcode ico shortcode top :battery: :battery: :electric_plug: :electric_plug: top top :computer: :computer: :desktop_computer: :desktop_computer: top top :printer: :printer: :keyboard: :keyboard: top top :computer_mouse: :computer_mouse: :trackball: :trackball: top top :minidisc: :minidisc: :floppy_disk: :floppy_disk: top top :cd: :cd: :dvd: :dvd: top top :abacus: :abacus: top","title":"Computer"},{"location":"markdown/emoji_list/#light-video","text":"ico shortcode ico shortcode top :movie_camera: :movie_camera: :film_strip: :film_strip: top top :film_projector: :film_projector: :clapper: :clapper: top top :tv: :tv: :camera: :camera: top top :camera_flash: :camera_flash: :video_camera: :video_camera: top top :vhs: :vhs: :mag: :mag: top top :mag_right: :mag_right: :candle: :candle: top top :bulb: :bulb: :flashlight: :flashlight: top top :izakaya_lantern: :izakaya_lantern: :lantern: :diya_lamp: :diya_lamp: top","title":"Light &amp; Video"},{"location":"markdown/emoji_list/#book-paper","text":"ico shortcode ico shortcode top :notebook_with_decorative_cover: :notebook_with_decorative_cover: :closed_book: :closed_book: top top :book: :book: :open_book: :green_book: :green_book: top top :blue_book: :blue_book: :orange_book: :orange_book: top top :books: :books: :notebook: :notebook: top top :ledger: :ledger: :page_with_curl: :page_with_curl: top top :scroll: :scroll: :page_facing_up: :page_facing_up: top top :newspaper: :newspaper: :newspaper_roll: :newspaper_roll: top top :bookmark_tabs: :bookmark_tabs: :bookmark: :bookmark: top top :label: :label: top","title":"Book Paper"},{"location":"markdown/emoji_list/#money","text":"ico shortcode ico shortcode top :moneybag: :moneybag: :coin: :coin: top top :yen: :yen: :dollar: :dollar: top top :euro: :euro: :pound: :pound: top top :money_with_wings: :money_with_wings: :credit_card: :credit_card: top top :receipt: :receipt: :chart: :chart: top","title":"Money"},{"location":"markdown/emoji_list/#mail","text":"ico shortcode ico shortcode top :envelope: :envelope: :e-mail: :e-mail: :email: top top :incoming_envelope: :incoming_envelope: :envelope_with_arrow: :envelope_with_arrow: top top :outbox_tray: :outbox_tray: :inbox_tray: :inbox_tray: top top :package: :package: :mailbox: :mailbox: top top :mailbox_closed: :mailbox_closed: :mailbox_with_mail: :mailbox_with_mail: top top :mailbox_with_no_mail: :mailbox_with_no_mail: :postbox: :postbox: top top :ballot_box: :ballot_box: top","title":"Mail"},{"location":"markdown/emoji_list/#writing","text":"ico shortcode ico shortcode top :pencil2: :pencil2: :black_nib: :black_nib: top top :fountain_pen: :fountain_pen: :pen: :pen: top top :paintbrush: :paintbrush: :crayon: :crayon: top top :memo: :memo: :pencil: top","title":"Writing"},{"location":"markdown/emoji_list/#office","text":"ico shortcode ico shortcode top :briefcase: :briefcase: :file_folder: :file_folder: top top :open_file_folder: :open_file_folder: :card_index_dividers: :card_index_dividers: top top :date: :date: :calendar: :calendar: top top :spiral_notepad: :spiral_notepad: :spiral_calendar: :spiral_calendar: top top :card_index: :card_index: :chart_with_upwards_trend: :chart_with_upwards_trend: top top :chart_with_downwards_trend: :chart_with_downwards_trend: :bar_chart: :bar_chart: top top :clipboard: :clipboard: :pushpin: :pushpin: top top :round_pushpin: :round_pushpin: :paperclip: :paperclip: top top :paperclips: :paperclips: :straight_ruler: :straight_ruler: top top :triangular_ruler: :triangular_ruler: :scissors: :scissors: top top :card_file_box: :card_file_box: :file_cabinet: :file_cabinet: top top :wastebasket: :wastebasket: top","title":"Office"},{"location":"markdown/emoji_list/#lock","text":"ico shortcode ico shortcode top :lock: :lock: :unlock: :unlock: top top :lock_with_ink_pen: :lock_with_ink_pen: :closed_lock_with_key: :closed_lock_with_key: top top :key: :key: :old_key: :old_key: top","title":"Lock"},{"location":"markdown/emoji_list/#tool","text":"ico shortcode ico shortcode top :hammer: :hammer: :axe: :axe: top top :pick: :pick: :hammer_and_pick: :hammer_and_pick: top top :hammer_and_wrench: :hammer_and_wrench: :dagger: :dagger: top top :crossed_swords: :crossed_swords: :gun: :gun: top top :boomerang: :boomerang: :bow_and_arrow: :bow_and_arrow: top top :shield: :shield: :carpentry_saw: :carpentry_saw: top top :wrench: :wrench: :screwdriver: :screwdriver: top top :nut_and_bolt: :nut_and_bolt: :gear: :gear: top top :clamp: :clamp: :balance_scale: :balance_scale: top top :probing_cane: :probing_cane: :link: :link: top top :chains: :chains: :hook: :hook: top top :toolbox: :toolbox: :magnet: :magnet: top top :ladder: :ladder: top","title":"Tool"},{"location":"markdown/emoji_list/#science","text":"ico shortcode ico shortcode top :alembic: :alembic: :test_tube: :test_tube: top top :petri_dish: :petri_dish: :dna: :dna: top top :microscope: :microscope: :telescope: :telescope: top top :satellite: :satellite: top","title":"Science"},{"location":"markdown/emoji_list/#medical","text":"ico shortcode ico shortcode top :syringe: :syringe: :drop_of_blood: :drop_of_blood: top top :pill: :pill: :adhesive_bandage: :adhesive_bandage: top top :stethoscope: :stethoscope: top","title":"Medical"},{"location":"markdown/emoji_list/#household","text":"ico shortcode ico shortcode top :door: :door: :elevator: :elevator: top top :mirror: :mirror: :window: :window: top top :bed: :bed: :couch_and_lamp: :couch_and_lamp: top top :chair: :chair: :toilet: :toilet: top top :plunger: :plunger: :shower: :shower: top top :bathtub: :bathtub: :mouse_trap: :mouse_trap: top top :razor: :razor: :lotion_bottle: :lotion_bottle: top top :safety_pin: :safety_pin: :broom: :broom: top top :basket: :basket: :roll_of_paper: :roll_of_paper: top top :bucket: :bucket: :soap: :soap: top top :toothbrush: :toothbrush: :sponge: :sponge: top top :fire_extinguisher: :fire_extinguisher: :shopping_cart: :shopping_cart: top","title":"Household"},{"location":"markdown/emoji_list/#other-object","text":"ico shortcode ico shortcode top :smoking: :smoking: :coffin: :coffin: top top :headstone: :headstone: :funeral_urn: :funeral_urn: top top :moyai: :moyai: :placard: :placard: top","title":"Other Object"},{"location":"markdown/emoji_list/#symbols","text":"Transport Sign Warning Arrow Religion Zodiac Av Symbol Gender Math Punctuation Currency Other Symbol Keycap Alphanum Geometric","title":"Symbols"},{"location":"markdown/emoji_list/#transport-sign","text":"ico shortcode ico shortcode top :atm: :atm: :put_litter_in_its_place: :put_litter_in_its_place: top top :potable_water: :potable_water: :wheelchair: :wheelchair: top top :mens: :mens: :womens: :womens: top top :restroom: :restroom: :baby_symbol: :baby_symbol: top top :wc: :wc: :passport_control: :passport_control: top top :customs: :customs: :baggage_claim: :baggage_claim: top top :left_luggage: :left_luggage: top","title":"Transport Sign"},{"location":"markdown/emoji_list/#warning","text":"ico shortcode ico shortcode top :warning: :warning: :children_crossing: :children_crossing: top top :no_entry: :no_entry: :no_entry_sign: :no_entry_sign: top top :no_bicycles: :no_bicycles: :no_smoking: :no_smoking: top top :do_not_litter: :do_not_litter: :non-potable_water: :non-potable_water: top top :no_pedestrians: :no_pedestrians: :no_mobile_phones: :no_mobile_phones: top top :underage: :underage: :radioactive: :radioactive: top top :biohazard: :biohazard: top","title":"Warning"},{"location":"markdown/emoji_list/#arrow","text":"ico shortcode ico shortcode top :arrow_up: :arrow_up: :arrow_upper_right: :arrow_upper_right: top top :arrow_right: :arrow_right: :arrow_lower_right: :arrow_lower_right: top top :arrow_down: :arrow_down: :arrow_lower_left: :arrow_lower_left: top top :arrow_left: :arrow_left: :arrow_upper_left: :arrow_upper_left: top top :arrow_up_down: :arrow_up_down: :left_right_arrow: :left_right_arrow: top top :leftwards_arrow_with_hook: :leftwards_arrow_with_hook: :arrow_right_hook: :arrow_right_hook: top top :arrow_heading_up: :arrow_heading_up: :arrow_heading_down: :arrow_heading_down: top top :arrows_clockwise: :arrows_clockwise: :arrows_counterclockwise: :arrows_counterclockwise: top top :back: :back: :end: :end: top top :on: :on: :soon: :soon: top top :top: :top: top","title":"Arrow"},{"location":"markdown/emoji_list/#religion","text":"ico shortcode ico shortcode top :place_of_worship: :place_of_worship: :atom_symbol: :atom_symbol: top top :om: :om: :star_of_david: :star_of_david: top top :wheel_of_dharma: :wheel_of_dharma: :yin_yang: :yin_yang: top top :latin_cross: :latin_cross: :orthodox_cross: :orthodox_cross: top top :star_and_crescent: :star_and_crescent: :peace_symbol: :peace_symbol: top top :menorah: :menorah: :six_pointed_star: :six_pointed_star: top","title":"Religion"},{"location":"markdown/emoji_list/#zodiac","text":"ico shortcode ico shortcode top :aries: :aries: :taurus: :taurus: top top :gemini: :gemini: :cancer: :cancer: top top :leo: :leo: :virgo: :virgo: top top :libra: :libra: :scorpius: :scorpius: top top :sagittarius: :sagittarius: :capricorn: :capricorn: top top :aquarius: :aquarius: :pisces: :pisces: top top :ophiuchus: :ophiuchus: top","title":"Zodiac"},{"location":"markdown/emoji_list/#av-symbol","text":"ico shortcode ico shortcode top :twisted_rightwards_arrows: :twisted_rightwards_arrows: :repeat: :repeat: top top :repeat_one: :repeat_one: :arrow_forward: :arrow_forward: top top :fast_forward: :fast_forward: :next_track_button: :next_track_button: top top :play_or_pause_button: :play_or_pause_button: :arrow_backward: :arrow_backward: top top :rewind: :rewind: :previous_track_button: :previous_track_button: top top :arrow_up_small: :arrow_up_small: :arrow_double_up: :arrow_double_up: top top :arrow_down_small: :arrow_down_small: :arrow_double_down: :arrow_double_down: top top :pause_button: :pause_button: :stop_button: :stop_button: top top :record_button: :record_button: :eject_button: :eject_button: top top :cinema: :cinema: :low_brightness: :low_brightness: top top :high_brightness: :high_brightness: :signal_strength: :signal_strength: top top :vibration_mode: :vibration_mode: :mobile_phone_off: :mobile_phone_off: top","title":"Av Symbol"},{"location":"markdown/emoji_list/#gender","text":"ico shortcode ico shortcode top :female_sign: :female_sign: :male_sign: :male_sign: top top :transgender_symbol: :transgender_symbol: top","title":"Gender"},{"location":"markdown/emoji_list/#math","text":"ico shortcode ico shortcode top :heavy_multiplication_x: :heavy_multiplication_x: :heavy_plus_sign: :heavy_plus_sign: top top :heavy_minus_sign: :heavy_minus_sign: :heavy_division_sign: :heavy_division_sign: top top :infinity: :infinity: top","title":"Math"},{"location":"markdown/emoji_list/#punctuation","text":"ico shortcode ico shortcode top :bangbang: :bangbang: :interrobang: :interrobang: top top :question: :question: :grey_question: :grey_question: top top :grey_exclamation: :grey_exclamation: :exclamation: :exclamation: :heavy_exclamation_mark: top top :wavy_dash: :wavy_dash: top","title":"Punctuation"},{"location":"markdown/emoji_list/#currency","text":"ico shortcode ico shortcode top :currency_exchange: :currency_exchange: :heavy_dollar_sign: :heavy_dollar_sign: top","title":"Currency"},{"location":"markdown/emoji_list/#other-symbol","text":"ico shortcode ico shortcode top :medical_symbol: :medical_symbol: :recycle: :recycle: top top :fleur_de_lis: :fleur_de_lis: :trident: :trident: top top :name_badge: :name_badge: :beginner: :beginner: top top :o: :o: :white_check_mark: :white_check_mark: top top :ballot_box_with_check: :ballot_box_with_check: :heavy_check_mark: :heavy_check_mark: top top :x: :x: :negative_squared_cross_mark: :negative_squared_cross_mark: top top :curly_loop: :curly_loop: :loop: :loop: top top :part_alternation_mark: :part_alternation_mark: :eight_spoked_asterisk: :eight_spoked_asterisk: top top :eight_pointed_black_star: :eight_pointed_black_star: :sparkle: :sparkle: top top :copyright: :copyright: :registered: :registered: top top :tm: :tm: top","title":"Other Symbol"},{"location":"markdown/emoji_list/#keycap","text":"ico shortcode ico shortcode top :hash: :hash: :asterisk: :asterisk: top top :zero: :zero: :one: :one: top top :two: :two: :three: :three: top top :four: :four: :five: :five: top top :six: :six: :seven: :seven: top top :eight: :eight: :nine: :nine: top top :keycap_ten: :keycap_ten: top","title":"Keycap"},{"location":"markdown/emoji_list/#alphanum","text":"ico shortcode ico shortcode top :capital_abcd: :capital_abcd: :abcd: :abcd: top top :1234: :1234: :symbols: :symbols: top top :abc: :abc: :a: :a: top top :ab: :ab: :b: :b: top top :cl: :cl: :cool: :cool: top top :free: :free: :information_source: :information_source: top top :id: :id: :m: :m: top top :new: :new: :ng: :ng: top top :o2: :o2: :ok: :ok: top top :parking: :parking: :sos: :sos: top top :up: :up: :vs: :vs: top top :koko: :koko: :sa: :sa: top top :u6708: :u6708: :u6709: :u6709: top top :u6307: :u6307: :ideograph_advantage: :ideograph_advantage: top top :u5272: :u5272: :u7121: :u7121: top top :u7981: :u7981: :accept: :accept: top top :u7533: :u7533: :u5408: :u5408: top top :u7a7a: :u7a7a: :congratulations: :congratulations: top top :secret: :secret: :u55b6: :u55b6: top top :u6e80: :u6e80: top","title":"Alphanum"},{"location":"markdown/emoji_list/#geometric","text":"ico shortcode ico shortcode top :red_circle: :red_circle: :orange_circle: :orange_circle: top top :yellow_circle: :yellow_circle: :green_circle: :green_circle: top top :large_blue_circle: :large_blue_circle: :purple_circle: :purple_circle: top top :brown_circle: :brown_circle: :black_circle: :black_circle: top top :white_circle: :white_circle: :red_square: :red_square: top top :orange_square: :orange_square: :yellow_square: :yellow_square: top top :green_square: :green_square: :blue_square: :blue_square: top top :purple_square: :purple_square: :brown_square: :brown_square: top top :black_large_square: :black_large_square: :white_large_square: :white_large_square: top top :black_medium_square: :black_medium_square: :white_medium_square: :white_medium_square: top top :black_medium_small_square: :black_medium_small_square: :white_medium_small_square: :white_medium_small_square: top top :black_small_square: :black_small_square: :white_small_square: :white_small_square: top top :large_orange_diamond: :large_orange_diamond: :large_blue_diamond: :large_blue_diamond: top top :small_orange_diamond: :small_orange_diamond: :small_blue_diamond: :small_blue_diamond: top top :small_red_triangle: :small_red_triangle: :small_red_triangle_down: :small_red_triangle_down: top top :diamond_shape_with_a_dot_inside: :diamond_shape_with_a_dot_inside: :radio_button: :radio_button: top top :white_square_button: :white_square_button: :black_square_button: :black_square_button: top","title":"Geometric"},{"location":"markdown/emoji_list/#flags","text":"Flag Country Flag Subdivision Flag","title":"Flags"},{"location":"markdown/emoji_list/#flag","text":"ico shortcode ico shortcode top :checkered_flag: :checkered_flag: :triangular_flag_on_post: :triangular_flag_on_post: top top :crossed_flags: :crossed_flags: :black_flag: :black_flag: top top :white_flag: :white_flag: :rainbow_flag: :rainbow_flag: top top :transgender_flag: :transgender_flag: :pirate_flag: :pirate_flag: top","title":"Flag"},{"location":"markdown/emoji_list/#country-flag","text":"ico shortcode ico shortcode top :ascension_island: :ascension_island: :andorra: :andorra: top top :united_arab_emirates: :united_arab_emirates: :afghanistan: :afghanistan: top top :antigua_barbuda: :antigua_barbuda: :anguilla: :anguilla: top top :albania: :albania: :armenia: :armenia: top top :angola: :angola: :antarctica: :antarctica: top top :argentina: :argentina: :american_samoa: :american_samoa: top top :austria: :austria: :australia: :australia: top top :aruba: :aruba: :aland_islands: :aland_islands: top top :azerbaijan: :azerbaijan: :bosnia_herzegovina: :bosnia_herzegovina: top top :barbados: :barbados: :bangladesh: :bangladesh: top top :belgium: :belgium: :burkina_faso: :burkina_faso: top top :bulgaria: :bulgaria: :bahrain: :bahrain: top top :burundi: :burundi: :benin: :benin: top top :st_barthelemy: :st_barthelemy: :bermuda: :bermuda: top top :brunei: :brunei: :bolivia: :bolivia: top top :caribbean_netherlands: :caribbean_netherlands: :brazil: :brazil: top top :bahamas: :bahamas: :bhutan: :bhutan: top top :bouvet_island: :bouvet_island: :botswana: :botswana: top top :belarus: :belarus: :belize: :belize: top top :canada: :canada: :cocos_islands: :cocos_islands: top top :congo_kinshasa: :congo_kinshasa: :central_african_republic: :central_african_republic: top top :congo_brazzaville: :congo_brazzaville: :switzerland: :switzerland: top top :cote_divoire: :cote_divoire: :cook_islands: :cook_islands: top top :chile: :chile: :cameroon: :cameroon: top top :cn: :cn: :colombia: :colombia: top top :clipperton_island: :clipperton_island: :costa_rica: :costa_rica: top top :cuba: :cuba: :cape_verde: :cape_verde: top top :curacao: :curacao: :christmas_island: :christmas_island: top top :cyprus: :cyprus: :czech_republic: :czech_republic: top top :de: :de: :diego_garcia: :diego_garcia: top top :djibouti: :djibouti: :denmark: :denmark: top top :dominica: :dominica: :dominican_republic: :dominican_republic: top top :algeria: :algeria: :ceuta_melilla: :ceuta_melilla: top top :ecuador: :ecuador: :estonia: :estonia: top top :egypt: :egypt: :western_sahara: :western_sahara: top top :eritrea: :eritrea: :es: :es: top top :ethiopia: :ethiopia: :eu: :eu: :european_union: top top :finland: :finland: :fiji: :fiji: top top :falkland_islands: :falkland_islands: :micronesia: :micronesia: top top :faroe_islands: :faroe_islands: :fr: :fr: top top :gabon: :gabon: :gb: :gb: :uk: top top :grenada: :grenada: :georgia: :georgia: top top :french_guiana: :french_guiana: :guernsey: :guernsey: top top :ghana: :ghana: :gibraltar: :gibraltar: top top :greenland: :greenland: :gambia: :gambia: top top :guinea: :guinea: :guadeloupe: :guadeloupe: top top :equatorial_guinea: :equatorial_guinea: :greece: :greece: top top :south_georgia_south_sandwich_islands: :south_georgia_south_sandwich_islands: :guatemala: :guatemala: top top :guam: :guam: :guinea_bissau: :guinea_bissau: top top :guyana: :guyana: :hong_kong: :hong_kong: top top :heard_mcdonald_islands: :heard_mcdonald_islands: :honduras: :honduras: top top :croatia: :croatia: :haiti: :haiti: top top :hungary: :hungary: :canary_islands: :canary_islands: top top :indonesia: :indonesia: :ireland: :ireland: top top :israel: :israel: :isle_of_man: :isle_of_man: top top :india: :india: :british_indian_ocean_territory: :british_indian_ocean_territory: top top :iraq: :iraq: :iran: :iran: top top :iceland: :iceland: :it: :it: top top :jersey: :jersey: :jamaica: :jamaica: top top :jordan: :jordan: :jp: :jp: top top :kenya: :kenya: :kyrgyzstan: :kyrgyzstan: top top :cambodia: :cambodia: :kiribati: :kiribati: top top :comoros: :comoros: :st_kitts_nevis: :st_kitts_nevis: top top :north_korea: :north_korea: :kr: :kr: top top :kuwait: :kuwait: :cayman_islands: :cayman_islands: top top :kazakhstan: :kazakhstan: :laos: :laos: top top :lebanon: :lebanon: :st_lucia: :st_lucia: top top :liechtenstein: :liechtenstein: :sri_lanka: :sri_lanka: top top :liberia: :liberia: :lesotho: :lesotho: top top :lithuania: :lithuania: :luxembourg: :luxembourg: top top :latvia: :latvia: :libya: :libya: top top :morocco: :morocco: :monaco: :monaco: top top :moldova: :moldova: :montenegro: :montenegro: top top :st_martin: :st_martin: :madagascar: :madagascar: top top :marshall_islands: :marshall_islands: :macedonia: :macedonia: top top :mali: :mali: :myanmar: :myanmar: top top :mongolia: :mongolia: :macau: :macau: top top :northern_mariana_islands: :northern_mariana_islands: :martinique: :martinique: top top :mauritania: :mauritania: :montserrat: :montserrat: top top :malta: :malta: :mauritius: :mauritius: top top :maldives: :maldives: :malawi: :malawi: top top :mexico: :mexico: :malaysia: :malaysia: top top :mozambique: :mozambique: :namibia: :namibia: top top :new_caledonia: :new_caledonia: :niger: :niger: top top :norfolk_island: :norfolk_island: :nigeria: :nigeria: top top :nicaragua: :nicaragua: :netherlands: :netherlands: top top :norway: :norway: :nepal: :nepal: top top :nauru: :nauru: :niue: :niue: top top :new_zealand: :new_zealand: :oman: :oman: top top :panama: :panama: :peru: :peru: top top :french_polynesia: :french_polynesia: :papua_new_guinea: :papua_new_guinea: top top :philippines: :philippines: :pakistan: :pakistan: top top :poland: :poland: :st_pierre_miquelon: :st_pierre_miquelon: top top :pitcairn_islands: :pitcairn_islands: :puerto_rico: :puerto_rico: top top :palestinian_territories: :palestinian_territories: :portugal: :portugal: top top :palau: :palau: :paraguay: :paraguay: top top :qatar: :qatar: :reunion: :reunion: top top :romania: :romania: :serbia: :serbia: top top :ru: :ru: :rwanda: :rwanda: top top :saudi_arabia: :saudi_arabia: :solomon_islands: :solomon_islands: top top :seychelles: :seychelles: :sudan: :sudan: top top :sweden: :sweden: :singapore: :singapore: top top :st_helena: :st_helena: :slovenia: :slovenia: top top :svalbard_jan_mayen: :svalbard_jan_mayen: :slovakia: :slovakia: top top :sierra_leone: :sierra_leone: :san_marino: :san_marino: top top :senegal: :senegal: :somalia: :somalia: top top :suriname: :suriname: :south_sudan: :south_sudan: top top :sao_tome_principe: :sao_tome_principe: :el_salvador: :el_salvador: top top :sint_maarten: :sint_maarten: :syria: :syria: top top :swaziland: :swaziland: :tristan_da_cunha: :tristan_da_cunha: top top :turks_caicos_islands: :turks_caicos_islands: :chad: :chad: top top :french_southern_territories: :french_southern_territories: :togo: :togo: top top :thailand: :thailand: :tajikistan: :tajikistan: top top :tokelau: :tokelau: :timor_leste: :timor_leste: top top :turkmenistan: :turkmenistan: :tunisia: :tunisia: top top :tonga: :tonga: :tr: :tr: top top :trinidad_tobago: :trinidad_tobago: :tuvalu: :tuvalu: top top :taiwan: :taiwan: :tanzania: :tanzania: top top :ukraine: :ukraine: :uganda: :uganda: top top :us_outlying_islands: :us_outlying_islands: :united_nations: :united_nations: top top :us: :us: :uruguay: :uruguay: top top :uzbekistan: :uzbekistan: :vatican_city: :vatican_city: top top :st_vincent_grenadines: :st_vincent_grenadines: :venezuela: :venezuela: top top :british_virgin_islands: :british_virgin_islands: :us_virgin_islands: :us_virgin_islands: top top :vietnam: :vietnam: :vanuatu: :vanuatu: top top :wallis_futuna: :wallis_futuna: :samoa: :samoa: top top :kosovo: :kosovo: :yemen: :yemen: top top :mayotte: :mayotte: :south_africa: :south_africa: top top :zambia: :zambia: :zimbabwe: :zimbabwe: top","title":"Country Flag"},{"location":"markdown/emoji_list/#subdivision-flag","text":"ico shortcode ico shortcode top :england: :england: :scotland: :scotland: top top :wales: :wales: top","title":"Subdivision Flag"},{"location":"markdown/emoji_list/#github-custom-emoji","text":"ico shortcode ico shortcode top :atom: :atom: :basecamp: :basecamp: top top :basecampy: :basecampy: :bowtie: :bowtie: top top :electron: :electron: :feelsgood: :feelsgood: top top :finnadie: :finnadie: :goberserk: :goberserk: top top :godmode: :godmode: :hurtrealbad: :hurtrealbad: top top :neckbeard: :neckbeard: :octocat: :octocat: top top :rage1: :rage1: :rage2: :rage2: top top :rage3: :rage3: :rage4: :rage4: top top :shipit: :shipit: :suspect: :suspect: top top :trollface: :trollface: top","title":"GitHub Custom Emoji"},{"location":"markdown/markdown/","text":"Markdown Cheatsheet Add images The following HTML is also legal Markdown: <img src=\"markdownmonstericon.png\" alt=\"Markdown Monster icon\" style=\"float: left; margin-right: 10px;\" />","title":"markdown images"},{"location":"markdown/markdown/#markdown-cheatsheet","text":"","title":"Markdown Cheatsheet"},{"location":"markdown/markdown/#add-images","text":"The following HTML is also legal Markdown: <img src=\"markdownmonstericon.png\" alt=\"Markdown Monster icon\" style=\"float: left; margin-right: 10px;\" />","title":"Add images"},{"location":"markdown/mermaid_graphs/","text":"Mermaid Graph graph and flowchart are interchangeable mermaid flowcharts graph TD; A-->B; A-->C; B-->D; C-->D; Use HTML with mermaid graph TD; A-->B; A-->C; B-->D; C-->D; Nested subgraph graph TD A[Christmas] -->|Get money| B(Go shopping) subgraph Nerve wracking B --> C{Roll a dice} end subgraph Don't look C -->|One| D[Laptop] C -->|Two| E[iPhone] subgraph High Probability C-->|Three| G C-->|Four| G C-->|Five| G[A gift card] end subgraph Low Probability C -->|Six| F[fa:fa-car Car] end end MLOps Architecture graph LR A[GitHub] --> B(CICD <br> GitHub Actions) B --> C{Roll a dice} subgraph ML Prediction C1 --> C2 C1 --> C3(Flask) end subgraph Don't look C -->|Two| E[Flask] subgraph High Probability C-->|Three| G C-->|Four| G C-->|Five| G[A gift card] end subgraph Low Probability C -->|Seven| H[\"\ud83c\udf49\"] end end flowchart TB c1-->a2 subgraph one a1-->a2 end subgraph two b1-->b2 end subgraph three c1-->c2 end one --> two three --> two two --> c2 Sequence Diagram sequenceDiagram participant Alice participant Bob Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts <br/>prevail! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good! Gantt gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d GitGraph git graphs Create a feature branch and make some file edits. gitGraph commit id: \"1\" commit id: \"2\" branch feature commit id: \"A\" commit id: \"B\" checkout main commit id: \"3\" commit id: \"4\" gitGraph commit commit branch develop checkout develop commit commit checkout main merge develop commit commit","title":"Mermaid Graphs"},{"location":"markdown/mermaid_graphs/#mermaid","text":"","title":"Mermaid"},{"location":"markdown/mermaid_graphs/#graph","text":"graph and flowchart are interchangeable mermaid flowcharts graph TD; A-->B; A-->C; B-->D; C-->D;","title":"Graph"},{"location":"markdown/mermaid_graphs/#use-html-with-mermaid","text":"graph TD; A-->B; A-->C; B-->D; C-->D;","title":"Use HTML with mermaid"},{"location":"markdown/mermaid_graphs/#nested-subgraph","text":"graph TD A[Christmas] -->|Get money| B(Go shopping) subgraph Nerve wracking B --> C{Roll a dice} end subgraph Don't look C -->|One| D[Laptop] C -->|Two| E[iPhone] subgraph High Probability C-->|Three| G C-->|Four| G C-->|Five| G[A gift card] end subgraph Low Probability C -->|Six| F[fa:fa-car Car] end end","title":"Nested subgraph"},{"location":"markdown/mermaid_graphs/#mlops-architecture","text":"graph LR A[GitHub] --> B(CICD <br> GitHub Actions) B --> C{Roll a dice} subgraph ML Prediction C1 --> C2 C1 --> C3(Flask) end subgraph Don't look C -->|Two| E[Flask] subgraph High Probability C-->|Three| G C-->|Four| G C-->|Five| G[A gift card] end subgraph Low Probability C -->|Seven| H[\"\ud83c\udf49\"] end end flowchart TB c1-->a2 subgraph one a1-->a2 end subgraph two b1-->b2 end subgraph three c1-->c2 end one --> two three --> two two --> c2","title":"MLOps Architecture"},{"location":"markdown/mermaid_graphs/#sequence-diagram","text":"sequenceDiagram participant Alice participant Bob Alice->>John: Hello John, how are you? loop Healthcheck John->>John: Fight against hypochondria end Note right of John: Rational thoughts <br/>prevail! John-->>Alice: Great! John->>Bob: How about you? Bob-->>John: Jolly good!","title":"Sequence Diagram"},{"location":"markdown/mermaid_graphs/#gantt","text":"gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d","title":"Gantt"},{"location":"markdown/mermaid_graphs/#gitgraph","text":"git graphs Create a feature branch and make some file edits. gitGraph commit id: \"1\" commit id: \"2\" branch feature commit id: \"A\" commit id: \"B\" checkout main commit id: \"3\" commit id: \"4\" gitGraph commit commit branch develop checkout develop commit commit checkout main merge develop commit commit","title":"GitGraph"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/","text":"Securing Amazon SageMaker Studio internet traffic using AWS Network Firewall Building secure machine learning environments with Amazon SageMaker Securing Amazon SageMaker Studio connectivity using a private VPC. Configuring Amazon SageMaker Studio for teams and groups with complete resource isolation Securing Amazon SageMaker Studio connectivity using a private VPC Background Amazon SageMaker Studio is a web-based fully integrated development environment (IDE) where you can perform end-to-end machine learning (ML) development to prepare data and build, train, and deploy models. One of these fundamental security features allows you to launch Studio in your own Amazon Virtual Private Cloud (Amazon VPC). This allows you to control, monitor, and inspect network traffic within and outside your VPC using standard AWS networking and security capabilities. For more information, see Securing Amazon SageMaker Studio connectivity using a private VPC. SM Studio users may want to provide internet access but also have some controls such as domain name or URL filtering and allow access to only specific public repositories and websites, possibly packet inspection, or other network traffic-related security controls. For these cases, AWS Network Firewall and NAT gateway-based deployment may provide a suitable use case. In this post, I outline the use of network firewall to build a secure and compliant environment by restricting and monitoring internet access, inspecting traffic, and using stateless and stateful firewall engine rules to control the network flow between Studio notebooks and the internet. Depending on your security, compliance, and governance rules, you may not need to or cannot completely block internet access from Studio and your AI and ML workloads. You may have requirements beyond the scope of network security controls implemented by security groups and network access control lists (ACLs), such as application protocol protection, deep packet inspection, domain name filtering, and intrusion prevention system (IPS). Your network traffic controls may also require many more rules compared to what is currently supported in security groups and network ACLs. In these scenarios, you can use Network Firewall\u2014a managed network firewall and IPS for your VPC. Solution overview Sagemaker Studio deployed in a VPC, provides internet access control, using the parameter AppNetworkAccessType (via the Amazon SageMaker API ) or by selecting your preference on the console when you create a Studio domain. If you select Public internet Only ( PublicInternetOnly ), all the ingress and egress internet traffic from Amazon SageMaker notebooks flows through an AWS managed internet gateway attached to a VPC in your SageMaker account. The following diagram shows this network configuration. Studio provides public internet egress through a platform-managed VPC for data scientists to download notebooks, packages, and datasets. Traffic to the attached Amazon Elastic File System (Amazon EFS) volume always goes through the customer VPC and never through the public internet egress. To use your own control flow for the internet traffic, like a NAT or internet gateway, you must set the AppNetworkAccessType parameter to VpcOnly (or select VPC Only on the console). When you launch your app, this creates an elastic network interface in the specified subnets in your VPC. You can apply all available layers of security control\u2014 security groups , network ACLs , VPC endpoints , AWS PrivateLink , or Network Firewall endpoints \u2014to the internal network and internet traffic to exercise fine-grained control of network access in Studio. The following diagram shows the VpcOnly network configuration. In this mode, the direct internet access to or from notebooks is completely disabled, and all traffic is routed through an elastic network interface in your private VPC. This also includes traffic from Studio UI widgets and interfaces, such as Experiments , Autopilot , and Model Monitor , to their respective backend SageMaker APIs. VPC only option The solution in this post uses the VpcOnly option and deploys the Studio domain into a VPC with three subnets: SageMaker subnet \u2013 Hosts all Studio workloads. All ingress and egress network flow is controlled by a security group. NAT subnet \u2013 Contains a NAT gateway. We use the NAT gateway to access the internet without exposing any private IP addresses from our private network. Network Firewall subnet \u2013 Contains a Network Firewall endpoint. The route tables are configured so that all inbound and outbound external network traffic is routed via Network Firewall. You can configure stateful and stateless Network Firewall policies to inspect, monitor, and control the traffic. The following diagram shows the overview of the solution architecture and the deployed components. SageMaker resources Create a SageMaker domain and user profile. The solution uses only one Availability Zone and is not highly available. A best practice is to use a Multi-AZ configuration for any production deployment. We create an allow domain list rule to allow internet access to the specified network domains only and block traffic to any domain not on the allow list. AWS CloudFormation resources The source code and AWS CloudFormation template for solution deployment are provided in the GitHub repository . Network Firewall is a Regional service; for more information on Region availability, see the AWS Region Table . To start experimenting with the Network Firewall and stateful rules, you need first to deploy the provided CloudFormation template to the AWS account. Clone the GitHub repository: Create an S3 bucket in the Region where you deploy the solution: aws s3 mb s3://<your s3 bucket name> You can skip this step if you already have an S3 bucket. Deploy the CloudFormation stack: make deploy CFN_ARTEFACT_S3_BUCKET=<your s3 bucket name> The deployment procedure packages the CloudFormation template and copies it to the S3 bucket your provided. Then the CloudFormation template is deployed from the S3 bucket to your AWS account. The stack deploys all the needed resources like VPC, network devices, route tables, security groups, S3 buckets, IAM policies and roles, and VPC endpoints, and also creates a new Studio domain and user profile. When the deployment is complete, you can see the full list of stack output values by running the following command in terminal: aws cloudformation describe-stacks \\ --stack-name sagemaker-studio-demo \\ --output table \\ --query \"Stacks[0].Outputs[*].[OutputKey, OutputValue]\" Launch Studio via the SageMaker console. Experiment with Network Firewall Now you can learn how to control the internet inbound and outbound access with Network Firewall. In this section, we discuss the initial setup, accessing resources not on the allow list, adding domains to the allow list, configuring logging, and additional firewall rules. Initial setup The solution deploys a Network Firewall policy with a stateful rule group with an allow domain list. This policy is attached to the Network Firewall. All inbound and outbound internet traffic is blocked now, except for the .kaggle.com domain, which is on the allow list. Let\u2019s try to access https://kaggle.com by opening a new notebook in Studio and attempting to download the front page from kaggle.com : !wget https://kaggle.com The following screenshot shows that the request succeeds because the domain is allowed by the firewall policy. Users can connect to this and only to this domain from any Studio notebook. Access resources not on the allowed domain list In the Studio notebook, try to clone any public GitHub repository, such as the following: !git clone https://github.com/pytorch/examples.git This operation times out after 5 minutes because any internet traffic except to and from the .kaggle.com domain isn\u2019t allowed and is dropped by the firewall. Add a domain to the allowed domain list To be able to run the git clone command, you must allow internet traffic to the .github.com domain. On the Amazon VPC console, choose Firewall policies. Choose the policy network-firewall-policy- . In the Stateful rule groups section, select the group rule domain-allow-sagemaker- . You can see the domain .kaggle.com on the allow list. Choose Add domain. Enter .github.com . Choose Save. You now have two names on the allow domain list. Firewall policy is propagated in real time to Network Firewall and your changes take effect immediately. Any inbound or outbound traffic from or to these domains is now allowed by the firewall and all other traffic is dropped. To validate the new configuration, go to your Studio notebook and try to clone the same GitHub repository again: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git The operation succeeds this time\u2014Network Firewall allows access to the .github.com domain. Network Firewall logging In this section, you configure Network Firewall logging for your firewall\u2019s stateful engine. Logging gives you detailed information about network traffic, including the time that the stateful engine received a packet, detailed information about the packet, and any stateful rule action taken against the packet. The logs are published to the log destination that you configured, where you can retrieve and view them. On the Amazon VPC console, choose Firewalls . Choose your firewall. Choose the Firewall details tab. In the Logging section, choose Edit . Configure your firewall logging by selecting what log types you want to capture and providing the log destination. For this post, select Alert log type, set Log destination for alerts to CloudWatch Log group, and provide an existing or a new log group where the firewall logs are delivered. Choose Save . To check your settings, go back to Studio and try to access pypi.org to install a Python package: !pip install -U scikit-learn This command fails with ReadTimeoutError because Network Firewall drops any traffic to any domain not on the allow list (which contains only two domains: .github.com and .kaggle.com ). On the Amazon CloudWatch console , navigate to the log group and browse through the recent log streams. The pipy.org domain shows the blocked action. The log event also provides additional details such as various timestamps, protocol, port and IP details, event type, availability zone, and the firewall name. You can continue experimenting with Network Firewall by adding .pypi.org and .pythonhosted.org domains to the allowed domain list. Then validate your access to them via your Studio notebook. Additional firewall rules You can create any other stateless or stateful firewall rules and implement traffic filtering based on a standard stateful 5-tuple rule for network traffic inspection (protocol, source IP, source port, destination IP, destination port). Network Firewall also supports industry standard stateful Suricata compatible IPS rule groups. You can implement protocol-based rules to detect and block any non-standard or promiscuous usage or activity. For more information about creating and managing Network Firewall rule groups, see Rule groups in AWS Network Firewall. Additional security controls with Network Firewall In the previous section, we looked at one feature of the Network Firewall: filtering network traffic based on the domain name. In addition to stateless or stateful firewall rules, Network Firewall provides several tools and features for further security controls and monitoring: Central firewall management and visibility in AWS Firewall Manager . You can centrally manage security policies and automatically enforce mandatory security policies across existing and newly created accounts and VPCs. Network Firewall logging for the firewall\u2019s stateful engine. You can record flow and alert logs, and use the same or different logging destinations for each log type. Stateless rules to filter network traffic based on protocol, source IP addresses, ranges, source port ranges, destination IP addresses and ranges, and TCP flags. Integration into a broader set of AWS security components. For an example, see Automatically block suspicious traffic with AWS Network Firewall and Amazon GuardDuty. Integration in a diverse ecosystem of Network Firewall Partners that complement Network Firewall, enabling the deployment of a comprehensive security architecture. For example use cases, see Full VPC traffic visibility with AWS Network Firewall and Sumo Logic and Splunk Named Launch Partner of AWS Network Firewall. Build secure ML environments A robust security design normally includes multi-layer security controls for the system. For SageMaker environments and workloads, you can use the following AWS security services and concepts to secure, control, and monitor your environment: VPC and private subnets to perform secure API calls to other AWS services and restrict internet access for downloading packages. S3 bucket policies that restrict access to specific VPC endpoints. Encryption of ML model artifacts and other system artifacts that are either in transit or at rest. Requests to the SageMaker API and console are made over a Secure Sockets Layer (SSL) connection. Restricted IAM roles and policies for SageMaker runs and notebook access based on resource tags and project ID. Restricted access to Amazon public services, such as Amazon Elastic Container Registry (Amazon ECR) to VPC endpoints only. For a reference deployment architecture and ready-to-use deployable constructs for your environment, see Amazon SageMaker with Guardrails on AWS. Conclusion In this post, we showed how you can secure, log, and monitor internet ingress and egress traffic in Studio notebooks for your sensitive ML workloads using managed Network Firewall. You can use the provided CloudFormation templates to automate SageMaker deployment as part of your Infrastructure as Code (IaC) strategy. For more information about other possibilities to secure your SageMaker deployments and ML workloads, see Building secure machine learning environments with Amazon SageMaker.","title":"Secure Network Summary"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#securing-amazon-sagemaker-studio-internet-traffic-using-aws-network-firewall","text":"Building secure machine learning environments with Amazon SageMaker Securing Amazon SageMaker Studio connectivity using a private VPC. Configuring Amazon SageMaker Studio for teams and groups with complete resource isolation Securing Amazon SageMaker Studio connectivity using a private VPC","title":"Securing Amazon SageMaker Studio internet traffic using AWS Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#background","text":"Amazon SageMaker Studio is a web-based fully integrated development environment (IDE) where you can perform end-to-end machine learning (ML) development to prepare data and build, train, and deploy models. One of these fundamental security features allows you to launch Studio in your own Amazon Virtual Private Cloud (Amazon VPC). This allows you to control, monitor, and inspect network traffic within and outside your VPC using standard AWS networking and security capabilities. For more information, see Securing Amazon SageMaker Studio connectivity using a private VPC. SM Studio users may want to provide internet access but also have some controls such as domain name or URL filtering and allow access to only specific public repositories and websites, possibly packet inspection, or other network traffic-related security controls. For these cases, AWS Network Firewall and NAT gateway-based deployment may provide a suitable use case. In this post, I outline the use of network firewall to build a secure and compliant environment by restricting and monitoring internet access, inspecting traffic, and using stateless and stateful firewall engine rules to control the network flow between Studio notebooks and the internet. Depending on your security, compliance, and governance rules, you may not need to or cannot completely block internet access from Studio and your AI and ML workloads. You may have requirements beyond the scope of network security controls implemented by security groups and network access control lists (ACLs), such as application protocol protection, deep packet inspection, domain name filtering, and intrusion prevention system (IPS). Your network traffic controls may also require many more rules compared to what is currently supported in security groups and network ACLs. In these scenarios, you can use Network Firewall\u2014a managed network firewall and IPS for your VPC.","title":"Background"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#solution-overview","text":"Sagemaker Studio deployed in a VPC, provides internet access control, using the parameter AppNetworkAccessType (via the Amazon SageMaker API ) or by selecting your preference on the console when you create a Studio domain. If you select Public internet Only ( PublicInternetOnly ), all the ingress and egress internet traffic from Amazon SageMaker notebooks flows through an AWS managed internet gateway attached to a VPC in your SageMaker account. The following diagram shows this network configuration. Studio provides public internet egress through a platform-managed VPC for data scientists to download notebooks, packages, and datasets. Traffic to the attached Amazon Elastic File System (Amazon EFS) volume always goes through the customer VPC and never through the public internet egress. To use your own control flow for the internet traffic, like a NAT or internet gateway, you must set the AppNetworkAccessType parameter to VpcOnly (or select VPC Only on the console). When you launch your app, this creates an elastic network interface in the specified subnets in your VPC. You can apply all available layers of security control\u2014 security groups , network ACLs , VPC endpoints , AWS PrivateLink , or Network Firewall endpoints \u2014to the internal network and internet traffic to exercise fine-grained control of network access in Studio. The following diagram shows the VpcOnly network configuration. In this mode, the direct internet access to or from notebooks is completely disabled, and all traffic is routed through an elastic network interface in your private VPC. This also includes traffic from Studio UI widgets and interfaces, such as Experiments , Autopilot , and Model Monitor , to their respective backend SageMaker APIs.","title":"Solution overview"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#vpc-only-option","text":"The solution in this post uses the VpcOnly option and deploys the Studio domain into a VPC with three subnets: SageMaker subnet \u2013 Hosts all Studio workloads. All ingress and egress network flow is controlled by a security group. NAT subnet \u2013 Contains a NAT gateway. We use the NAT gateway to access the internet without exposing any private IP addresses from our private network. Network Firewall subnet \u2013 Contains a Network Firewall endpoint. The route tables are configured so that all inbound and outbound external network traffic is routed via Network Firewall. You can configure stateful and stateless Network Firewall policies to inspect, monitor, and control the traffic. The following diagram shows the overview of the solution architecture and the deployed components.","title":"VPC only option"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#sagemaker-resources","text":"Create a SageMaker domain and user profile. The solution uses only one Availability Zone and is not highly available. A best practice is to use a Multi-AZ configuration for any production deployment. We create an allow domain list rule to allow internet access to the specified network domains only and block traffic to any domain not on the allow list.","title":"SageMaker resources"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#aws-cloudformation-resources","text":"The source code and AWS CloudFormation template for solution deployment are provided in the GitHub repository . Network Firewall is a Regional service; for more information on Region availability, see the AWS Region Table . To start experimenting with the Network Firewall and stateful rules, you need first to deploy the provided CloudFormation template to the AWS account. Clone the GitHub repository: Create an S3 bucket in the Region where you deploy the solution: aws s3 mb s3://<your s3 bucket name> You can skip this step if you already have an S3 bucket. Deploy the CloudFormation stack: make deploy CFN_ARTEFACT_S3_BUCKET=<your s3 bucket name> The deployment procedure packages the CloudFormation template and copies it to the S3 bucket your provided. Then the CloudFormation template is deployed from the S3 bucket to your AWS account. The stack deploys all the needed resources like VPC, network devices, route tables, security groups, S3 buckets, IAM policies and roles, and VPC endpoints, and also creates a new Studio domain and user profile. When the deployment is complete, you can see the full list of stack output values by running the following command in terminal: aws cloudformation describe-stacks \\ --stack-name sagemaker-studio-demo \\ --output table \\ --query \"Stacks[0].Outputs[*].[OutputKey, OutputValue]\" Launch Studio via the SageMaker console.","title":"AWS CloudFormation resources"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#experiment-with-network-firewall","text":"Now you can learn how to control the internet inbound and outbound access with Network Firewall. In this section, we discuss the initial setup, accessing resources not on the allow list, adding domains to the allow list, configuring logging, and additional firewall rules.","title":"Experiment with Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#initial-setup","text":"The solution deploys a Network Firewall policy with a stateful rule group with an allow domain list. This policy is attached to the Network Firewall. All inbound and outbound internet traffic is blocked now, except for the .kaggle.com domain, which is on the allow list. Let\u2019s try to access https://kaggle.com by opening a new notebook in Studio and attempting to download the front page from kaggle.com : !wget https://kaggle.com The following screenshot shows that the request succeeds because the domain is allowed by the firewall policy. Users can connect to this and only to this domain from any Studio notebook.","title":"Initial setup"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#access-resources-not-on-the-allowed-domain-list","text":"In the Studio notebook, try to clone any public GitHub repository, such as the following: !git clone https://github.com/pytorch/examples.git This operation times out after 5 minutes because any internet traffic except to and from the .kaggle.com domain isn\u2019t allowed and is dropped by the firewall.","title":"Access resources not on the allowed domain list"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#add-a-domain-to-the-allowed-domain-list","text":"To be able to run the git clone command, you must allow internet traffic to the .github.com domain. On the Amazon VPC console, choose Firewall policies. Choose the policy network-firewall-policy- . In the Stateful rule groups section, select the group rule domain-allow-sagemaker- . You can see the domain .kaggle.com on the allow list. Choose Add domain. Enter .github.com . Choose Save. You now have two names on the allow domain list. Firewall policy is propagated in real time to Network Firewall and your changes take effect immediately. Any inbound or outbound traffic from or to these domains is now allowed by the firewall and all other traffic is dropped. To validate the new configuration, go to your Studio notebook and try to clone the same GitHub repository again: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git The operation succeeds this time\u2014Network Firewall allows access to the .github.com domain.","title":"Add a domain to the allowed domain list"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#network-firewall-logging","text":"In this section, you configure Network Firewall logging for your firewall\u2019s stateful engine. Logging gives you detailed information about network traffic, including the time that the stateful engine received a packet, detailed information about the packet, and any stateful rule action taken against the packet. The logs are published to the log destination that you configured, where you can retrieve and view them. On the Amazon VPC console, choose Firewalls . Choose your firewall. Choose the Firewall details tab. In the Logging section, choose Edit . Configure your firewall logging by selecting what log types you want to capture and providing the log destination. For this post, select Alert log type, set Log destination for alerts to CloudWatch Log group, and provide an existing or a new log group where the firewall logs are delivered. Choose Save . To check your settings, go back to Studio and try to access pypi.org to install a Python package: !pip install -U scikit-learn This command fails with ReadTimeoutError because Network Firewall drops any traffic to any domain not on the allow list (which contains only two domains: .github.com and .kaggle.com ). On the Amazon CloudWatch console , navigate to the log group and browse through the recent log streams. The pipy.org domain shows the blocked action. The log event also provides additional details such as various timestamps, protocol, port and IP details, event type, availability zone, and the firewall name. You can continue experimenting with Network Firewall by adding .pypi.org and .pythonhosted.org domains to the allowed domain list. Then validate your access to them via your Studio notebook.","title":"Network Firewall logging"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#additional-firewall-rules","text":"You can create any other stateless or stateful firewall rules and implement traffic filtering based on a standard stateful 5-tuple rule for network traffic inspection (protocol, source IP, source port, destination IP, destination port). Network Firewall also supports industry standard stateful Suricata compatible IPS rule groups. You can implement protocol-based rules to detect and block any non-standard or promiscuous usage or activity. For more information about creating and managing Network Firewall rule groups, see Rule groups in AWS Network Firewall.","title":"Additional firewall rules"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#additional-security-controls-with-network-firewall","text":"In the previous section, we looked at one feature of the Network Firewall: filtering network traffic based on the domain name. In addition to stateless or stateful firewall rules, Network Firewall provides several tools and features for further security controls and monitoring: Central firewall management and visibility in AWS Firewall Manager . You can centrally manage security policies and automatically enforce mandatory security policies across existing and newly created accounts and VPCs. Network Firewall logging for the firewall\u2019s stateful engine. You can record flow and alert logs, and use the same or different logging destinations for each log type. Stateless rules to filter network traffic based on protocol, source IP addresses, ranges, source port ranges, destination IP addresses and ranges, and TCP flags. Integration into a broader set of AWS security components. For an example, see Automatically block suspicious traffic with AWS Network Firewall and Amazon GuardDuty. Integration in a diverse ecosystem of Network Firewall Partners that complement Network Firewall, enabling the deployment of a comprehensive security architecture. For example use cases, see Full VPC traffic visibility with AWS Network Firewall and Sumo Logic and Splunk Named Launch Partner of AWS Network Firewall.","title":"Additional security controls with Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#build-secure-ml-environments","text":"A robust security design normally includes multi-layer security controls for the system. For SageMaker environments and workloads, you can use the following AWS security services and concepts to secure, control, and monitor your environment: VPC and private subnets to perform secure API calls to other AWS services and restrict internet access for downloading packages. S3 bucket policies that restrict access to specific VPC endpoints. Encryption of ML model artifacts and other system artifacts that are either in transit or at rest. Requests to the SageMaker API and console are made over a Secure Sockets Layer (SSL) connection. Restricted IAM roles and policies for SageMaker runs and notebook access based on resource tags and project ID. Restricted access to Amazon public services, such as Amazon Elastic Container Registry (Amazon ECR) to VPC endpoints only. For a reference deployment architecture and ready-to-use deployable constructs for your environment, see Amazon SageMaker with Guardrails on AWS.","title":"Build secure ML environments"},{"location":"sagemaker/secure-sagemaker-network-firewall-summary/#conclusion","text":"In this post, we showed how you can secure, log, and monitor internet ingress and egress traffic in Studio notebooks for your sensitive ML workloads using managed Network Firewall. You can use the provided CloudFormation templates to automate SageMaker deployment as part of your Infrastructure as Code (IaC) strategy. For more information about other possibilities to secure your SageMaker deployments and ML workloads, see Building secure machine learning environments with Amazon SageMaker.","title":"Conclusion"},{"location":"sagemaker/secure-sagemaker-network-firewall/","text":"Securing Amazon SageMaker Studio internet traffic using AWS Network Firewall Full github repo with code The work in this document complements previous work: - Building secure machine learning environments with Amazon SageMaker Securing Amazon SageMaker Studio connectivity using a private VPC. Background Amazon SageMaker Studio is a web-based fully integrated development environment (IDE) where you can perform end-to-end machine learning (ML) development to prepare data and build, train, and deploy models. Like other AWS services, Studio supports a rich set of security-related features that allow you to build highly secure and compliant environments. One of these fundamental security features allows you to launch Studio in your own Amazon Virtual Private Cloud (Amazon VPC). This allows you to control, monitor, and inspect network traffic within and outside your VPC using standard AWS networking and security capabilities. For more information, see Securing Amazon SageMaker Studio connectivity using a private VPC. Customers in regulated industries, such as financial services, often don\u2019t allow any internet access in ML environments. They often use only VPC endpoints for AWS services, and connect only to private source code repositories in which all libraries have been vetted both in terms of security and licensing. Customers may want to provide internet access but also have some controls such as domain name or URL filtering and allow access to only specific public repositories and websites, possibly packet inspection, or other network traffic-related security controls. For these cases, AWS Network Firewall and NAT gateway-based deployment may provide a suitable use case. In this post, we show how you can use Network Firewall to build a secure and compliant environment by restricting and monitoring internet access, inspecting traffic, and using stateless and stateful firewall engine rules to control the network flow between Studio notebooks and the internet. Depending on your security, compliance, and governance rules, you may not need to or cannot completely block internet access from Studio and your AI and ML workloads. You may have requirements beyond the scope of network security controls implemented by security groups and network access control lists (ACLs), such as application protocol protection, deep packet inspection, domain name filtering, and intrusion prevention system (IPS). Your network traffic controls may also require many more rules compared to what is currently supported in security groups and network ACLs. In these scenarios, you can use Network Firewall\u2014a managed network firewall and IPS for your VPC. Solution overview When you deploy Studio in your VPC, you control how Studio accesses the internet with the parameter AppNetworkAccessType (via the Amazon SageMaker API ) or by selecting your preference on the console when you create a Studio domain. If you select Public internet Only ( PublicInternetOnly ), all the ingress and egress internet traffic from Amazon SageMaker notebooks flows through an AWS managed internet gateway attached to a VPC in your SageMaker account. The following diagram shows this network configuration. Studio provides public internet egress through a platform-managed VPC for data scientists to download notebooks, packages, and datasets. Traffic to the attached Amazon Elastic File System (Amazon EFS) volume always goes through the customer VPC and never through the public internet egress. To use your own control flow for the internet traffic, like a NAT or internet gateway, you must set the AppNetworkAccessType parameter to VpcOnly (or select VPC Only on the console). When you launch your app, this creates an elastic network interface in the specified subnets in your VPC. You can apply all available layers of security control\u2014 security groups , network ACLs , VPC endpoints , AWS PrivateLink , or Network Firewall endpoints \u2014to the internal network and internet traffic to exercise fine-grained control of network access in Studio. The following diagram shows the VpcOnly network configuration. In this mode, the direct internet access to or from notebooks is completely disabled, and all traffic is routed through an elastic network interface in your private VPC. This also includes traffic from Studio UI widgets and interfaces, such as Experiments , Autopilot , and Model Monitor , to their respective backend SageMaker APIs. For more information about network access parameters when creating a domain, see CreateDomain . The solution in this post uses the VpcOnly option and deploys the Studio domain into a VPC with three subnets: SageMaker subnet \u2013 Hosts all Studio workloads. All ingress and egress network flow is controlled by a security group. NAT subnet \u2013 Contains a NAT gateway. We use the NAT gateway to access the internet without exposing any private IP addresses from our private network. Network Firewall subnet \u2013 Contains a Network Firewall endpoint. The route tables are configured so that all inbound and outbound external network traffic is routed via Network Firewall. You can configure stateful and stateless Network Firewall policies to inspect, monitor, and control the traffic. The following diagram shows the overview of the solution architecture and the deployed components. VPC resources The solution deploys the following resources in your account: A VPC with a specified Classless Inter-Domain Routing (CIDR) block Three private subnets with specified CIDRs Internet gateway, NAT gateway, Network Firewall, and a Network Firewall endpoint in the Network Firewall subnet A Network Firewall policy and stateful domain list group with an allow domain list Elastic IP allocated to the NAT gateway Two security groups for SageMaker workloads and VPC endpoints, respectively Four route tables with configured routes An Amazon S3 VPC endpoint (type Gateway) AWS service access VPC endpoints (type Interface) for various AWS services that need to be accessed from Studio The solution also creates an AWS Identity and Access Management (IAM) execution role for SageMaker notebooks and Studio with preconfigured IAM policies. Network routing for targets outside the VPC is configured in such a way that all ingress and egress internet traffic goes via the Network Firewall and NAT gateway. For details and reference network architectures with Network Firewall and NAT gateway, see Architecture with an internet gateway and a NAT gateway , Deployment models for AWS Network Firewall , and Enforce your AWS Network Firewall protections at scale with AWS Firewall Manager . The AWS re:Invent 2020 video Which inspection architecture is right for you? discusses which inspection architecture is right for your use case. SageMaker resources The solution creates a SageMaker domain and user profile. The solution uses only one Availability Zone and is not highly available. A best practice is to use a Multi-AZ configuration for any production deployment. You can implement the highly available solution by duplicating the Single-AZ setup\u2014subnets, NAT gateway, and Network Firewall endpoints\u2014to additional Availability Zones. You use Network Firewall and its policies to control entry and exit of the internet traffic in your VPC. You create an allow domain list rule to allow internet access to the specified network domains only and block traffic to any domain not on the allow list. AWS CloudFormation resources The source code and AWS CloudFormation template for solution deployment are provided in the GitHub repository . To deploy the solution on your account, you need: An AWS account and the AWS Command Line Interface (AWS CLI) configured with administrator permissions An Amazon Simple Storage Service (Amazon S3) bucket in your account in the same Region where you deploy the solution Network Firewall is a Regional service; for more information on Region availability, see the AWS Region Table . Your CloudFormation stack doesn\u2019t have any required parameters. You may want to change the DomainName or *CIDR parameters to avoid naming conflicts with the existing resources and your VPC CIDR allocations. Otherwise, use the following default values: ProjectName \u2013 sagemaker-studio-vpc-firewall DomainName \u2013 sagemaker-anfw-domain UserProfileName \u2013 anfw-user-profile VPCCIDR \u2013 10.2.0.0/16 FirewallSubnetCIDR \u2013 10.2.1.0/24 NATGatewaySubnetCIDR \u2013 10.2.2.0/24 SageMakerStudioSubnetCIDR \u2013 10.2.3.0/24 Deploy the CloudFormation template To start experimenting with the Network Firewall and stateful rules, you need first to deploy the provided CloudFormation template to your AWS account. Clone the GitHub repository: git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git cd amazon-sagemaker-studio-vpc-networkfirewall Create an S3 bucket in the Region where you deploy the solution: aws s3 mb s3://<your s3 bucket name> You can skip this step if you already have an S3 bucket. Deploy the CloudFormation stack: make deploy CFN_ARTEFACT_S3_BUCKET=<your s3 bucket name> The deployment procedure packages the CloudFormation template and copies it to the S3 bucket your provided. Then the CloudFormation template is deployed from the S3 bucket to your AWS account. The stack deploys all the needed resources like VPC, network devices, route tables, security groups, S3 buckets, IAM policies and roles, and VPC endpoints, and also creates a new Studio domain and user profile. When the deployment is complete, you can see the full list of stack output values by running the following command in terminal: aws cloudformation describe-stacks \\ --stack-name sagemaker-studio-demo \\ --output table \\ --query \"Stacks[0].Outputs[*].[OutputKey, OutputValue]\" Launch Studio via the SageMaker console. Experiment with Network Firewall Now you can learn how to control the internet inbound and outbound access with Network Firewall. In this section, we discuss the initial setup, accessing resources not on the allow list, adding domains to the allow list, configuring logging, and additional firewall rules. Initial setup The solution deploys a Network Firewall policy with a stateful rule group with an allow domain list. This policy is attached to the Network Firewall. All inbound and outbound internet traffic is blocked now, except for the .kaggle.com domain, which is on the allow list. Let\u2019s try to access https://kaggle.com by opening a new notebook in Studio and attempting to download the front page from kaggle.com : !wget https://kaggle.com The following screenshot shows that the request succeeds because the domain is allowed by the firewall policy. Users can connect to this and only to this domain from any Studio notebook. Access resources not on the allowed domain list In the Studio notebook, try to clone any public GitHub repository, such as the following: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git This operation times out after 5 minutes because any internet traffic except to and from the .kaggle.com domain isn\u2019t allowed and is dropped by Network Firewall. Add a domain to the allowed domain list To be able to run the git clone command, you must allow internet traffic to the .github.com domain. On the Amazon VPC console, choose Firewall policies. Choose the policy network-firewall-policy- . In the Stateful rule groups section, select the group rule domain-allow-sagemaker- . You can see the domain .kaggle.com on the allow list. Choose Add domain. Enter .github.com . Choose Save. You now have two names on the allow domain list. Firewall policy is propagated in real time to Network Firewall and your changes take effect immediately. Any inbound or outbound traffic from or to these domains is now allowed by the firewall and all other traffic is dropped. To validate the new configuration, go to your Studio notebook and try to clone the same GitHub repository again: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git The operation succeeds this time\u2014Network Firewall allows access to the .github.com domain. Network Firewall logging In this section, you configure Network Firewall logging for your firewall\u2019s stateful engine. Logging gives you detailed information about network traffic, including the time that the stateful engine received a packet, detailed information about the packet, and any stateful rule action taken against the packet. The logs are published to the log destination that you configured, where you can retrieve and view them. On the Amazon VPC console, choose Firewalls . Choose your firewall. Choose the Firewall details tab. In the Logging section, choose Edit . Configure your firewall logging by selecting what log types you want to capture and providing the log destination. For this post, select Alert log type, set Log destination for alerts to CloudWatch Log group, and provide an existing or a new log group where the firewall logs are delivered. Choose Save . To check your settings, go back to Studio and try to access pypi.org to install a Python package: !pip install -U scikit-learn This command fails with ReadTimeoutError because Network Firewall drops any traffic to any domain not on the allow list (which contains only two domains: .github.com and .kaggle.com ). On the Amazon CloudWatch console , navigate to the log group and browse through the recent log streams. The pipy.org domain shows the blocked action. The log event also provides additional details such as various timestamps, protocol, port and IP details, event type, availability zone, and the firewall name. You can continue experimenting with Network Firewall by adding .pypi.org and .pythonhosted.org domains to the allowed domain list. Then validate your access to them via your Studio notebook. Additional firewall rules You can create any other stateless or stateful firewall rules and implement traffic filtering based on a standard stateful 5-tuple rule for network traffic inspection (protocol, source IP, source port, destination IP, destination port). Network Firewall also supports industry standard stateful Suricata compatible IPS rule groups. You can implement protocol-based rules to detect and block any non-standard or promiscuous usage or activity. For more information about creating and managing Network Firewall rule groups, see Rule groups in AWS Network Firewall. Additional security controls with Network Firewall In the previous section, we looked at one feature of the Network Firewall: filtering network traffic based on the domain name. In addition to stateless or stateful firewall rules, Network Firewall provides several tools and features for further security controls and monitoring: Central firewall management and visibility in AWS Firewall Manager . You can centrally manage security policies and automatically enforce mandatory security policies across existing and newly created accounts and VPCs. Network Firewall logging for the firewall\u2019s stateful engine. You can record flow and alert logs, and use the same or different logging destinations for each log type. Stateless rules to filter network traffic based on protocol, source IP addresses, ranges, source port ranges, destination IP addresses and ranges, and TCP flags. Integration into a broader set of AWS security components. For an example, see Automatically block suspicious traffic with AWS Network Firewall and Amazon GuardDuty. Integration in a diverse ecosystem of Network Firewall Partners that complement Network Firewall, enabling the deployment of a comprehensive security architecture. For example use cases, see Full VPC traffic visibility with AWS Network Firewall and Sumo Logic and Splunk Named Launch Partner of AWS Network Firewall. Build secure ML environments A robust security design normally includes multi-layer security controls for the system. For SageMaker environments and workloads, you can use the following AWS security services and concepts to secure, control, and monitor your environment: VPC and private subnets to perform secure API calls to other AWS services and restrict internet access for downloading packages. S3 bucket policies that restrict access to specific VPC endpoints. Encryption of ML model artifacts and other system artifacts that are either in transit or at rest. Requests to the SageMaker API and console are made over a Secure Sockets Layer (SSL) connection. Restricted IAM roles and policies for SageMaker runs and notebook access based on resource tags and project ID. Restricted access to Amazon public services, such as Amazon Elastic Container Registry (Amazon ECR) to VPC endpoints only. For a reference deployment architecture and ready-to-use deployable constructs for your environment, see Amazon SageMaker with Guardrails on AWS. Conclusion In this post, we showed how you can secure, log, and monitor internet ingress and egress traffic in Studio notebooks for your sensitive ML workloads using managed Network Firewall. You can use the provided CloudFormation templates to automate SageMaker deployment as part of your Infrastructure as Code (IaC) strategy. For more information about other possibilities to secure your SageMaker deployments and ML workloads, see Building secure machine learning environments with Amazon SageMaker.","title":"Secure Network"},{"location":"sagemaker/secure-sagemaker-network-firewall/#securing-amazon-sagemaker-studio-internet-traffic-using-aws-network-firewall","text":"Full github repo with code The work in this document complements previous work: - Building secure machine learning environments with Amazon SageMaker Securing Amazon SageMaker Studio connectivity using a private VPC.","title":"Securing Amazon SageMaker Studio internet traffic using AWS Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall/#background","text":"Amazon SageMaker Studio is a web-based fully integrated development environment (IDE) where you can perform end-to-end machine learning (ML) development to prepare data and build, train, and deploy models. Like other AWS services, Studio supports a rich set of security-related features that allow you to build highly secure and compliant environments. One of these fundamental security features allows you to launch Studio in your own Amazon Virtual Private Cloud (Amazon VPC). This allows you to control, monitor, and inspect network traffic within and outside your VPC using standard AWS networking and security capabilities. For more information, see Securing Amazon SageMaker Studio connectivity using a private VPC. Customers in regulated industries, such as financial services, often don\u2019t allow any internet access in ML environments. They often use only VPC endpoints for AWS services, and connect only to private source code repositories in which all libraries have been vetted both in terms of security and licensing. Customers may want to provide internet access but also have some controls such as domain name or URL filtering and allow access to only specific public repositories and websites, possibly packet inspection, or other network traffic-related security controls. For these cases, AWS Network Firewall and NAT gateway-based deployment may provide a suitable use case. In this post, we show how you can use Network Firewall to build a secure and compliant environment by restricting and monitoring internet access, inspecting traffic, and using stateless and stateful firewall engine rules to control the network flow between Studio notebooks and the internet. Depending on your security, compliance, and governance rules, you may not need to or cannot completely block internet access from Studio and your AI and ML workloads. You may have requirements beyond the scope of network security controls implemented by security groups and network access control lists (ACLs), such as application protocol protection, deep packet inspection, domain name filtering, and intrusion prevention system (IPS). Your network traffic controls may also require many more rules compared to what is currently supported in security groups and network ACLs. In these scenarios, you can use Network Firewall\u2014a managed network firewall and IPS for your VPC.","title":"Background"},{"location":"sagemaker/secure-sagemaker-network-firewall/#solution-overview","text":"When you deploy Studio in your VPC, you control how Studio accesses the internet with the parameter AppNetworkAccessType (via the Amazon SageMaker API ) or by selecting your preference on the console when you create a Studio domain. If you select Public internet Only ( PublicInternetOnly ), all the ingress and egress internet traffic from Amazon SageMaker notebooks flows through an AWS managed internet gateway attached to a VPC in your SageMaker account. The following diagram shows this network configuration. Studio provides public internet egress through a platform-managed VPC for data scientists to download notebooks, packages, and datasets. Traffic to the attached Amazon Elastic File System (Amazon EFS) volume always goes through the customer VPC and never through the public internet egress. To use your own control flow for the internet traffic, like a NAT or internet gateway, you must set the AppNetworkAccessType parameter to VpcOnly (or select VPC Only on the console). When you launch your app, this creates an elastic network interface in the specified subnets in your VPC. You can apply all available layers of security control\u2014 security groups , network ACLs , VPC endpoints , AWS PrivateLink , or Network Firewall endpoints \u2014to the internal network and internet traffic to exercise fine-grained control of network access in Studio. The following diagram shows the VpcOnly network configuration. In this mode, the direct internet access to or from notebooks is completely disabled, and all traffic is routed through an elastic network interface in your private VPC. This also includes traffic from Studio UI widgets and interfaces, such as Experiments , Autopilot , and Model Monitor , to their respective backend SageMaker APIs. For more information about network access parameters when creating a domain, see CreateDomain . The solution in this post uses the VpcOnly option and deploys the Studio domain into a VPC with three subnets: SageMaker subnet \u2013 Hosts all Studio workloads. All ingress and egress network flow is controlled by a security group. NAT subnet \u2013 Contains a NAT gateway. We use the NAT gateway to access the internet without exposing any private IP addresses from our private network. Network Firewall subnet \u2013 Contains a Network Firewall endpoint. The route tables are configured so that all inbound and outbound external network traffic is routed via Network Firewall. You can configure stateful and stateless Network Firewall policies to inspect, monitor, and control the traffic. The following diagram shows the overview of the solution architecture and the deployed components.","title":"Solution overview"},{"location":"sagemaker/secure-sagemaker-network-firewall/#vpc-resources","text":"The solution deploys the following resources in your account: A VPC with a specified Classless Inter-Domain Routing (CIDR) block Three private subnets with specified CIDRs Internet gateway, NAT gateway, Network Firewall, and a Network Firewall endpoint in the Network Firewall subnet A Network Firewall policy and stateful domain list group with an allow domain list Elastic IP allocated to the NAT gateway Two security groups for SageMaker workloads and VPC endpoints, respectively Four route tables with configured routes An Amazon S3 VPC endpoint (type Gateway) AWS service access VPC endpoints (type Interface) for various AWS services that need to be accessed from Studio The solution also creates an AWS Identity and Access Management (IAM) execution role for SageMaker notebooks and Studio with preconfigured IAM policies. Network routing for targets outside the VPC is configured in such a way that all ingress and egress internet traffic goes via the Network Firewall and NAT gateway. For details and reference network architectures with Network Firewall and NAT gateway, see Architecture with an internet gateway and a NAT gateway , Deployment models for AWS Network Firewall , and Enforce your AWS Network Firewall protections at scale with AWS Firewall Manager . The AWS re:Invent 2020 video Which inspection architecture is right for you? discusses which inspection architecture is right for your use case.","title":"VPC resources"},{"location":"sagemaker/secure-sagemaker-network-firewall/#sagemaker-resources","text":"The solution creates a SageMaker domain and user profile. The solution uses only one Availability Zone and is not highly available. A best practice is to use a Multi-AZ configuration for any production deployment. You can implement the highly available solution by duplicating the Single-AZ setup\u2014subnets, NAT gateway, and Network Firewall endpoints\u2014to additional Availability Zones. You use Network Firewall and its policies to control entry and exit of the internet traffic in your VPC. You create an allow domain list rule to allow internet access to the specified network domains only and block traffic to any domain not on the allow list.","title":"SageMaker resources"},{"location":"sagemaker/secure-sagemaker-network-firewall/#aws-cloudformation-resources","text":"The source code and AWS CloudFormation template for solution deployment are provided in the GitHub repository . To deploy the solution on your account, you need: An AWS account and the AWS Command Line Interface (AWS CLI) configured with administrator permissions An Amazon Simple Storage Service (Amazon S3) bucket in your account in the same Region where you deploy the solution Network Firewall is a Regional service; for more information on Region availability, see the AWS Region Table . Your CloudFormation stack doesn\u2019t have any required parameters. You may want to change the DomainName or *CIDR parameters to avoid naming conflicts with the existing resources and your VPC CIDR allocations. Otherwise, use the following default values: ProjectName \u2013 sagemaker-studio-vpc-firewall DomainName \u2013 sagemaker-anfw-domain UserProfileName \u2013 anfw-user-profile VPCCIDR \u2013 10.2.0.0/16 FirewallSubnetCIDR \u2013 10.2.1.0/24 NATGatewaySubnetCIDR \u2013 10.2.2.0/24 SageMakerStudioSubnetCIDR \u2013 10.2.3.0/24 Deploy the CloudFormation template To start experimenting with the Network Firewall and stateful rules, you need first to deploy the provided CloudFormation template to your AWS account. Clone the GitHub repository: git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git cd amazon-sagemaker-studio-vpc-networkfirewall Create an S3 bucket in the Region where you deploy the solution: aws s3 mb s3://<your s3 bucket name> You can skip this step if you already have an S3 bucket. Deploy the CloudFormation stack: make deploy CFN_ARTEFACT_S3_BUCKET=<your s3 bucket name> The deployment procedure packages the CloudFormation template and copies it to the S3 bucket your provided. Then the CloudFormation template is deployed from the S3 bucket to your AWS account. The stack deploys all the needed resources like VPC, network devices, route tables, security groups, S3 buckets, IAM policies and roles, and VPC endpoints, and also creates a new Studio domain and user profile. When the deployment is complete, you can see the full list of stack output values by running the following command in terminal: aws cloudformation describe-stacks \\ --stack-name sagemaker-studio-demo \\ --output table \\ --query \"Stacks[0].Outputs[*].[OutputKey, OutputValue]\" Launch Studio via the SageMaker console.","title":"AWS CloudFormation resources"},{"location":"sagemaker/secure-sagemaker-network-firewall/#experiment-with-network-firewall","text":"Now you can learn how to control the internet inbound and outbound access with Network Firewall. In this section, we discuss the initial setup, accessing resources not on the allow list, adding domains to the allow list, configuring logging, and additional firewall rules.","title":"Experiment with Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall/#initial-setup","text":"The solution deploys a Network Firewall policy with a stateful rule group with an allow domain list. This policy is attached to the Network Firewall. All inbound and outbound internet traffic is blocked now, except for the .kaggle.com domain, which is on the allow list. Let\u2019s try to access https://kaggle.com by opening a new notebook in Studio and attempting to download the front page from kaggle.com : !wget https://kaggle.com The following screenshot shows that the request succeeds because the domain is allowed by the firewall policy. Users can connect to this and only to this domain from any Studio notebook.","title":"Initial setup"},{"location":"sagemaker/secure-sagemaker-network-firewall/#access-resources-not-on-the-allowed-domain-list","text":"In the Studio notebook, try to clone any public GitHub repository, such as the following: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git This operation times out after 5 minutes because any internet traffic except to and from the .kaggle.com domain isn\u2019t allowed and is dropped by Network Firewall.","title":"Access resources not on the allowed domain list"},{"location":"sagemaker/secure-sagemaker-network-firewall/#add-a-domain-to-the-allowed-domain-list","text":"To be able to run the git clone command, you must allow internet traffic to the .github.com domain. On the Amazon VPC console, choose Firewall policies. Choose the policy network-firewall-policy- . In the Stateful rule groups section, select the group rule domain-allow-sagemaker- . You can see the domain .kaggle.com on the allow list. Choose Add domain. Enter .github.com . Choose Save. You now have two names on the allow domain list. Firewall policy is propagated in real time to Network Firewall and your changes take effect immediately. Any inbound or outbound traffic from or to these domains is now allowed by the firewall and all other traffic is dropped. To validate the new configuration, go to your Studio notebook and try to clone the same GitHub repository again: !git clone https://github.com/aws-samples/amazon-sagemaker-studio-vpc-networkfirewall.git The operation succeeds this time\u2014Network Firewall allows access to the .github.com domain.","title":"Add a domain to the allowed domain list"},{"location":"sagemaker/secure-sagemaker-network-firewall/#network-firewall-logging","text":"In this section, you configure Network Firewall logging for your firewall\u2019s stateful engine. Logging gives you detailed information about network traffic, including the time that the stateful engine received a packet, detailed information about the packet, and any stateful rule action taken against the packet. The logs are published to the log destination that you configured, where you can retrieve and view them. On the Amazon VPC console, choose Firewalls . Choose your firewall. Choose the Firewall details tab. In the Logging section, choose Edit . Configure your firewall logging by selecting what log types you want to capture and providing the log destination. For this post, select Alert log type, set Log destination for alerts to CloudWatch Log group, and provide an existing or a new log group where the firewall logs are delivered. Choose Save . To check your settings, go back to Studio and try to access pypi.org to install a Python package: !pip install -U scikit-learn This command fails with ReadTimeoutError because Network Firewall drops any traffic to any domain not on the allow list (which contains only two domains: .github.com and .kaggle.com ). On the Amazon CloudWatch console , navigate to the log group and browse through the recent log streams. The pipy.org domain shows the blocked action. The log event also provides additional details such as various timestamps, protocol, port and IP details, event type, availability zone, and the firewall name. You can continue experimenting with Network Firewall by adding .pypi.org and .pythonhosted.org domains to the allowed domain list. Then validate your access to them via your Studio notebook.","title":"Network Firewall logging"},{"location":"sagemaker/secure-sagemaker-network-firewall/#additional-firewall-rules","text":"You can create any other stateless or stateful firewall rules and implement traffic filtering based on a standard stateful 5-tuple rule for network traffic inspection (protocol, source IP, source port, destination IP, destination port). Network Firewall also supports industry standard stateful Suricata compatible IPS rule groups. You can implement protocol-based rules to detect and block any non-standard or promiscuous usage or activity. For more information about creating and managing Network Firewall rule groups, see Rule groups in AWS Network Firewall.","title":"Additional firewall rules"},{"location":"sagemaker/secure-sagemaker-network-firewall/#additional-security-controls-with-network-firewall","text":"In the previous section, we looked at one feature of the Network Firewall: filtering network traffic based on the domain name. In addition to stateless or stateful firewall rules, Network Firewall provides several tools and features for further security controls and monitoring: Central firewall management and visibility in AWS Firewall Manager . You can centrally manage security policies and automatically enforce mandatory security policies across existing and newly created accounts and VPCs. Network Firewall logging for the firewall\u2019s stateful engine. You can record flow and alert logs, and use the same or different logging destinations for each log type. Stateless rules to filter network traffic based on protocol, source IP addresses, ranges, source port ranges, destination IP addresses and ranges, and TCP flags. Integration into a broader set of AWS security components. For an example, see Automatically block suspicious traffic with AWS Network Firewall and Amazon GuardDuty. Integration in a diverse ecosystem of Network Firewall Partners that complement Network Firewall, enabling the deployment of a comprehensive security architecture. For example use cases, see Full VPC traffic visibility with AWS Network Firewall and Sumo Logic and Splunk Named Launch Partner of AWS Network Firewall.","title":"Additional security controls with Network Firewall"},{"location":"sagemaker/secure-sagemaker-network-firewall/#build-secure-ml-environments","text":"A robust security design normally includes multi-layer security controls for the system. For SageMaker environments and workloads, you can use the following AWS security services and concepts to secure, control, and monitor your environment: VPC and private subnets to perform secure API calls to other AWS services and restrict internet access for downloading packages. S3 bucket policies that restrict access to specific VPC endpoints. Encryption of ML model artifacts and other system artifacts that are either in transit or at rest. Requests to the SageMaker API and console are made over a Secure Sockets Layer (SSL) connection. Restricted IAM roles and policies for SageMaker runs and notebook access based on resource tags and project ID. Restricted access to Amazon public services, such as Amazon Elastic Container Registry (Amazon ECR) to VPC endpoints only. For a reference deployment architecture and ready-to-use deployable constructs for your environment, see Amazon SageMaker with Guardrails on AWS.","title":"Build secure ML environments"},{"location":"sagemaker/secure-sagemaker-network-firewall/#conclusion","text":"In this post, we showed how you can secure, log, and monitor internet ingress and egress traffic in Studio notebooks for your sensitive ML workloads using managed Network Firewall. You can use the provided CloudFormation templates to automate SageMaker deployment as part of your Infrastructure as Code (IaC) strategy. For more information about other possibilities to secure your SageMaker deployments and ML workloads, see Building secure machine learning environments with Amazon SageMaker.","title":"Conclusion"}]}